{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rY12UsJAs4Je",
    "outputId": "c65f34fe-4297-4403-ea35-e848dbd8eef6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: fairlearn in /home/s2balamurugan/.local/lib/python3.11/site-packages (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.11/site-packages (from fairlearn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.0.3 in /opt/conda/lib/python3.11/site-packages (from fairlearn) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=1.2.1 in /opt/conda/lib/python3.11/site-packages (from fairlearn) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.9.3 in /opt/conda/lib/python3.11/site-packages (from fairlearn) (1.13.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=2.0.3->fairlearn) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=2.0.3->fairlearn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=2.0.3->fairlearn) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=1.2.1->fairlearn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=1.2.1->fairlearn) (3.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "1C0EnfdCs1yd",
    "outputId": "bc4be124-f9a2-49dc-cfef-4494c4ae0042"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 17:21:18.205925: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-06 17:21:18.205964: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-06 17:21:18.207517: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-06 17:21:18.219024: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing Adult data...\n",
      "Features shape: (32561, 5)\n",
      "Observed Label Y shape: (32561,)   (Label from 'income')\n",
      "Sensitive Attribute (Sex) shape: (32561,)\n",
      "\n",
      "Training adversarial model (X → Y' with adversary) ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Dense' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 304\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    303\u001b[0m     adult_data_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43madult_data_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_adv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 237\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(data_url, lambda_adv)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m### 1. Train adversarial debiasing model (X → Y' with adversary)\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining adversarial model (X → Y\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with adversary) ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 237\u001b[0m adv_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_adversarial_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_adv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_adv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# For training, we use the observed Y as target for both pseudo_Y and Y_pred.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# Reshape Y_obs to (-1,1) since our outputs are scalars.\u001b[39;00m\n\u001b[1;32m    240\u001b[0m Y_train_obs_exp \u001b[38;5;241m=\u001b[39m Y_train_obs\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 99\u001b[0m, in \u001b[0;36mbuild_adversarial_model\u001b[0;34m(input_dim, lambda_adv)\u001b[0m\n\u001b[1;32m     96\u001b[0m S_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# one-hot encoded S\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Main branch: Encoder for pseudo-label.\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[43mDense\u001b[49m(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(X_input)\n\u001b[1;32m    100\u001b[0m h \u001b[38;5;241m=\u001b[39m BatchNormalization()(h)\n\u001b[1;32m    101\u001b[0m h \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m32\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(h)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dense' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# -------------------------------\n",
    "# Custom Gradient Reversal Layer\n",
    "# -------------------------------\n",
    "@tf.custom_gradient\n",
    "def grad_reverse(x, lambda_):\n",
    "    def grad(dy):\n",
    "        return -lambda_ * dy, None\n",
    "    return x, grad\n",
    "\n",
    "class GradientReversalLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, lambda_=1.0, **kwargs):\n",
    "        super(GradientReversalLayer, self).__init__(**kwargs)\n",
    "        self.lambda_ = lambda_\n",
    "    def call(self, x):\n",
    "        return grad_reverse(x, self.lambda_)\n",
    "\n",
    "# -------------------------------\n",
    "# Data Loading and Preprocessing\n",
    "# -------------------------------\n",
    "def set_seed(seed_num):\n",
    "    random.seed(seed_num)\n",
    "    np.random.seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_num)\n",
    "\n",
    "def load_and_preprocess_adult_data(data_url):\n",
    "    \"\"\"\n",
    "    Download and preprocess the UCI Adult dataset.\n",
    "\n",
    "    Features (X): use only:\n",
    "       'age', 'education-num', 'marital-status', 'occupation', 'hours-per-week'\n",
    "    Observed Label (Y): derived from 'income' (binary: 1 if '>50K', 0 otherwise)\n",
    "    Sensitive attribute (S): derived from 'sex' (binary: 1 if 'Male', 0 if 'Female')\n",
    "\n",
    "    Returns:\n",
    "      X: numpy array of shape (n_samples, 5)\n",
    "      Y: 1-D numpy array of observed labels.\n",
    "      S: 1-D numpy array of sensitive attribute.\n",
    "    \"\"\"\n",
    "    col_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "                 \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "                 \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n",
    "    data = pd.read_csv(data_url, header=None, names=col_names, na_values=\" ?\", skipinitialspace=True)\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    # Features\n",
    "    feature_cols = [\"age\", \"education-num\", \"marital-status\", \"occupation\", \"hours-per-week\"]\n",
    "    X = data[feature_cols].copy()\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == object:\n",
    "            X[col] = pd.Categorical(X[col]).codes\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X.values.astype(np.float32))\n",
    "\n",
    "    # Observed label\n",
    "    data['income'] = data['income'].apply(lambda s: s.replace('.', '').strip())\n",
    "    y_binary = (data['income'] == '>50K').astype(np.int32)\n",
    "    Y = y_binary.values  # 1-D array\n",
    "\n",
    "    # Sensitive attribute\n",
    "    S = (data['sex'].str.strip() == 'Male').astype(np.int32).values  # 1-D array\n",
    "\n",
    "    return X, Y, S\n",
    "\n",
    "# -------------------------------\n",
    "# Adversarial Debiasing Model\n",
    "# -------------------------------\n",
    "def build_adversarial_model(input_dim, lambda_adv=1.0):\n",
    "    \"\"\"\n",
    "    Build an adversarial debiasing model that learns pseudo‑labels Y' from X.\n",
    "\n",
    "    Architecture:\n",
    "      - Main branch (encoder): from X, several dense layers produce a latent pseudo‑label pseudo_Y (via sigmoid).\n",
    "      - Adversary branch: pseudo_Y is passed through a Gradient Reversal Layer and then dense layers predict S.\n",
    "      - Decoder branch: concatenates pseudo_Y and the one-hot sensitive attribute S to predict the observed label Y.\n",
    "\n",
    "    Losses:\n",
    "      - For the main branch, binary crossentropy between observed Y and pseudo_Y (and Y_pred).\n",
    "      - For the adversary branch, categorical crossentropy to predict S.\n",
    "\n",
    "    Returns a compiled Keras model that takes inputs X and S (one-hot encoded) and outputs:\n",
    "      [pseudo_Y, S_pred, Y_pred].\n",
    "    \"\"\"\n",
    "    X_input = tf.keras.Input(shape=(input_dim,), name=\"X\")\n",
    "    S_input = tf.keras.Input(shape=(2,), name=\"S\")  # one-hot encoded S\n",
    "\n",
    "    # Main branch: Encoder for pseudo-label.\n",
    "    h = Dense(64, activation='relu')(X_input)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Dense(32, activation='relu')(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    pseudo_Y = Dense(1, activation='sigmoid', name=\"pseudo_Y\")(h)\n",
    "\n",
    "    # Adversary branch: from pseudo_Y, with GRL.\n",
    "    grl = GradientReversalLayer(lambda_=lambda_adv)(pseudo_Y)\n",
    "    a = Dense(32, activation='relu')(grl)\n",
    "    a = BatchNormalization()(a)\n",
    "    S_pred = Dense(2, activation='softmax', name=\"S_pred\")(a)\n",
    "\n",
    "    # Decoder branch: combine pseudo_Y and S to predict observed Y.\n",
    "    concat = Concatenate()([pseudo_Y, S_input])\n",
    "    d = Dense(16, activation='relu')(concat)\n",
    "    d = BatchNormalization()(d)\n",
    "    Y_pred = Dense(1, activation='sigmoid', name=\"Y_pred\")(d)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[X_input, S_input],\n",
    "                           outputs=[pseudo_Y, S_pred, Y_pred])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  loss={\"pseudo_Y\": \"binary_crossentropy\",\n",
    "                        \"S_pred\": \"categorical_crossentropy\",\n",
    "                        \"Y_pred\": \"binary_crossentropy\"},\n",
    "                  loss_weights={\"pseudo_Y\": 1.0, \"S_pred\": lambda_adv, \"Y_pred\": 1.0},\n",
    "                  metrics={\"pseudo_Y\": \"accuracy\",\n",
    "                           \"S_pred\": \"accuracy\",\n",
    "                           \"Y_pred\": \"accuracy\"})\n",
    "    return model\n",
    "\n",
    "# -------------------------------\n",
    "# Manual Fairness Metrics\n",
    "# -------------------------------\n",
    "def compute_fairness_metrics_manual(y_true, y_pred, sensitive_features):\n",
    "    \"\"\"\n",
    "    Compute fairness metrics manually.\n",
    "    y_true: binary ground-truth labels (1-D numpy array).\n",
    "    y_pred: continuous scores (will be thresholded at 0.5).\n",
    "    sensitive_features: 1-D numpy array (0 or 1).\n",
    "\n",
    "    Returns a dictionary with:\n",
    "      - Demographic parity difference (absolute difference in positive rates).\n",
    "      - Equalized odds difference (average difference in TPR and FPR).\n",
    "      - Selection rates per group.\n",
    "      - Group-wise accuracy.\n",
    "    \"\"\"\n",
    "    y_pred_bin = (y_pred > 0.5).astype(int)\n",
    "    groups = np.unique(sensitive_features)\n",
    "\n",
    "    # Demographic parity\n",
    "    pos_rates = {}\n",
    "    for g in groups:\n",
    "        pos_rates[g] = np.mean(y_pred_bin[sensitive_features == g])\n",
    "    dp_diff = abs(pos_rates[0] - pos_rates[1])\n",
    "\n",
    "    # Equalized odds\n",
    "    metrics = {}\n",
    "    for g in groups:\n",
    "        mask = (sensitive_features == g)\n",
    "        y_true_g = y_true[mask]\n",
    "        y_pred_g = y_pred_bin[mask]\n",
    "        tpr = np.sum((y_pred_g == 1) & (y_true_g == 1)) / (np.sum(y_true_g == 1) + 1e-8)\n",
    "        fpr = np.sum((y_pred_g == 1) & (y_true_g == 0)) / (np.sum(y_true_g == 0) + 1e-8)\n",
    "        metrics[g] = (tpr, fpr)\n",
    "    eo_diff = (abs(metrics[0][0] - metrics[1][0]) + abs(metrics[0][1] - metrics[1][1])) / 2\n",
    "\n",
    "    # Selection rate per group.\n",
    "    sel_rate = {}\n",
    "    for g in groups:\n",
    "        sel_rate[g] = pos_rates[g]\n",
    "\n",
    "    # Group-wise accuracy.\n",
    "    group_acc = {}\n",
    "    for g in groups:\n",
    "        mask = (sensitive_features == g)\n",
    "        group_acc[g] = accuracy_score(y_true[mask], y_pred_bin[mask])\n",
    "\n",
    "    return {\n",
    "        \"demographic_parity_difference\": dp_diff,\n",
    "        \"equalized_odds_difference\": eo_diff,\n",
    "        \"selection_rate\": sel_rate,\n",
    "        \"group_accuracy\": group_acc\n",
    "    }\n",
    "\n",
    "# -------------------------------\n",
    "# Plotting Function\n",
    "# -------------------------------\n",
    "def plot_comparison(metrics_baseline, metrics_fair):\n",
    "    models = ['Baseline', 'Fair']\n",
    "    aucs = [metrics_baseline['auc'], metrics_fair['auc']]\n",
    "    accs = [metrics_baseline['accuracy'], metrics_fair['accuracy']]\n",
    "    dp_diff = [metrics_baseline[\"demographic_parity_difference\"], metrics_fair[\"demographic_parity_difference\"]]\n",
    "    eo_diff = [metrics_baseline[\"equalized_odds_difference\"], metrics_fair[\"equalized_odds_difference\"]]\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    axs[0,0].bar(models, aucs, color=['blue', 'green'])\n",
    "    axs[0,0].set_title('AUC')\n",
    "    axs[0,0].set_ylim([0, 1])\n",
    "\n",
    "    axs[0,1].bar(models, accs, color=['blue', 'green'])\n",
    "    axs[0,1].set_title('Accuracy')\n",
    "    axs[0,1].set_ylim([0, 1])\n",
    "\n",
    "    axs[1,0].bar(models, dp_diff, color=['orange', 'purple'])\n",
    "    axs[1,0].set_title('Demographic Parity Difference')\n",
    "\n",
    "    axs[1,1].bar(models, eo_diff, color=['orange', 'purple'])\n",
    "    axs[1,1].set_title('Equalized Odds Difference')\n",
    "\n",
    "    plt.suptitle(\"Comparison: Baseline (X → Y) vs. Fair (X → Y') Model\")\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# Main Function: Comparison and Visualization\n",
    "# -------------------------------\n",
    "def main(data_url, lambda_adv=1.0):\n",
    "    set_seed(42)\n",
    "\n",
    "    print(\"Loading and preprocessing Adult data...\")\n",
    "    X, Y_obs, S = load_and_preprocess_adult_data(data_url)\n",
    "    X_train, X_test, Y_train_obs, Y_test_obs, S_train, S_test = train_test_split(\n",
    "        X, Y_obs, S, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"Features shape: {X.shape}\")\n",
    "    print(f\"Observed Label Y shape: {Y_obs.shape}   (Label from 'income')\")\n",
    "    print(f\"Sensitive Attribute (Sex) shape: {S.shape}\")\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "\n",
    "    # One-hot encode S for adversarial model training.\n",
    "    S_train_oh = tf.keras.utils.to_categorical(S_train, num_classes=2)\n",
    "    S_test_oh  = tf.keras.utils.to_categorical(S_test, num_classes=2)\n",
    "\n",
    "    ### 1. Train adversarial debiasing model (X → Y' with adversary)\n",
    "    print(\"\\nTraining adversarial model (X → Y' with adversary) ...\")\n",
    "    adv_model = build_adversarial_model(input_dim, lambda_adv=lambda_adv)\n",
    "    # For training, we use the observed Y as target for both pseudo_Y and Y_pred.\n",
    "    # Reshape Y_obs to (-1,1) since our outputs are scalars.\n",
    "    Y_train_obs_exp = Y_train_obs.reshape(-1, 1)\n",
    "    Y_test_obs_exp  = Y_test_obs.reshape(-1, 1)\n",
    "    adv_model.fit([X_train, S_train_oh],\n",
    "                  {\"pseudo_Y\": Y_train_obs_exp, \"S_pred\": S_train_oh, \"Y_pred\": Y_train_obs_exp},\n",
    "                  epochs=30, batch_size=128, verbose=1)\n",
    "\n",
    "    # Get pseudo-label predictions.\n",
    "    pseudo_Y_train, _, _ = adv_model.predict([X_train, S_train_oh])\n",
    "    pseudo_Y_test,  _, _ = adv_model.predict([X_test, S_test_oh])\n",
    "\n",
    "    # Threshold pseudo-labels to get binary labels.\n",
    "    pseudo_Y_train_bin = (pseudo_Y_train > 0.5).astype(np.float32)\n",
    "    pseudo_Y_test_bin  = (pseudo_Y_test > 0.5).astype(np.float32)\n",
    "\n",
    "    print(\"\\nPseudo-label statistics (training):\")\n",
    "    for g in np.unique(S_train):\n",
    "        mask = (S_train == g)\n",
    "        print(f\"Group {g} pseudo-positive rate: {np.mean(pseudo_Y_train_bin[mask]):.4f}\")\n",
    "\n",
    "    ### 2. Train baseline logistic regression model on observed Y (X → Y)\n",
    "    print(\"\\nTraining baseline logistic regression classifier (X → Y)...\")\n",
    "    baseline_clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "    baseline_clf.fit(X_train, Y_train_obs)\n",
    "    baseline_preds = baseline_clf.predict_proba(X_test)[:, 1]\n",
    "    baseline_auc = roc_auc_score(Y_test_obs, baseline_preds)\n",
    "    baseline_acc = accuracy_score(Y_test_obs, (baseline_preds > 0.5).astype(int))\n",
    "    baseline_fairness = compute_fairness_metrics_manual(Y_test_obs, baseline_preds, sensitive_features=S_test)\n",
    "\n",
    "    ### 3. Train fair logistic regression model on pseudo-labels (X → Y')\n",
    "    print(\"\\nTraining fair logistic regression classifier (X → Y') using pseudo-labels...\")\n",
    "    fair_clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "    fair_clf.fit(X_train, pseudo_Y_train_bin.ravel())\n",
    "    fair_preds = fair_clf.predict_proba(X_test)[:, 1]\n",
    "    fair_auc = roc_auc_score(Y_test_obs, fair_preds)\n",
    "    fair_acc = accuracy_score(Y_test_obs, (fair_preds > 0.5).astype(int))\n",
    "    fair_fairness = compute_fairness_metrics_manual(Y_test_obs, fair_preds, sensitive_features=S_test)\n",
    "\n",
    "    # Aggregate metrics for plotting.\n",
    "    metrics_baseline = {\n",
    "        \"auc\": baseline_auc,\n",
    "        \"accuracy\": baseline_acc,\n",
    "        \"demographic_parity_difference\": baseline_fairness[\"demographic_parity_difference\"],\n",
    "        \"equalized_odds_difference\": baseline_fairness[\"equalized_odds_difference\"]\n",
    "    }\n",
    "    metrics_fair = {\n",
    "        \"auc\": fair_auc,\n",
    "        \"accuracy\": fair_acc,\n",
    "        \"demographic_parity_difference\": fair_fairness[\"demographic_parity_difference\"],\n",
    "        \"equalized_odds_difference\": fair_fairness[\"equalized_odds_difference\"]\n",
    "    }\n",
    "\n",
    "    print(\"\\nBaseline Logistic Regression (X → Y) Evaluation:\")\n",
    "    print(f\"AUC: {baseline_auc:.4f}, Accuracy: {baseline_acc:.4f}\")\n",
    "    print(\"Fairness metrics:\", baseline_fairness)\n",
    "\n",
    "    print(\"\\nFair Logistic Regression (X → Y') Evaluation (compared to observed Y):\")\n",
    "    print(f\"AUC: {fair_auc:.4f}, Accuracy: {fair_acc:.4f}\")\n",
    "    print(\"Fairness metrics:\", fair_fairness)\n",
    "\n",
    "    # Plot comparison.\n",
    "    plot_comparison(metrics_baseline, metrics_fair)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    adult_data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "    main(adult_data_url, lambda_adv=5.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_Ax_NVyoEVUT",
    "outputId": "695d0101-385b-4ee6-f6fe-88bbacedcfa2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# -------------------------------\n",
    "# Custom Gradient Reversal Layer\n",
    "# -------------------------------\n",
    "@tf.custom_gradient\n",
    "def grad_reverse(x, lambda_):\n",
    "    def grad(dy):\n",
    "        return -lambda_ * dy, None\n",
    "    return x, grad\n",
    "\n",
    "class GradientReversalLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, lambda_=1.0, **kwargs):\n",
    "        super(GradientReversalLayer, self).__init__(**kwargs)\n",
    "        self.lambda_ = lambda_\n",
    "    def call(self, x):\n",
    "        return grad_reverse(x, self.lambda_)\n",
    "\n",
    "# -------------------------------\n",
    "# Data Loading and Preprocessing for German Credit Data\n",
    "# -------------------------------\n",
    "def set_seed(seed_num):\n",
    "    random.seed(seed_num)\n",
    "    np.random.seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_num)\n",
    "\n",
    "def load_and_preprocess_german_data(data_url):\n",
    "    \"\"\"\n",
    "    Download and preprocess the German Credit dataset.\n",
    "\n",
    "    We assume the dataset has 21 columns.\n",
    "\n",
    "    Features (X): Use only:\n",
    "        \"duration\", \"credit_amount\", \"inst_rate\"\n",
    "    Observed Label (Y): from \"target\". In many versions, target is coded as 1 for good and 2 for bad.\n",
    "        We recode: good (1) -> 1, bad (2) -> 0.\n",
    "    Protected Attribute (S): Use the \"age\" column.\n",
    "        We binarize age by computing the median and setting S = 1 if age >= median (older), else 0.\n",
    "    \"\"\"\n",
    "    col_names = [\"chk_status\", \"duration\", \"credit_history\", \"purpose\", \"credit_amount\",\n",
    "                 \"savings\", \"employment\", \"inst_rate\", \"personal_status_sex\", \"other_debtors\",\n",
    "                 \"residence_since\", \"property\", \"age\", \"other_installment_plans\", \"housing\",\n",
    "                 \"num_credits\", \"job\", \"num_dependents\", \"telephone\", \"foreign_worker\", \"target\"]\n",
    "    data = pd.read_csv(data_url, header=None, names=col_names, sep=' ', engine='python')\n",
    "\n",
    "    # Features: use only duration, credit_amount, and inst_rate.\n",
    "    feature_cols = [\"duration\", \"credit_amount\", \"inst_rate\"]\n",
    "    X = data[feature_cols].copy().astype(np.float32)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X.values)\n",
    "\n",
    "    # Observed label: target. Recode so that 1 -> 1 (good) and 2 -> 0 (bad)\n",
    "    Y = data[\"target\"].values\n",
    "    Y = np.where(Y == 1, 1, 0)\n",
    "\n",
    "    # Protected attribute: use age.\n",
    "    # Convert age to float and then binarize by the median.\n",
    "    age_vals = data[\"age\"].astype(np.float32).values\n",
    "    median_age = np.median(age_vals)\n",
    "    S = (age_vals >= median_age).astype(np.int32)\n",
    "\n",
    "    return X, Y, S\n",
    "\n",
    "# -------------------------------\n",
    "# Adversarial Debiasing Model\n",
    "# -------------------------------\n",
    "def build_adversarial_model(input_dim, lambda_adv=1.0):\n",
    "    \"\"\"\n",
    "    Build an adversarial debiasing model that learns pseudo‑labels Y' from X.\n",
    "\n",
    "    Architecture:\n",
    "      - Encoder branch: from X, dense layers produce pseudo_Y (scalar via sigmoid).\n",
    "      - Adversary branch: applies a Gradient Reversal Layer on pseudo_Y and predicts S (2-class softmax).\n",
    "      - Decoder branch: concatenates pseudo_Y and S (one-hot) to predict the observed label Y.\n",
    "\n",
    "    Returns a compiled Keras model that takes inputs [X, S_onehot] and outputs [pseudo_Y, S_pred, Y_pred].\n",
    "    \"\"\"\n",
    "    X_input = tf.keras.Input(shape=(input_dim,), name=\"X\")\n",
    "    S_input = tf.keras.Input(shape=(2,), name=\"S\")  # S one-hot encoded\n",
    "\n",
    "    # Encoder branch.\n",
    "    h = tf.keras.layers.Dense(64, activation='relu')(X_input)\n",
    "    h = tf.keras.layers.BatchNormalization()(h)\n",
    "    h = tf.keras.layers.Dense(32, activation='relu')(h)\n",
    "    h = tf.keras.layers.BatchNormalization()(h)\n",
    "    pseudo_Y = tf.keras.layers.Dense(1, activation='sigmoid', name=\"pseudo_Y\")(h)\n",
    "\n",
    "    # Adversary branch.\n",
    "    grl = GradientReversalLayer(lambda_=lambda_adv)(pseudo_Y)\n",
    "    a = tf.keras.layers.Dense(32, activation='relu')(grl)\n",
    "    a = tf.keras.layers.BatchNormalization()(a)\n",
    "    S_pred = tf.keras.layers.Dense(2, activation='softmax', name=\"S_pred\")(a)\n",
    "\n",
    "    # Decoder branch.\n",
    "    concat = tf.keras.layers.Concatenate()([pseudo_Y, S_input])\n",
    "    d = tf.keras.layers.Dense(16, activation='relu')(concat)\n",
    "    d = tf.keras.layers.BatchNormalization()(d)\n",
    "    Y_pred = tf.keras.layers.Dense(1, activation='sigmoid', name=\"Y_pred\")(d)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[X_input, S_input],\n",
    "                           outputs=[pseudo_Y, S_pred, Y_pred])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  loss={\"pseudo_Y\": \"binary_crossentropy\",\n",
    "                        \"S_pred\": \"categorical_crossentropy\",\n",
    "                        \"Y_pred\": \"binary_crossentropy\"},\n",
    "                  loss_weights={\"pseudo_Y\": 1.0, \"S_pred\": lambda_adv, \"Y_pred\": 1.0},\n",
    "                  metrics={\"pseudo_Y\": \"accuracy\",\n",
    "                           \"S_pred\": \"accuracy\",\n",
    "                           \"Y_pred\": \"accuracy\"})\n",
    "    return model\n",
    "\n",
    "# -------------------------------\n",
    "# Manual Fairness Metrics\n",
    "# -------------------------------\n",
    "def compute_fairness_metrics_manual(y_true, y_pred, sensitive_features):\n",
    "    \"\"\"\n",
    "    Compute fairness metrics manually.\n",
    "    y_true: binary ground-truth labels.\n",
    "    y_pred: continuous scores (thresholded at 0.5 for binary predictions).\n",
    "    sensitive_features: 1-D numpy array (e.g., 0 or 1).\n",
    "\n",
    "    Returns a dictionary with:\n",
    "      - Demographic parity difference.\n",
    "      - Equalized odds difference.\n",
    "      - Selection rates per group.\n",
    "      - Group-wise accuracy.\n",
    "    \"\"\"\n",
    "    y_pred_bin = (y_pred > 0.5).astype(int)\n",
    "    groups = np.unique(sensitive_features)\n",
    "\n",
    "    pos_rates = {}\n",
    "    for g in groups:\n",
    "        pos_rates[g] = np.mean(y_pred_bin[sensitive_features == g])\n",
    "    dp_diff = abs(pos_rates[0] - pos_rates[1])\n",
    "\n",
    "    metrics = {}\n",
    "    for g in groups:\n",
    "        mask = (sensitive_features == g)\n",
    "        y_true_g = y_true[mask]\n",
    "        y_pred_g = y_pred_bin[mask]\n",
    "        tpr = np.sum((y_pred_g == 1) & (y_true_g == 1)) / (np.sum(y_true_g == 1) + 1e-8)\n",
    "        fpr = np.sum((y_pred_g == 1) & (y_true_g == 0)) / (np.sum(y_true_g == 0) + 1e-8)\n",
    "        metrics[g] = (tpr, fpr)\n",
    "    eo_diff = (abs(metrics[0][0] - metrics[1][0]) + abs(metrics[0][1] - metrics[1][1])) / 2\n",
    "\n",
    "    sel_rate = {}\n",
    "    for g in groups:\n",
    "        sel_rate[g] = pos_rates[g]\n",
    "\n",
    "    group_acc = {}\n",
    "    for g in groups:\n",
    "        mask = (sensitive_features == g)\n",
    "        group_acc[g] = accuracy_score(y_true[mask], y_pred_bin[mask])\n",
    "\n",
    "    return {\n",
    "        \"demographic_parity_difference\": dp_diff,\n",
    "        \"equalized_odds_difference\": eo_diff,\n",
    "        \"selection_rate\": sel_rate,\n",
    "        \"group_accuracy\": group_acc\n",
    "    }\n",
    "\n",
    "# -------------------------------\n",
    "# Plotting Function\n",
    "# -------------------------------\n",
    "def plot_comparison(metrics_baseline, metrics_fair):\n",
    "    models = ['Baseline', 'Fair']\n",
    "    aucs = [metrics_baseline['auc'], metrics_fair['auc']]\n",
    "    accs = [metrics_baseline['accuracy'], metrics_fair['accuracy']]\n",
    "    dp_diff = [metrics_baseline[\"demographic_parity_difference\"], metrics_fair[\"demographic_parity_difference\"]]\n",
    "    eo_diff = [metrics_baseline[\"equalized_odds_difference\"], metrics_fair[\"equalized_odds_difference\"]]\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    axs[0,0].bar(models, aucs, color=['blue', 'green'])\n",
    "    axs[0,0].set_title('AUC')\n",
    "    axs[0,0].set_ylim([0, 1])\n",
    "\n",
    "    axs[0,1].bar(models, accs, color=['blue', 'green'])\n",
    "    axs[0,1].set_title('Accuracy')\n",
    "    axs[0,1].set_ylim([0, 1])\n",
    "\n",
    "    axs[1,0].bar(models, dp_diff, color=['orange', 'purple'])\n",
    "    axs[1,0].set_title('Demographic Parity Difference')\n",
    "\n",
    "    axs[1,1].bar(models, eo_diff, color=['orange', 'purple'])\n",
    "    axs[1,1].set_title('Equalized Odds Difference')\n",
    "\n",
    "    plt.suptitle(\"Comparison: Baseline (X → Y) vs. Fair (X → Y') Model\")\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# Main Function: German Data Comparison using Age as Protected Attribute\n",
    "# -------------------------------\n",
    "def main(data_url, lambda_adv=1.0):\n",
    "    set_seed(42)\n",
    "\n",
    "    print(\"Loading and preprocessing German Credit data...\")\n",
    "    X, Y_obs, S_raw = load_and_preprocess_german_data(data_url)\n",
    "    # S_raw is the raw age value (continuous). Binarize it using median.\n",
    "    median_age = np.median(S_raw.astype(np.float32))\n",
    "    S = (S_raw.astype(np.float32) >= median_age).astype(np.int32)\n",
    "\n",
    "    X_train, X_test, Y_train_obs, Y_test_obs, S_train, S_test = train_test_split(\n",
    "        X, Y_obs, S, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"Features shape: {X.shape}\")\n",
    "    print(f\"Observed Label Y shape: {Y_obs.shape}   (Credit risk: 1=good, 0=bad)\")\n",
    "    print(f\"Sensitive Attribute (Age, binarized) shape: {S.shape}\")\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "\n",
    "    # One-hot encode S for the adversarial model.\n",
    "    S_train_oh = tf.keras.utils.to_categorical(S_train, num_classes=2)\n",
    "    S_test_oh  = tf.keras.utils.to_categorical(S_test, num_classes=2)\n",
    "\n",
    "    ### 1. Train adversarial debiasing model on German data.\n",
    "    print(\"\\nTraining adversarial model (X → Y' with adversary) ...\")\n",
    "    adv_model = build_adversarial_model(input_dim, lambda_adv=lambda_adv)\n",
    "    # Reshape observed Y to (-1,1)\n",
    "    Y_train_obs_exp = Y_train_obs.reshape(-1, 1)\n",
    "    Y_test_obs_exp  = Y_test_obs.reshape(-1, 1)\n",
    "\n",
    "    adv_model.fit([X_train, S_train_oh],\n",
    "                  {\"pseudo_Y\": Y_train_obs_exp, \"S_pred\": S_train_oh, \"Y_pred\": Y_train_obs_exp},\n",
    "                  epochs=30, batch_size=128, verbose=1)\n",
    "\n",
    "    # Get pseudo-label predictions.\n",
    "    pseudo_Y_train, _, _ = adv_model.predict([X_train, S_train_oh])\n",
    "    pseudo_Y_test,  _, _ = adv_model.predict([X_test, S_test_oh])\n",
    "\n",
    "    # Threshold to get binary pseudo-labels.\n",
    "    pseudo_Y_train_bin = (pseudo_Y_train > 0.5).astype(np.float32)\n",
    "    pseudo_Y_test_bin  = (pseudo_Y_test > 0.5).astype(np.float32)\n",
    "\n",
    "    print(\"\\nPseudo-label statistics (training):\")\n",
    "    for g in np.unique(S_train):\n",
    "        mask = (S_train == g)\n",
    "        print(f\"Group {g} pseudo-positive rate: {np.mean(pseudo_Y_train_bin[mask]):.4f}\")\n",
    "\n",
    "    ### 2. Train baseline logistic regression classifier (X → Y)\n",
    "    print(\"\\nTraining baseline logistic regression classifier (X → Y)...\")\n",
    "    baseline_clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "    baseline_clf.fit(X_train, Y_train_obs)\n",
    "    baseline_preds = baseline_clf.predict_proba(X_test)[:, 1]\n",
    "    baseline_auc = roc_auc_score(Y_test_obs, baseline_preds)\n",
    "    baseline_acc = accuracy_score(Y_test_obs, (baseline_preds > 0.5).astype(int))\n",
    "    baseline_fairness = compute_fairness_metrics_manual(Y_test_obs, baseline_preds, sensitive_features=S_test)\n",
    "\n",
    "    ### 3. Train fair logistic regression classifier on pseudo‑labels (X → Y')\n",
    "    print(\"\\nTraining fair logistic regression classifier (X → Y') using pseudo-labels...\")\n",
    "    fair_clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "    fair_clf.fit(X_train, pseudo_Y_train_bin.ravel())\n",
    "    fair_preds = fair_clf.predict_proba(X_test)[:, 1]\n",
    "    fair_auc = roc_auc_score(Y_test_obs, fair_preds)\n",
    "    fair_acc = accuracy_score(Y_test_obs, (fair_preds > 0.5).astype(int))\n",
    "    fair_fairness = compute_fairness_metrics_manual(Y_test_obs, fair_preds, sensitive_features=S_test)\n",
    "\n",
    "    # Aggregate metrics.\n",
    "    metrics_baseline = {\n",
    "        \"auc\": baseline_auc,\n",
    "        \"accuracy\": baseline_acc,\n",
    "        \"demographic_parity_difference\": baseline_fairness[\"demographic_parity_difference\"],\n",
    "        \"equalized_odds_difference\": baseline_fairness[\"equalized_odds_difference\"]\n",
    "    }\n",
    "    metrics_fair = {\n",
    "        \"auc\": fair_auc,\n",
    "        \"accuracy\": fair_acc,\n",
    "        \"demographic_parity_difference\": fair_fairness[\"demographic_parity_difference\"],\n",
    "        \"equalized_odds_difference\": fair_fairness[\"equalized_odds_difference\"]\n",
    "    }\n",
    "\n",
    "    print(\"\\nBaseline Logistic Regression (X → Y) Evaluation:\")\n",
    "    print(f\"AUC: {baseline_auc:.4f}, Accuracy: {baseline_acc:.4f}\")\n",
    "    print(\"Fairness metrics:\", baseline_fairness)\n",
    "\n",
    "    print(\"\\nFair Logistic Regression (X → Y') Evaluation (compared to observed Y):\")\n",
    "    print(f\"AUC: {fair_auc:.4f}, Accuracy: {fair_acc:.4f}\")\n",
    "    print(\"Fairness metrics:\", fair_fairness)\n",
    "\n",
    "    # Plot comparisons.\n",
    "    plot_comparison(metrics_baseline, metrics_fair)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    german_data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"\n",
    "    main(german_data_url, lambda_adv=15.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IN6xM3nM1YL0",
    "outputId": "ca719a37-80ac-4b74-8d68-308f7eecf4f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing COMPAS data...\n",
      "Features shape: (7214, 5)\n",
      "Observed Label Y shape: (7214,)   (Recidivism: 1=recid, 0=non-recid)\n",
      "Sensitive Attribute (Race, binarized) shape: (7214,)\n",
      "\n",
      "Training adversarial model (X → Y' with adversary) ...\n",
      "Epoch 1/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - S_pred_accuracy: 0.4345 - S_pred_loss: 0.7993 - Y_pred_accuracy: 0.4909 - Y_pred_loss: 0.9218 - loss: 4.1629 - pseudo_Y_accuracy: 0.5783 - pseudo_Y_loss: 0.7626\n",
      "Epoch 2/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - S_pred_accuracy: 0.4059 - S_pred_loss: 0.7977 - Y_pred_accuracy: 0.5077 - Y_pred_loss: 0.8320 - loss: 4.0229 - pseudo_Y_accuracy: 0.6225 - pseudo_Y_loss: 0.7174\n",
      "Epoch 3/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - S_pred_accuracy: 0.4024 - S_pred_loss: 0.7642 - Y_pred_accuracy: 0.5212 - Y_pred_loss: 0.7691 - loss: 3.8297 - pseudo_Y_accuracy: 0.6317 - pseudo_Y_loss: 0.6913\n",
      "Epoch 4/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - S_pred_accuracy: 0.3935 - S_pred_loss: 0.7315 - Y_pred_accuracy: 0.5577 - Y_pred_loss: 0.7271 - loss: 3.6663 - pseudo_Y_accuracy: 0.6465 - pseudo_Y_loss: 0.6714\n",
      "Epoch 5/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - S_pred_accuracy: 0.4066 - S_pred_loss: 0.7062 - Y_pred_accuracy: 0.6192 - Y_pred_loss: 0.6964 - loss: 3.5425 - pseudo_Y_accuracy: 0.6554 - pseudo_Y_loss: 0.6571\n",
      "Epoch 6/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - S_pred_accuracy: 0.5357 - S_pred_loss: 0.6885 - Y_pred_accuracy: 0.6484 - Y_pred_loss: 0.6733 - loss: 3.4539 - pseudo_Y_accuracy: 0.6623 - pseudo_Y_loss: 0.6467\n",
      "Epoch 7/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - S_pred_accuracy: 0.6153 - S_pred_loss: 0.6771 - Y_pred_accuracy: 0.6557 - Y_pred_loss: 0.6568 - loss: 3.3945 - pseudo_Y_accuracy: 0.6678 - pseudo_Y_loss: 0.6392\n",
      "Epoch 8/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - S_pred_accuracy: 0.6160 - S_pred_loss: 0.6708 - Y_pred_accuracy: 0.6587 - Y_pred_loss: 0.6458 - loss: 3.3588 - pseudo_Y_accuracy: 0.6687 - pseudo_Y_loss: 0.6341\n",
      "Epoch 9/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - S_pred_accuracy: 0.6160 - S_pred_loss: 0.6686 - Y_pred_accuracy: 0.6565 - Y_pred_loss: 0.6400 - loss: 3.3443 - pseudo_Y_accuracy: 0.6672 - pseudo_Y_loss: 0.6323\n",
      "Epoch 10/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - S_pred_accuracy: 0.6076 - S_pred_loss: 0.6706 - Y_pred_accuracy: 0.6529 - Y_pred_loss: 0.6415 - loss: 3.3559 - pseudo_Y_accuracy: 0.6644 - pseudo_Y_loss: 0.6361\n",
      "Epoch 11/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - S_pred_accuracy: 0.5840 - S_pred_loss: 0.6778 - Y_pred_accuracy: 0.6285 - Y_pred_loss: 0.6556 - loss: 3.4063 - pseudo_Y_accuracy: 0.6484 - pseudo_Y_loss: 0.6501\n",
      "Epoch 12/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - S_pred_accuracy: 0.5198 - S_pred_loss: 0.6890 - Y_pred_accuracy: 0.5864 - Y_pred_loss: 0.6773 - loss: 3.4896 - pseudo_Y_accuracy: 0.5959 - pseudo_Y_loss: 0.6771\n",
      "Epoch 13/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - S_pred_accuracy: 0.4973 - S_pred_loss: 0.6970 - Y_pred_accuracy: 0.5543 - Y_pred_loss: 0.6913 - loss: 3.5580 - pseudo_Y_accuracy: 0.5435 - pseudo_Y_loss: 0.7065\n",
      "Epoch 14/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - S_pred_accuracy: 0.4893 - S_pred_loss: 0.6982 - Y_pred_accuracy: 0.5474 - Y_pred_loss: 0.6924 - loss: 3.5735 - pseudo_Y_accuracy: 0.5265 - pseudo_Y_loss: 0.7169\n",
      "Epoch 15/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - S_pred_accuracy: 0.4891 - S_pred_loss: 0.6967 - Y_pred_accuracy: 0.5727 - Y_pred_loss: 0.6861 - loss: 3.5565 - pseudo_Y_accuracy: 0.5190 - pseudo_Y_loss: 0.7107\n",
      "Epoch 16/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - S_pred_accuracy: 0.4905 - S_pred_loss: 0.6950 - Y_pred_accuracy: 0.5912 - Y_pred_loss: 0.6778 - loss: 3.5300 - pseudo_Y_accuracy: 0.5249 - pseudo_Y_loss: 0.6980\n",
      "Epoch 17/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - S_pred_accuracy: 0.4979 - S_pred_loss: 0.6935 - Y_pred_accuracy: 0.6016 - Y_pred_loss: 0.6689 - loss: 3.5022 - pseudo_Y_accuracy: 0.5423 - pseudo_Y_loss: 0.6834\n",
      "Epoch 18/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - S_pred_accuracy: 0.4997 - S_pred_loss: 0.6924 - Y_pred_accuracy: 0.6100 - Y_pred_loss: 0.6609 - loss: 3.4776 - pseudo_Y_accuracy: 0.5715 - pseudo_Y_loss: 0.6702\n",
      "Epoch 19/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - S_pred_accuracy: 0.5024 - S_pred_loss: 0.6914 - Y_pred_accuracy: 0.6182 - Y_pred_loss: 0.6555 - loss: 3.4606 - pseudo_Y_accuracy: 0.5910 - pseudo_Y_loss: 0.6619\n",
      "Epoch 20/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - S_pred_accuracy: 0.5028 - S_pred_loss: 0.6909 - Y_pred_accuracy: 0.6239 - Y_pred_loss: 0.6534 - loss: 3.4547 - pseudo_Y_accuracy: 0.5984 - pseudo_Y_loss: 0.6597\n",
      "Epoch 21/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - S_pred_accuracy: 0.4973 - S_pred_loss: 0.6916 - Y_pred_accuracy: 0.6175 - Y_pred_loss: 0.6550 - loss: 3.4628 - pseudo_Y_accuracy: 0.5764 - pseudo_Y_loss: 0.6638\n",
      "Epoch 22/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - S_pred_accuracy: 0.4927 - S_pred_loss: 0.6930 - Y_pred_accuracy: 0.6126 - Y_pred_loss: 0.6585 - loss: 3.4772 - pseudo_Y_accuracy: 0.5646 - pseudo_Y_loss: 0.6704\n",
      "Epoch 23/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - S_pred_accuracy: 0.4880 - S_pred_loss: 0.6939 - Y_pred_accuracy: 0.6085 - Y_pred_loss: 0.6610 - loss: 3.4864 - pseudo_Y_accuracy: 0.5563 - pseudo_Y_loss: 0.6746\n",
      "Epoch 24/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - S_pred_accuracy: 0.4925 - S_pred_loss: 0.6938 - Y_pred_accuracy: 0.6079 - Y_pred_loss: 0.6601 - loss: 3.4833 - pseudo_Y_accuracy: 0.5615 - pseudo_Y_loss: 0.6727\n",
      "Epoch 25/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - S_pred_accuracy: 0.4953 - S_pred_loss: 0.6931 - Y_pred_accuracy: 0.6139 - Y_pred_loss: 0.6564 - loss: 3.4712 - pseudo_Y_accuracy: 0.5758 - pseudo_Y_loss: 0.6663\n",
      "Epoch 26/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - S_pred_accuracy: 0.4970 - S_pred_loss: 0.6924 - Y_pred_accuracy: 0.6173 - Y_pred_loss: 0.6524 - loss: 3.4590 - pseudo_Y_accuracy: 0.5900 - pseudo_Y_loss: 0.6603\n",
      "Epoch 27/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - S_pred_accuracy: 0.4993 - S_pred_loss: 0.6921 - Y_pred_accuracy: 0.6211 - Y_pred_loss: 0.6505 - loss: 3.4540 - pseudo_Y_accuracy: 0.5956 - pseudo_Y_loss: 0.6581\n",
      "Epoch 28/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - S_pred_accuracy: 0.4949 - S_pred_loss: 0.6925 - Y_pred_accuracy: 0.6210 - Y_pred_loss: 0.6511 - loss: 3.4582 - pseudo_Y_accuracy: 0.5877 - pseudo_Y_loss: 0.6604\n",
      "Epoch 29/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - S_pred_accuracy: 0.4908 - S_pred_loss: 0.6932 - Y_pred_accuracy: 0.6192 - Y_pred_loss: 0.6528 - loss: 3.4653 - pseudo_Y_accuracy: 0.5773 - pseudo_Y_loss: 0.6638\n",
      "Epoch 30/30\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - S_pred_accuracy: 0.4912 - S_pred_loss: 0.6934 - Y_pred_accuracy: 0.6177 - Y_pred_loss: 0.6531 - loss: 3.4668 - pseudo_Y_accuracy: 0.5744 - pseudo_Y_loss: 0.6643\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Pseudo‑label statistics (training):\n",
      "Group 0 pseudo‑positive rate: 0.4348\n",
      "Group 1 pseudo‑positive rate: 0.4550\n",
      "\n",
      "Training baseline logistic regression classifier (X → Y)...\n",
      "\n",
      "Training fair logistic regression classifier (X → Y') using pseudo‑labels...\n",
      "\n",
      "Baseline Logistic Regression (X → Y) Evaluation:\n",
      "AUC: 0.7372, Accuracy: 0.6992\n",
      "Fairness metrics: {'demographic_parity_difference': 0.22660777140749164, 'equalized_odds_difference': 0.18255760165519835, 'selection_rate': {0: 0.22893258426966293, 1: 0.45554035567715456}, 'group_accuracy': {0: 0.7036516853932584, 1: 0.6949384404924761}}\n",
      "\n",
      "Fair Logistic Regression (X → Y') Evaluation (compared to observed Y):\n",
      "AUC: 0.6035, Accuracy: 0.6279\n",
      "Fairness metrics: {'demographic_parity_difference': 0.09723289629413304, 'equalized_odds_difference': 0.07126715642954184, 'selection_rate': {0: 0.20646067415730338, 1: 0.3036935704514364}, 'group_accuracy': {0: 0.6615168539325843, 1: 0.5950752393980848}}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# -------------------------------\n",
    "# Custom Gradient Reversal Layer\n",
    "# -------------------------------\n",
    "@tf.custom_gradient\n",
    "def grad_reverse(x, lambda_):\n",
    "    def grad(dy):\n",
    "        return -lambda_ * dy, None\n",
    "    return x, grad\n",
    "\n",
    "class GradientReversalLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, lambda_=1.0, **kwargs):\n",
    "        super(GradientReversalLayer, self).__init__(**kwargs)\n",
    "        self.lambda_ = lambda_\n",
    "    def call(self, x):\n",
    "        return grad_reverse(x, self.lambda_)\n",
    "\n",
    "# -------------------------------\n",
    "# Data Loading and Preprocessing for COMPAS Data\n",
    "# -------------------------------\n",
    "def load_and_preprocess_compas_data(data_url):\n",
    "    \"\"\"\n",
    "    Download and preprocess the COMPAS dataset.\n",
    "\n",
    "    We assume the dataset contains, among others, the following columns:\n",
    "      - 'age'\n",
    "      - 'race'\n",
    "      - 'priors_count'\n",
    "      - 'juv_fel_count'\n",
    "      - 'juv_misd_count'\n",
    "      - 'juv_other_count'\n",
    "      - 'two_year_recid'\n",
    "\n",
    "    Features (X): We select a few numerical features.\n",
    "    Observed Label (Y): Use 'two_year_recid' as a binary label (0/1).\n",
    "    Protected Attribute (S): Use 'race'. Here we binarize race so that:\n",
    "         African‑American  → 1\n",
    "         all other races  → 0.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(data_url)\n",
    "    # Drop rows with missing values in the selected columns.\n",
    "    data = data.dropna(subset=[\"age\", \"race\", \"priors_count\", \"juv_fel_count\", \"juv_misd_count\", \"juv_other_count\", \"two_year_recid\"])\n",
    "\n",
    "    # Observed label: two_year_recid (already 0/1)\n",
    "    Y = data[\"two_year_recid\"].values\n",
    "\n",
    "    # Sensitive attribute: race. We set S=1 if race is African-American, else 0.\n",
    "    S = (data[\"race\"] == \"African-American\").astype(int).values\n",
    "\n",
    "    # Features: use a subset of numerical features.\n",
    "    feature_cols = [\"age\", \"priors_count\", \"juv_fel_count\", \"juv_misd_count\", \"juv_other_count\"]\n",
    "    X = data[feature_cols].copy().astype(np.float32)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X.values)\n",
    "\n",
    "    return X, Y, S\n",
    "\n",
    "# -------------------------------\n",
    "# Adversarial Debiasing Model\n",
    "# -------------------------------\n",
    "def build_adversarial_model(input_dim, lambda_adv=1.0):\n",
    "    \"\"\"\n",
    "    Build an adversarial debiasing model that learns pseudo‑labels Y' from X.\n",
    "\n",
    "    Architecture:\n",
    "      - Encoder branch: from X, dense layers produce pseudo_Y (scalar via sigmoid).\n",
    "      - Adversary branch: applies a Gradient Reversal Layer on pseudo_Y and predicts S (2-class softmax).\n",
    "      - Decoder branch: concatenates pseudo_Y and S (one-hot) to predict the observed label Y.\n",
    "    \"\"\"\n",
    "    X_input = tf.keras.Input(shape=(input_dim,), name=\"X\")\n",
    "    S_input = tf.keras.Input(shape=(2,), name=\"S\")  # S one-hot encoded\n",
    "\n",
    "    # Encoder branch.\n",
    "    h = tf.keras.layers.Dense(64, activation='relu')(X_input)\n",
    "    h = tf.keras.layers.BatchNormalization()(h)\n",
    "    h = tf.keras.layers.Dense(32, activation='relu')(h)\n",
    "    h = tf.keras.layers.BatchNormalization()(h)\n",
    "    pseudo_Y = tf.keras.layers.Dense(1, activation='sigmoid', name=\"pseudo_Y\")(h)\n",
    "\n",
    "    # Adversary branch.\n",
    "    grl = GradientReversalLayer(lambda_=lambda_adv)(pseudo_Y)\n",
    "    a = tf.keras.layers.Dense(32, activation='relu')(grl)\n",
    "    a = tf.keras.layers.BatchNormalization()(a)\n",
    "    S_pred = tf.keras.layers.Dense(2, activation='softmax', name=\"S_pred\")(a)\n",
    "\n",
    "    # Decoder branch.\n",
    "    concat = tf.keras.layers.Concatenate()([pseudo_Y, S_input])\n",
    "    d = tf.keras.layers.Dense(16, activation='relu')(concat)\n",
    "    d = tf.keras.layers.BatchNormalization()(d)\n",
    "    Y_pred = tf.keras.layers.Dense(1, activation='sigmoid', name=\"Y_pred\")(d)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[X_input, S_input],\n",
    "                           outputs=[pseudo_Y, S_pred, Y_pred])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  loss={\"pseudo_Y\": \"binary_crossentropy\",\n",
    "                        \"S_pred\": \"categorical_crossentropy\",\n",
    "                        \"Y_pred\": \"binary_crossentropy\"},\n",
    "                  loss_weights={\"pseudo_Y\": 1.0, \"S_pred\": lambda_adv, \"Y_pred\": 1.0},\n",
    "                  metrics={\"pseudo_Y\": \"accuracy\",\n",
    "                           \"S_pred\": \"accuracy\",\n",
    "                           \"Y_pred\": \"accuracy\"})\n",
    "    return model\n",
    "\n",
    "# -------------------------------\n",
    "# Manual Fairness Metrics\n",
    "# -------------------------------\n",
    "def compute_fairness_metrics_manual(y_true, y_pred, sensitive_features):\n",
    "    \"\"\"\n",
    "    Compute fairness metrics manually.\n",
    "    y_true: binary ground-truth labels.\n",
    "    y_pred: continuous scores (thresholded at 0.5 for binary predictions).\n",
    "    sensitive_features: 1-D numpy array (e.g., 0 or 1).\n",
    "\n",
    "    Returns a dictionary with:\n",
    "      - Demographic parity difference.\n",
    "      - Equalized odds difference.\n",
    "      - Selection rates per group.\n",
    "      - Group-wise accuracy.\n",
    "    \"\"\"\n",
    "    y_pred_bin = (y_pred > 0.5).astype(int)\n",
    "    groups = np.unique(sensitive_features)\n",
    "\n",
    "    pos_rates = {}\n",
    "    for g in groups:\n",
    "        pos_rates[g] = np.mean(y_pred_bin[sensitive_features == g])\n",
    "    dp_diff = abs(pos_rates[0] - pos_rates[1])\n",
    "\n",
    "    metrics = {}\n",
    "    for g in groups:\n",
    "        mask = (sensitive_features == g)\n",
    "        y_true_g = y_true[mask]\n",
    "        y_pred_g = y_pred_bin[mask]\n",
    "        tpr = np.sum((y_pred_g == 1) & (y_true_g == 1)) / (np.sum(y_true_g == 1) + 1e-8)\n",
    "        fpr = np.sum((y_pred_g == 1) & (y_true_g == 0)) / (np.sum(y_true_g == 0) + 1e-8)\n",
    "        metrics[g] = (tpr, fpr)\n",
    "    eo_diff = (abs(metrics[0][0] - metrics[1][0]) + abs(metrics[0][1] - metrics[1][1])) / 2\n",
    "\n",
    "    sel_rate = {}\n",
    "    for g in groups:\n",
    "        sel_rate[g] = pos_rates[g]\n",
    "\n",
    "    group_acc = {}\n",
    "    for g in groups:\n",
    "        mask = (sensitive_features == g)\n",
    "        group_acc[g] = accuracy_score(y_true[mask], y_pred_bin[mask])\n",
    "\n",
    "    return {\n",
    "        \"demographic_parity_difference\": dp_diff,\n",
    "        \"equalized_odds_difference\": eo_diff,\n",
    "        \"selection_rate\": sel_rate,\n",
    "        \"group_accuracy\": group_acc\n",
    "    }\n",
    "\n",
    "# -------------------------------\n",
    "# Plotting Function\n",
    "# -------------------------------\n",
    "def plot_comparison(metrics_baseline, metrics_fair):\n",
    "    models = ['Baseline', 'Fair']\n",
    "    aucs = [metrics_baseline['auc'], metrics_fair['auc']]\n",
    "    accs = [metrics_baseline['accuracy'], metrics_fair['accuracy']]\n",
    "    dp_diff = [metrics_baseline[\"demographic_parity_difference\"], metrics_fair[\"demographic_parity_difference\"]]\n",
    "    eo_diff = [metrics_baseline[\"equalized_odds_difference\"], metrics_fair[\"equalized_odds_difference\"]]\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    axs[0,0].bar(models, aucs, color=['blue', 'green'])\n",
    "    axs[0,0].set_title('AUC')\n",
    "    axs[0,0].set_ylim([0, 1])\n",
    "\n",
    "    axs[0,1].bar(models, accs, color=['blue', 'green'])\n",
    "    axs[0,1].set_title('Accuracy')\n",
    "    axs[0,1].set_ylim([0, 1])\n",
    "\n",
    "    axs[1,0].bar(models, dp_diff, color=['orange', 'purple'])\n",
    "    axs[1,0].set_title('Demographic Parity Difference')\n",
    "\n",
    "    axs[1,1].bar(models, eo_diff, color=['orange', 'purple'])\n",
    "    axs[1,1].set_title('Equalized Odds Difference')\n",
    "\n",
    "    plt.suptitle(\"Comparison: Baseline (X → Y) vs. Fair (X → Y') Model\")\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# Utility: Seed Setting\n",
    "# -------------------------------\n",
    "def set_seed(seed_num):\n",
    "    random.seed(seed_num)\n",
    "    np.random.seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_num)\n",
    "\n",
    "# -------------------------------\n",
    "# Main Function: COMPAS Data Comparison\n",
    "# -------------------------------\n",
    "def main_compas(data_url, lambda_adv=1.0):\n",
    "    set_seed(42)\n",
    "\n",
    "    print(\"Loading and preprocessing COMPAS data...\")\n",
    "    X, Y_obs, S_raw = load_and_preprocess_compas_data(data_url)\n",
    "    # S_raw is already binary (0 or 1) per our processing.\n",
    "    S = S_raw\n",
    "\n",
    "    X_train, X_test, Y_train_obs, Y_test_obs, S_train, S_test = train_test_split(\n",
    "        X, Y_obs, S, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"Features shape: {X.shape}\")\n",
    "    print(f\"Observed Label Y shape: {Y_obs.shape}   (Recidivism: 1=recid, 0=non-recid)\")\n",
    "    print(f\"Sensitive Attribute (Race, binarized) shape: {S.shape}\")\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "\n",
    "    # One-hot encode S for the adversarial model.\n",
    "    S_train_oh = tf.keras.utils.to_categorical(S_train, num_classes=2)\n",
    "    S_test_oh  = tf.keras.utils.to_categorical(S_test, num_classes=2)\n",
    "\n",
    "    ### 1. Train adversarial debiasing model on COMPAS data.\n",
    "    print(\"\\nTraining adversarial model (X → Y' with adversary) ...\")\n",
    "    adv_model = build_adversarial_model(input_dim, lambda_adv=lambda_adv)\n",
    "    Y_train_obs_exp = Y_train_obs.reshape(-1, 1)\n",
    "    Y_test_obs_exp  = Y_test_obs.reshape(-1, 1)\n",
    "\n",
    "    adv_model.fit([X_train, S_train_oh],\n",
    "                  {\"pseudo_Y\": Y_train_obs_exp, \"S_pred\": S_train_oh, \"Y_pred\": Y_train_obs_exp},\n",
    "                  epochs=30, batch_size=128, verbose=1)\n",
    "\n",
    "    # Get pseudo‑label predictions.\n",
    "    pseudo_Y_train, _, _ = adv_model.predict([X_train, S_train_oh])\n",
    "    pseudo_Y_test,  _, _ = adv_model.predict([X_test, S_test_oh])\n",
    "\n",
    "    # Threshold to get binary pseudo‑labels.\n",
    "    pseudo_Y_train_bin = (pseudo_Y_train > 0.5).astype(np.float32)\n",
    "    pseudo_Y_test_bin  = (pseudo_Y_test > 0.5).astype(np.float32)\n",
    "\n",
    "    print(\"\\nPseudo‑label statistics (training):\")\n",
    "    for g in np.unique(S_train):\n",
    "        mask = (S_train == g)\n",
    "        print(f\"Group {g} pseudo‑positive rate: {np.mean(pseudo_Y_train_bin[mask]):.4f}\")\n",
    "\n",
    "    ### 2. Train baseline logistic regression classifier (X → Y)\n",
    "    print(\"\\nTraining baseline logistic regression classifier (X → Y)...\")\n",
    "    baseline_clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "    baseline_clf.fit(X_train, Y_train_obs)\n",
    "    baseline_preds = baseline_clf.predict_proba(X_test)[:, 1]\n",
    "    baseline_auc = roc_auc_score(Y_test_obs, baseline_preds)\n",
    "    baseline_acc = accuracy_score(Y_test_obs, (baseline_preds > 0.5).astype(int))\n",
    "    baseline_fairness = compute_fairness_metrics_manual(Y_test_obs, baseline_preds, sensitive_features=S_test)\n",
    "\n",
    "    ### 3. Train fair logistic regression classifier on pseudo‑labels (X → Y')\n",
    "    print(\"\\nTraining fair logistic regression classifier (X → Y') using pseudo‑labels...\")\n",
    "    fair_clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "    fair_clf.fit(X_train, pseudo_Y_train_bin.ravel())\n",
    "    fair_preds = fair_clf.predict_proba(X_test)[:, 1]\n",
    "    fair_auc = roc_auc_score(Y_test_obs, fair_preds)\n",
    "    fair_acc = accuracy_score(Y_test_obs, (fair_preds > 0.5).astype(int))\n",
    "    fair_fairness = compute_fairness_metrics_manual(Y_test_obs, fair_preds, sensitive_features=S_test)\n",
    "\n",
    "    # Aggregate metrics.\n",
    "    metrics_baseline = {\n",
    "        \"auc\": baseline_auc,\n",
    "        \"accuracy\": baseline_acc,\n",
    "        \"demographic_parity_difference\": baseline_fairness[\"demographic_parity_difference\"],\n",
    "        \"equalized_odds_difference\": baseline_fairness[\"equalized_odds_difference\"]\n",
    "    }\n",
    "    metrics_fair = {\n",
    "        \"auc\": fair_auc,\n",
    "        \"accuracy\": fair_acc,\n",
    "        \"demographic_parity_difference\": fair_fairness[\"demographic_parity_difference\"],\n",
    "        \"equalized_odds_difference\": fair_fairness[\"equalized_odds_difference\"]\n",
    "    }\n",
    "\n",
    "    print(\"\\nBaseline Logistic Regression (X → Y) Evaluation:\")\n",
    "    print(f\"AUC: {baseline_auc:.4f}, Accuracy: {baseline_acc:.4f}\")\n",
    "    print(\"Fairness metrics:\", baseline_fairness)\n",
    "\n",
    "    print(\"\\nFair Logistic Regression (X → Y') Evaluation (compared to observed Y):\")\n",
    "    print(f\"AUC: {fair_auc:.4f}, Accuracy: {fair_acc:.4f}\")\n",
    "    print(\"Fairness metrics:\", fair_fairness)\n",
    "\n",
    "    # Plot comparisons.\n",
    "    plot_comparison(metrics_baseline, metrics_fair)\n",
    "\n",
    "# -------------------------------\n",
    "# Run the COMPAS Analysis\n",
    "# -------------------------------\n",
    "if __name__ == '__main__':\n",
    "    # URL for the ProPublica COMPAS dataset\n",
    "    compas_data_url = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
    "    # You can adjust lambda_adv as desired (e.g., lambda_adv=15.5 as in your German data experiment)\n",
    "    main_compas(compas_data_url, lambda_adv=3.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kp5PVM_VGQw9"
   },
   "source": [
    "o3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yl76BnxEEWWh"
   },
   "source": [
    "O3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gz69gslBiYQN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
