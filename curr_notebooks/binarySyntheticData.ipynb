{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf22c554-b495-4551-ae60-0381413fb23b",
   "metadata": {},
   "source": [
    "#### Plan for synthetic data \n",
    "1. Create synthetic datasets\n",
    "2. Run synthetic unbiased fair synthetic dataset\n",
    "3. add in error + bias into Y-train, make it rely on S\n",
    "4. run pipeline on new data and try to get it to meet the same baseline as the original dataset for demographic parity + accuracy.\n",
    "\n",
    "#### Additional work \n",
    "hypertune for lambda so that accuracy and demographic parity are well balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24672b93-3c9d-4e08-98b2-b6a106a323bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 23:38:26.609051: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-04 23:38:26.609096: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-04 23:38:26.610685: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-04 23:38:26.620400: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# !pip install fairlearn\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Conv2D, Flatten, \n",
    "    MaxPooling2D, BatchNormalization, Dropout\n",
    ")\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    LearningRateScheduler\n",
    ")\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.initializers import Constant\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tqdm import tqdm\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Conv2D, Flatten, \n",
    "    MaxPooling2D, BatchNormalization, Dropout, Concatenate\n",
    ")\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    LearningRateScheduler\n",
    ")\n",
    "\n",
    "from tensorflow.keras.regularizers import Regularizer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9af067-aa00-404e-9bbb-9fa55fd4367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Custom Gradient Reversal Layer\n",
    "# -------------------------------\n",
    "@tf.custom_gradient\n",
    "def grad_reverse(x, lambda_):\n",
    "    def grad(dy):\n",
    "        return -lambda_ * dy, None # reverses direction of gradient \n",
    "    return x, grad\n",
    "\n",
    "# custom Keras layer\n",
    "\"\"\"\n",
    "Layer is used to ensure that the feature representation are independent of a sensitive attribute\n",
    "- feature extract learns normally in the forward pass\n",
    "- reversing gradients of classifier that tries to predict the sensitive attribute during backpropagation -- stops feature extractor from encoding sensitive information\n",
    "\"\"\"\n",
    "class GradientReversalLayer(tf.keras.layers.Layer): \n",
    "    def __init__(self, lambda_=1.0, **kwargs):\n",
    "        super(GradientReversalLayer, self).__init__(**kwargs)\n",
    "        self.lambda_ = lambda_ # strength of gradient reversal\n",
    "    def call(self, x):\n",
    "        return grad_reverse(x, self.lambda_)\n",
    "\n",
    "# -------------------------------\n",
    "# Data Loading and Preprocessing\n",
    "# -------------------------------\n",
    "def set_seed(seed_num):\n",
    "    random.seed(seed_num)\n",
    "    np.random.seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98a279a6-a67d-4bab-8049-18a4eb1ab4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Adversarial Debiasing Model\n",
    "# -------------------------------\n",
    "def build_adversarial_model(input_dim, lambda_adv=1.0):\n",
    "    \"\"\"\n",
    "    Build an adversarial debiasing model that learns pseudo‑labels Y' from X.\n",
    "\n",
    "    Architecture:\n",
    "      - Main branch (encoder): from X, several dense layers produce a latent pseudo‑label pseudo_Y (via sigmoid).\n",
    "      - Adversary branch: pseudo_Y is passed through a Gradient Reversal Layer and then dense layers predict S.\n",
    "      - Decoder branch: concatenates pseudo_Y and the one-hot sensitive attribute S to predict the observed label Y.\n",
    "\n",
    "    Losses:\n",
    "      - For the main branch, binary crossentropy between observed Y and pseudo_Y (and Y_pred).\n",
    "      - For the adversary branch, categorical crossentropy to predict S.\n",
    "\n",
    "    Returns a compiled Keras model that takes inputs X and S (one-hot encoded) and outputs:\n",
    "      [pseudo_Y, S_pred, Y_pred].\n",
    "    \"\"\"\n",
    "    X_input = tf.keras.Input(shape=(input_dim,), name=\"X\")\n",
    "    S_input = tf.keras.Input(shape=(2,), name=\"S\")  # one-hot encoded S\n",
    "\n",
    "    # Main branch: Encoder for pseudo-label.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    h = Dense(64, activation='relu')(X_input)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Dense(32, activation='relu')(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    pseudo_Y = Dense(1, activation='sigmoid', name=\"pseudo_Y\")(h) ## outputs  probability value for pseudo_Y between 0,1\n",
    "\n",
    "    # Adversary branch: from pseudo_Y, with GRL.\n",
    "    \"\"\"\n",
    "    This is to prevent psuedo_Y from containing information about S\n",
    "    - adversary will try to predict S from pseudo_Y (fair label)...if it can accurately predict S, then Y' still encodes information about S (don't want this) \n",
    "    - use the gradient reversal layer to prevent this from happening\n",
    "    \"\"\"\n",
    "    grl = GradientReversalLayer(lambda_=lambda_adv)(pseudo_Y)\n",
    "    a = Dense(32, activation='relu')(grl)\n",
    "    a = BatchNormalization()(a)\n",
    "    S_pred = Dense(2, activation='softmax', name=\"S_pred\")(a)\n",
    "\n",
    "    # Decoder branch: combine pseudo_Y and S to predict observed Y.\n",
    "    \"\"\"\n",
    "    Y depepends on both Y' and S \n",
    "    -- predict the final observed label Y using both psuedo_Y and S\n",
    "    -- Y may still depend on S, that is why it's being used here \n",
    "    -- decoder ensures Y_final is accurate, while psuedo_Y is not directly influenced by S \n",
    "    -- psuedo_Y removes unfair dependencies on S...however S might still contain legit info needed to predict Y accurately \n",
    "    -- IMPORTANT - THIS STEP ALLOWS FAIR DEPENDENCIES WHILE ELIMINATING UNFAIR ONES\n",
    "    -- structure how S influences Y, without letting hidden biases leak through \n",
    "    \"\"\"\n",
    "    concat = Concatenate()([pseudo_Y, S_input])\n",
    "    d = Dense(16, activation='relu')(concat)\n",
    "    d = BatchNormalization()(d)\n",
    "    Y_pred = Dense(1, activation='sigmoid', name=\"Y_pred\")(d)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[X_input, S_input],\n",
    "                           outputs=[pseudo_Y, S_pred, Y_pred])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  loss={\"pseudo_Y\": \"binary_crossentropy\",\n",
    "                        \"S_pred\": \"categorical_crossentropy\",\n",
    "                        \"Y_pred\": \"binary_crossentropy\"},\n",
    "                  loss_weights={\"pseudo_Y\": 1.0, \"S_pred\": lambda_adv, \"Y_pred\": 1.0},\n",
    "                  metrics={\"pseudo_Y\": \"accuracy\",\n",
    "                           \"S_pred\": \"accuracy\",\n",
    "                           \"Y_pred\": \"accuracy\"}) # Y_pred is the best estimate of Y accounting for fair dependencies \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdce495e-4c4f-4024-81ae-ec51509beaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Manual Fairness Metrics\n",
    "# -------------------------------\n",
    "def compute_fairness_metrics_manual(y_true, y_pred, sensitive_features):\n",
    "    \"\"\"\n",
    "    Compute fairness metrics manually.\n",
    "    y_true: binary ground-truth labels (1-D numpy array).\n",
    "    y_pred: continuous scores (will be thresholded at 0.5).\n",
    "    sensitive_features: 1-D numpy array (0 or 1).\n",
    "\n",
    "    Returns a dictionary with:\n",
    "      - Demographic parity difference (absolute difference in positive rates).\n",
    "      - Equalized odds difference (average difference in TPR and FPR).\n",
    "      - Selection rates per group.\n",
    "      - Group-wise accuracy.\n",
    "    \"\"\"\n",
    "    y_pred_bin = (y_pred > 0.5).astype(int) # y_pred is continuous value, so converting it to binary \n",
    "    groups = np.unique(sensitive_features)\n",
    "\n",
    "    # Demographic parity \n",
    "    \"\"\"\n",
    "    All groups (from sensitive feature) should receive positive predictions at the same rate\n",
    "    P(Y_hat = 1|S=0) = P(Y_hat=1|S=1)\n",
    "    \"\"\"\n",
    "\n",
    "    # For each group in the sensitive feature, find the demographic parity and compute the difference (based on the formula in above comment)\n",
    "    pos_rates = {}\n",
    "    for g in groups: \n",
    "        pos_rates[g] = np.mean(y_pred_bin[sensitive_features == g])\n",
    "    dp_diff = abs(pos_rates[0] - pos_rates[1]) ## this line assumes that there are only 2 groups, 0 and 1 -- if there are more than 2 groups, this would need to be changed\n",
    "    ## in all the examples used, there were only 2 groups -- need to double check this when working on new data\n",
    "    \n",
    "    # dp_diff > 0, then demographic parity isn't fair \n",
    "\n",
    "    # Equalized odds\n",
    "    \"\"\"\n",
    "    Ensuring the different groups in the sensitive feature similar TPR and FPR rates -- this is so that the model isn't discriminating in error types\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    for g in groups:\n",
    "        mask = (sensitive_features == g)\n",
    "        y_true_g = y_true[mask]\n",
    "        y_pred_g = y_pred_bin[mask]\n",
    "        tpr = np.sum((y_pred_g == 1) & (y_true_g == 1)) / (np.sum(y_true_g == 1) + 1e-8) # True Positive Rate\n",
    "        fpr = np.sum((y_pred_g == 1) & (y_true_g == 0)) / (np.sum(y_true_g == 0) + 1e-8) # False Positive Rate\n",
    "        metrics[g] = (tpr, fpr)\n",
    "    eo_diff = (abs(metrics[0][0] - metrics[1][0]) + abs(metrics[0][1] - metrics[1][1])) # taking average of two error types\n",
    "\n",
    "    # Selection rate per group.\n",
    "    \"\"\"\n",
    "    proportion of samples predicted as positive for each group -- a a group has a higher selection rate, the model may favor that group unfairly\n",
    "    \"\"\"\n",
    "    sel_rate = {}\n",
    "    for g in groups:\n",
    "        sel_rate[g] = pos_rates[g]\n",
    "\n",
    "    # Group-wise accuracy.\n",
    "    \"\"\"\n",
    "    for each group in the sensitive feature, compute the accuracy of the model (to ensure that it's perfoming consistently across groups)\n",
    "    \"\"\"\n",
    "    group_acc = {}\n",
    "    for g in groups:\n",
    "        mask = (sensitive_features == g)\n",
    "        group_acc[g] = accuracy_score(y_true[mask], y_pred_bin[mask])\n",
    "\n",
    "    return {\n",
    "        \"demographic_parity_difference\": dp_diff,\n",
    "        \"equalized_odds_difference\": eo_diff,\n",
    "        \"selection_rate\": sel_rate,\n",
    "        \"group_accuracy\": group_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "215ef3cd-b252-45a1-a259-d6b4dd09001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Plotting Function\n",
    "# -------------------------------\n",
    "def plot_comparison(metrics_baseline, metrics_fair):\n",
    "    \"\"\"\n",
    "    parameters are dictionaries with the stored values of the evaluation metrics\n",
    "    \"\"\"\n",
    "    models = ['Baseline', 'Fair']\n",
    "    aucs = [metrics_baseline['auc'], metrics_fair['auc']]\n",
    "    accs = [metrics_baseline['accuracy'], metrics_fair['accuracy']]\n",
    "    dp_diff = [metrics_baseline[\"demographic_parity_difference\"], metrics_fair[\"demographic_parity_difference\"]]\n",
    "    eo_diff = [metrics_baseline[\"equalized_odds_difference\"], metrics_fair[\"equalized_odds_difference\"]]\n",
    "\n",
    "    # creating a 2x3 gird of bar chars comparing baseline model and fair model across: AUC, accuracy, demographic parity diff, equalized odd difference\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    ## measures how well the model seperates postiive and negative classes, higher AUC = better model performance\n",
    "    # if fair model has a lower AUC than the baseline, can indicate a fairness-performance tradeoff (meaning less well seperation for more fair results)\n",
    "    axs[0,0].bar(models, aucs, color=['blue', 'green'])\n",
    "    axs[0,0].set_title('AUC')\n",
    "    axs[0,0].set_ylim([0, 1])\n",
    "\n",
    "    ## correct pred/total pred\n",
    "    ## fairness may lower accuracy \n",
    "    axs[0,1].bar(models, accs, color=['blue', 'green'])\n",
    "    axs[0,1].set_title('Accuracy')\n",
    "    axs[0,1].set_ylim([0, 1])\n",
    "\n",
    "    ## orange = baseline, purple = fairness -LOOK INTO TO SEE HOW TO KNOW WHICH GROUP IS CONTRIBUTING TO HIGHER DP\n",
    "    # lower values of dp indciate better fairness\n",
    "    axs[1,0].bar(models, dp_diff, color=['orange', 'purple'])\n",
    "    axs[1,0].set_title('Demographic Parity Difference')\n",
    "\n",
    "    ## lower value - better fairness\n",
    "    ## equalized odds is satisfied if tpr and fpr are equal across the different groups in the sensitive feature\n",
    "    axs[1,1].bar(models, eo_diff, color=['orange', 'purple'])\n",
    "    axs[1,1].set_title('Equalized Odds Difference')\n",
    "\n",
    "    plt.suptitle(\"Comparison: Baseline (X → Y) vs. Fair (X → Y') Model\")\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcb64d7f-b1bf-44e6-8a2e-82ec01d85ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(n_samples=5000, n_features=30, bias_factor=0.4, noise_level=0.1, seed=42):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Generate Sensitive Attribute S ~ Binomial(1, 0.5)\n",
    "    S = np.random.binomial(1, 0.5, size=n_samples)\n",
    "\n",
    "    # Generate Features X: Some function of S + Multinomial noise\n",
    "    X = np.random.randn(n_samples, n_features) + 0.5 * S[:, np.newaxis]\n",
    "\n",
    "    # Generate True Labels Y (linear function of X + noise)\n",
    "    true_weights = np.random.randn(n_features)\n",
    "    Y_continuous = X @ true_weights + np.random.normal(0, noise_level, size=n_samples)\n",
    "\n",
    "    # Convert Y into discrete categories (multi-class setting)\n",
    "    Y = np.digitize(Y_continuous, bins=np.percentile(Y_continuous, [50]))  # 2 classes (0,1) ## change this later if we want to see \n",
    "\n",
    "    X_train, X_test, Y_train_obs, Y_test_obs, S_train, S_test = train_test_split(\n",
    "        X, Y, S, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, Y_train_obs, Y_test_obs, S_train, S_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4db287ff-63dd-4c5d-9aa9-324e31b26826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def inject_bias(X_train, Y_train, S_train, X_test, Y_test, S_test, bias_factor=0.3, seed=42):\n",
    "def inject_bias(bias_factor=0.4, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    X_train, X_test, Y_train_raw, Y_test_raw, S_train, S_test = generate_synthetic_data()\n",
    "    def apply_bias(Y, S):\n",
    "        flip_mask = np.random.rand(len(Y)) < bias_factor  # Generate a flip mask for this dataset\n",
    "        Y_biased = Y.copy()\n",
    "        Y_biased[flip_mask & (S == 1)] = 1  # Favor positive outcomes for S=1\n",
    "        Y_biased[flip_mask & (S == 0)] = 0  # Favor negative outcomes for S=0\n",
    "        return Y_biased\n",
    "\n",
    "    Y_train_biased = apply_bias(Y_train_raw, S_train)\n",
    "    Y_test_biased = apply_bias(Y_test_raw, S_test)\n",
    "\n",
    "    return Y_train_biased, Y_test_biased\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86fc6588-04a1-4918-bf7c-6f8466a2da09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: AUC:0.9996070947462955, Accuracy:0.99, Demographic Parity Difference:0.015438596491228085, Equalized Odds Difference:0.02260242900471713\n"
     ]
    }
   ],
   "source": [
    "def run_biased_logistic(X_train, Y_train_biased_pred, X_test, Y_test_biased_pred, Y_train_raw, Y_test_raw, S_train, S_test): \n",
    "    clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "    clf.fit(X_train, Y_train_biased_pred)\n",
    "    preds = clf.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(Y_test_raw, preds)\n",
    "    acc = accuracy_score(Y_test_raw, (preds > 0.5).astype(int))\n",
    "    fairness = compute_fairness_metrics_manual(Y_test_raw, preds, sensitive_features=S_test)\n",
    "    \n",
    "    return auc, acc, fairness\n",
    "\n",
    "def run_unbiased_logistic(): \n",
    "    X_train, X_test, Y_train_raw, Y_test_raw, S_train, S_test = generate_synthetic_data() ##  Y is binary class, S is binary\n",
    "    clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "    clf.fit(X_train, Y_train_raw)\n",
    "    preds = clf.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(Y_test_raw, preds)\n",
    "    acc = accuracy_score(Y_test_raw, (preds > 0.5).astype(int))\n",
    "    fairness = compute_fairness_metrics_manual(Y_test_raw, preds, sensitive_features=S_test)\n",
    "\n",
    "    dp_diff = fairness[\"demographic_parity_difference\"]\n",
    "    eo_diff = fairness[\"equalized_odds_difference\"]\n",
    "\n",
    "    print (f\"Baseline: AUC:{auc}, Accuracy:{acc}, Demographic Parity Difference:{dp_diff}, Equalized Odds Difference:{eo_diff}\")\n",
    "\n",
    "run_unbiased_logistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9934d0d9-03c6-4480-a9d2-90283ba9e07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Main Function: Comparison and Visualization\n",
    "# -------------------------------\n",
    "def main_synthetic(lambda_adv=1.0, epochs=64, batch_size=128):\n",
    "    set_seed(42)\n",
    "\n",
    "    X_train, X_test, Y_train_raw, Y_test_raw, S_train, S_test = generate_synthetic_data() ##  Y is binary class, S is binary\n",
    "    # Y_train_biased, Y_test_biased = inject_bias(X_train, Y_train_raw, S_train, Y_test_raw, S_train, S_test, bias_factor=0.3, seed=42)\n",
    "    Y_train_biased, Y_test_biased = inject_bias(bias_factor=0.3, seed=42)\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "\n",
    "    # One-hot encode S for adversarial model training.\n",
    "    S_train_oh = tf.keras.utils.to_categorical(S_train, num_classes=2)\n",
    "    S_test_oh  = tf.keras.utils.to_categorical(S_test, num_classes=2)\n",
    "\n",
    "    ### 1. Train adversarial debiasing model (X → Y' with adversary)\n",
    "    print(\"\\nTraining adversarial model (X → Y' with adversary) ...\")\n",
    "    adv_model = build_adversarial_model(input_dim, lambda_adv=lambda_adv)\n",
    "    Y_train_biased_exp = Y_train_biased.reshape(-1, 1)\n",
    "    Y_test_biased_exp  = Y_test_biased.reshape(-1, 1)\n",
    "    adv_model.fit([X_train, S_train_oh],\n",
    "                  {\"pseudo_Y\": Y_train_biased_exp, \"S_pred\": S_train_oh, \"Y_pred\": Y_train_biased_exp},\n",
    "                  epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    # Get predictions \n",
    "    pseudo_Y_train, S_pred, Y_pred_train = adv_model.predict([X_train, S_train_oh]) ## do we want psuedo_Y or Y_pred? psuedo_Y is for complete fairness why pred_Y can be a bit more accurate by keep necessary dependencies\n",
    "    pseudo_Y_test,  S_pred, Y_pred_test = adv_model.predict([X_test, S_test_oh])\n",
    "\n",
    "    # # THIS IS WITH PSUEDO_Y - Professor's way\n",
    "    Y_pred_train_bin = (pseudo_Y_train > 0.5).astype(np.float32)\n",
    "    Y_pred_test_bin  = (pseudo_Y_test > 0.5).astype(np.float32)\n",
    "\n",
    "    # # # THIS IS WITH Y_PRED\n",
    "    # Y_pred_train_bin = (Y_pred_train > 0.5).astype(np.float32)\n",
    "    # Y_pred_test_bin  = (Y_pred_test > 0.5).astype(np.float32)\n",
    "\n",
    "    print(\"\\nPseudo-label statistics (training):\")\n",
    "    for g in np.unique(S_train):\n",
    "        mask = (S_train == g)\n",
    "        print(f\"Group {g} pseudo-positive rate: {np.mean(Y_pred_train_bin[mask]):.4f}\") # average probability of a postive prediction per group -- fairness check to see if both groups receive similar treatment\n",
    "\n",
    "    ### 2. Train baseline logistic regression model on observed Y (X → Y) -- regular logistic regression for baseline for comparison; does not include any fairness constraints\n",
    "    print(\"\\nTraining baseline [BIASED] logistic regression classifier (X → Y)...\")\n",
    "    baseline_auc, baseline_acc, baseline_fairness = run_biased_logistic(X_train, Y_train_biased, X_test, Y_test_biased,  Y_train_raw, Y_test_raw, S_train, S_test)\n",
    "\n",
    "    ### 3. Train fair logistic regression model on pseudo-labels (X → Y') -- using psuedo_Y from the the adv_model, \n",
    "    print(\"\\nTraining fair logistic regression classifier (X → Y') using pseudo-labels...\")\n",
    "    fair_auc, fair_acc, fair_fairness = run_biased_logistic(X_train, Y_pred_train_bin, X_test, Y_pred_test_bin, Y_train_raw, Y_test_raw, S_train, S_test)\n",
    "\n",
    "    # Aggregate metrics for plotting.\n",
    "    metrics_baseline = {\n",
    "        \"auc\": baseline_auc,\n",
    "        \"accuracy\": baseline_acc,\n",
    "        \"demographic_parity_difference\": baseline_fairness[\"demographic_parity_difference\"],\n",
    "        \"equalized_odds_difference\": baseline_fairness[\"equalized_odds_difference\"]\n",
    "    }\n",
    "    metrics_fair = {\n",
    "        \"auc\": fair_auc,\n",
    "        \"accuracy\": fair_acc,\n",
    "        \"demographic_parity_difference\": fair_fairness[\"demographic_parity_difference\"],\n",
    "        \"equalized_odds_difference\": fair_fairness[\"equalized_odds_difference\"]\n",
    "    }\n",
    "\n",
    "    print(\"\\nBaseline Logistic Regression (X → Y) Evaluation:\")\n",
    "    print(f\"AUC: {baseline_auc:.4f}, Accuracy: {baseline_acc:.4f}\")\n",
    "    print(\"Fairness metrics:\", baseline_fairness)\n",
    "\n",
    "    print(\"\\nFair Logistic Regression (X → Y') Evaluation (compared to observed Y):\")\n",
    "    print(f\"AUC: {fair_auc:.4f}, Accuracy: {fair_acc:.4f}\")\n",
    "    print(\"Fairness metrics:\", fair_fairness)\n",
    "\n",
    "    # Plot comparison.\n",
    "    plot_comparison(metrics_baseline, metrics_fair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046a7324-619d-470b-9ec7-f1b4bf6d984f",
   "metadata": {},
   "source": [
    "### Application on Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4a8cb1-26fd-47ae-ba82-01642fb05249",
   "metadata": {},
   "source": [
    "#### Synthetic Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f7fc422-2dee-4b97-81ef-76411f44298b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training adversarial model (X → Y' with adversary) ...\n",
      "Epoch 1/72\n",
      "32/32 [==============================] - 2s 9ms/step - loss: 5.1862 - pseudo_Y_loss: 0.9296 - S_pred_loss: 0.7964 - Y_pred_loss: 1.0710 - pseudo_Y_accuracy: 0.4835 - S_pred_accuracy: 0.4840 - Y_pred_accuracy: 0.3923\n",
      "Epoch 2/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.1937 - pseudo_Y_loss: 0.9078 - S_pred_loss: 0.8220 - Y_pred_loss: 0.9978 - pseudo_Y_accuracy: 0.4972 - S_pred_accuracy: 0.4100 - Y_pred_accuracy: 0.4047\n",
      "Epoch 3/72\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 5.0871 - pseudo_Y_loss: 0.8924 - S_pred_loss: 0.8148 - Y_pred_loss: 0.9355 - pseudo_Y_accuracy: 0.5203 - S_pred_accuracy: 0.3683 - Y_pred_accuracy: 0.4207\n",
      "Epoch 4/72\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.9096 - pseudo_Y_loss: 0.8806 - S_pred_loss: 0.7863 - Y_pred_loss: 0.8839 - pseudo_Y_accuracy: 0.5282 - S_pred_accuracy: 0.3237 - Y_pred_accuracy: 0.4365\n",
      "Epoch 5/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.6990 - pseudo_Y_loss: 0.8684 - S_pred_loss: 0.7457 - Y_pred_loss: 0.8476 - pseudo_Y_accuracy: 0.5395 - S_pred_accuracy: 0.3055 - Y_pred_accuracy: 0.4543\n",
      "Epoch 6/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.5031 - pseudo_Y_loss: 0.8591 - S_pred_loss: 0.7062 - Y_pred_loss: 0.8193 - pseudo_Y_accuracy: 0.5418 - S_pred_accuracy: 0.3647 - Y_pred_accuracy: 0.4760\n",
      "Epoch 7/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3271 - pseudo_Y_loss: 0.8420 - S_pred_loss: 0.6727 - Y_pred_loss: 0.7941 - pseudo_Y_accuracy: 0.5443 - S_pred_accuracy: 0.7023 - Y_pred_accuracy: 0.5013\n",
      "Epoch 8/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1859 - pseudo_Y_loss: 0.8225 - S_pred_loss: 0.6472 - Y_pred_loss: 0.7745 - pseudo_Y_accuracy: 0.5527 - S_pred_accuracy: 0.7050 - Y_pred_accuracy: 0.5100\n",
      "Epoch 9/72\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1137 - pseudo_Y_loss: 0.8064 - S_pred_loss: 0.6363 - Y_pred_loss: 0.7619 - pseudo_Y_accuracy: 0.5617 - S_pred_accuracy: 0.6827 - Y_pred_accuracy: 0.5173\n",
      "Epoch 10/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1194 - pseudo_Y_loss: 0.7919 - S_pred_loss: 0.6443 - Y_pred_loss: 0.7504 - pseudo_Y_accuracy: 0.5642 - S_pred_accuracy: 0.6405 - Y_pred_accuracy: 0.5257\n",
      "Epoch 11/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.2267 - pseudo_Y_loss: 0.7857 - S_pred_loss: 0.6736 - Y_pred_loss: 0.7466 - pseudo_Y_accuracy: 0.5555 - S_pred_accuracy: 0.5842 - Y_pred_accuracy: 0.5295\n",
      "Epoch 12/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3841 - pseudo_Y_loss: 0.7914 - S_pred_loss: 0.7116 - Y_pred_loss: 0.7463 - pseudo_Y_accuracy: 0.5405 - S_pred_accuracy: 0.5050 - Y_pred_accuracy: 0.5132\n",
      "Epoch 13/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4733 - pseudo_Y_loss: 0.8091 - S_pred_loss: 0.7303 - Y_pred_loss: 0.7429 - pseudo_Y_accuracy: 0.5328 - S_pred_accuracy: 0.4317 - Y_pred_accuracy: 0.5063\n",
      "Epoch 14/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.4364 - pseudo_Y_loss: 0.8223 - S_pred_loss: 0.7200 - Y_pred_loss: 0.7341 - pseudo_Y_accuracy: 0.5290 - S_pred_accuracy: 0.3977 - Y_pred_accuracy: 0.5100\n",
      "Epoch 15/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.3216 - pseudo_Y_loss: 0.8239 - S_pred_loss: 0.6952 - Y_pred_loss: 0.7171 - pseudo_Y_accuracy: 0.5222 - S_pred_accuracy: 0.4935 - Y_pred_accuracy: 0.5117\n",
      "Epoch 16/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.2217 - pseudo_Y_loss: 0.8021 - S_pred_loss: 0.6809 - Y_pred_loss: 0.6962 - pseudo_Y_accuracy: 0.5322 - S_pred_accuracy: 0.6095 - Y_pred_accuracy: 0.5527\n",
      "Epoch 17/72\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1719 - pseudo_Y_loss: 0.7754 - S_pred_loss: 0.6802 - Y_pred_loss: 0.6758 - pseudo_Y_accuracy: 0.5447 - S_pred_accuracy: 0.5828 - Y_pred_accuracy: 0.5985\n",
      "Epoch 18/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1541 - pseudo_Y_loss: 0.7422 - S_pred_loss: 0.6888 - Y_pred_loss: 0.6568 - pseudo_Y_accuracy: 0.5723 - S_pred_accuracy: 0.5415 - Y_pred_accuracy: 0.6210\n",
      "Epoch 19/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1630 - pseudo_Y_loss: 0.7161 - S_pred_loss: 0.7006 - Y_pred_loss: 0.6447 - pseudo_Y_accuracy: 0.5945 - S_pred_accuracy: 0.4857 - Y_pred_accuracy: 0.6335\n",
      "Epoch 20/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1515 - pseudo_Y_loss: 0.6981 - S_pred_loss: 0.7040 - Y_pred_loss: 0.6375 - pseudo_Y_accuracy: 0.6095 - S_pred_accuracy: 0.4445 - Y_pred_accuracy: 0.6428\n",
      "Epoch 21/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.1081 - pseudo_Y_loss: 0.6843 - S_pred_loss: 0.6981 - Y_pred_loss: 0.6314 - pseudo_Y_accuracy: 0.6210 - S_pred_accuracy: 0.4405 - Y_pred_accuracy: 0.6438\n",
      "Epoch 22/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.0510 - pseudo_Y_loss: 0.6734 - S_pred_loss: 0.6881 - Y_pred_loss: 0.6253 - pseudo_Y_accuracy: 0.6273 - S_pred_accuracy: 0.5567 - Y_pred_accuracy: 0.6525\n",
      "Epoch 23/72\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0147 - pseudo_Y_loss: 0.6655 - S_pred_loss: 0.6821 - Y_pred_loss: 0.6209 - pseudo_Y_accuracy: 0.6320 - S_pred_accuracy: 0.5710 - Y_pred_accuracy: 0.6578\n",
      "Epoch 24/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0366 - pseudo_Y_loss: 0.6664 - S_pred_loss: 0.6883 - Y_pred_loss: 0.6171 - pseudo_Y_accuracy: 0.6325 - S_pred_accuracy: 0.5357 - Y_pred_accuracy: 0.6612\n",
      "Epoch 25/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0739 - pseudo_Y_loss: 0.6696 - S_pred_loss: 0.6983 - Y_pred_loss: 0.6110 - pseudo_Y_accuracy: 0.6323 - S_pred_accuracy: 0.4945 - Y_pred_accuracy: 0.6685\n",
      "Epoch 26/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0915 - pseudo_Y_loss: 0.6786 - S_pred_loss: 0.7012 - Y_pred_loss: 0.6080 - pseudo_Y_accuracy: 0.6140 - S_pred_accuracy: 0.4610 - Y_pred_accuracy: 0.6733\n",
      "Epoch 27/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 4.0701 - pseudo_Y_loss: 0.6827 - S_pred_loss: 0.6959 - Y_pred_loss: 0.6037 - pseudo_Y_accuracy: 0.6148 - S_pred_accuracy: 0.4762 - Y_pred_accuracy: 0.6720\n",
      "Epoch 28/72\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 4.0401 - pseudo_Y_loss: 0.6765 - S_pred_loss: 0.6912 - Y_pred_loss: 0.5990 - pseudo_Y_accuracy: 0.6190 - S_pred_accuracy: 0.5303 - Y_pred_accuracy: 0.6762\n",
      "Epoch 29/72\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0112 - pseudo_Y_loss: 0.6553 - S_pred_loss: 0.6909 - Y_pred_loss: 0.5923 - pseudo_Y_accuracy: 0.6335 - S_pred_accuracy: 0.5300 - Y_pred_accuracy: 0.6810\n",
      "Epoch 30/72\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9997 - pseudo_Y_loss: 0.6352 - S_pred_loss: 0.6941 - Y_pred_loss: 0.5880 - pseudo_Y_accuracy: 0.6495 - S_pred_accuracy: 0.4963 - Y_pred_accuracy: 0.6793\n",
      "Epoch 31/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9856 - pseudo_Y_loss: 0.6190 - S_pred_loss: 0.6962 - Y_pred_loss: 0.5818 - pseudo_Y_accuracy: 0.6650 - S_pred_accuracy: 0.4695 - Y_pred_accuracy: 0.6888\n",
      "Epoch 32/72\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.9580 - pseudo_Y_loss: 0.6059 - S_pred_loss: 0.6939 - Y_pred_loss: 0.5765 - pseudo_Y_accuracy: 0.6758 - S_pred_accuracy: 0.4850 - Y_pred_accuracy: 0.6865\n",
      "Epoch 33/72\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9347 - pseudo_Y_loss: 0.5995 - S_pred_loss: 0.6909 - Y_pred_loss: 0.5717 - pseudo_Y_accuracy: 0.6842 - S_pred_accuracy: 0.5318 - Y_pred_accuracy: 0.6885\n",
      "Epoch 34/72\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9280 - pseudo_Y_loss: 0.5989 - S_pred_loss: 0.6905 - Y_pred_loss: 0.5670 - pseudo_Y_accuracy: 0.6858 - S_pred_accuracy: 0.5293 - Y_pred_accuracy: 0.6927\n",
      "Epoch 35/72\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9307 - pseudo_Y_loss: 0.5990 - S_pred_loss: 0.6929 - Y_pred_loss: 0.5602 - pseudo_Y_accuracy: 0.6862 - S_pred_accuracy: 0.5102 - Y_pred_accuracy: 0.7030\n",
      "Epoch 36/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9377 - pseudo_Y_loss: 0.6028 - S_pred_loss: 0.6949 - Y_pred_loss: 0.5554 - pseudo_Y_accuracy: 0.6810 - S_pred_accuracy: 0.4910 - Y_pred_accuracy: 0.7122\n",
      "Epoch 37/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9401 - pseudo_Y_loss: 0.6067 - S_pred_loss: 0.6952 - Y_pred_loss: 0.5526 - pseudo_Y_accuracy: 0.6825 - S_pred_accuracy: 0.4715 - Y_pred_accuracy: 0.7150\n",
      "Epoch 38/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9266 - pseudo_Y_loss: 0.6054 - S_pred_loss: 0.6934 - Y_pred_loss: 0.5474 - pseudo_Y_accuracy: 0.6888 - S_pred_accuracy: 0.4980 - Y_pred_accuracy: 0.7150\n",
      "Epoch 39/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.9020 - pseudo_Y_loss: 0.5930 - S_pred_loss: 0.6925 - Y_pred_loss: 0.5391 - pseudo_Y_accuracy: 0.6915 - S_pred_accuracy: 0.5110 - Y_pred_accuracy: 0.7230\n",
      "Epoch 40/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8909 - pseudo_Y_loss: 0.5823 - S_pred_loss: 0.6933 - Y_pred_loss: 0.5355 - pseudo_Y_accuracy: 0.7025 - S_pred_accuracy: 0.5010 - Y_pred_accuracy: 0.7207\n",
      "Epoch 41/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8770 - pseudo_Y_loss: 0.5705 - S_pred_loss: 0.6938 - Y_pred_loss: 0.5314 - pseudo_Y_accuracy: 0.7095 - S_pred_accuracy: 0.4848 - Y_pred_accuracy: 0.7243\n",
      "Epoch 42/72\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8598 - pseudo_Y_loss: 0.5616 - S_pred_loss: 0.6928 - Y_pred_loss: 0.5270 - pseudo_Y_accuracy: 0.7132 - S_pred_accuracy: 0.5105 - Y_pred_accuracy: 0.7290\n",
      "Epoch 43/72\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8464 - pseudo_Y_loss: 0.5570 - S_pred_loss: 0.6920 - Y_pred_loss: 0.5214 - pseudo_Y_accuracy: 0.7220 - S_pred_accuracy: 0.5188 - Y_pred_accuracy: 0.7352\n",
      "Epoch 44/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8448 - pseudo_Y_loss: 0.5581 - S_pred_loss: 0.6925 - Y_pred_loss: 0.5166 - pseudo_Y_accuracy: 0.7193 - S_pred_accuracy: 0.5100 - Y_pred_accuracy: 0.7410\n",
      "Epoch 45/72\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8444 - pseudo_Y_loss: 0.5594 - S_pred_loss: 0.6934 - Y_pred_loss: 0.5113 - pseudo_Y_accuracy: 0.7250 - S_pred_accuracy: 0.5002 - Y_pred_accuracy: 0.7405\n",
      "Epoch 46/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8459 - pseudo_Y_loss: 0.5628 - S_pred_loss: 0.6938 - Y_pred_loss: 0.5077 - pseudo_Y_accuracy: 0.7283 - S_pred_accuracy: 0.4868 - Y_pred_accuracy: 0.7450\n",
      "Epoch 47/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8460 - pseudo_Y_loss: 0.5648 - S_pred_loss: 0.6935 - Y_pred_loss: 0.5071 - pseudo_Y_accuracy: 0.7235 - S_pred_accuracy: 0.4967 - Y_pred_accuracy: 0.7462\n",
      "Epoch 48/72\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8226 - pseudo_Y_loss: 0.5522 - S_pred_loss: 0.6930 - Y_pred_loss: 0.4983 - pseudo_Y_accuracy: 0.7347 - S_pred_accuracy: 0.5058 - Y_pred_accuracy: 0.7495\n",
      "Epoch 49/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8149 - pseudo_Y_loss: 0.5461 - S_pred_loss: 0.6932 - Y_pred_loss: 0.4960 - pseudo_Y_accuracy: 0.7352 - S_pred_accuracy: 0.5063 - Y_pred_accuracy: 0.7548\n",
      "Epoch 50/72\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8024 - pseudo_Y_loss: 0.5390 - S_pred_loss: 0.6932 - Y_pred_loss: 0.4908 - pseudo_Y_accuracy: 0.7427 - S_pred_accuracy: 0.5063 - Y_pred_accuracy: 0.7545\n",
      "Epoch 51/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.8000 - pseudo_Y_loss: 0.5381 - S_pred_loss: 0.6928 - Y_pred_loss: 0.4910 - pseudo_Y_accuracy: 0.7450 - S_pred_accuracy: 0.5042 - Y_pred_accuracy: 0.7552\n",
      "Epoch 52/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7891 - pseudo_Y_loss: 0.5328 - S_pred_loss: 0.6927 - Y_pred_loss: 0.4854 - pseudo_Y_accuracy: 0.7487 - S_pred_accuracy: 0.5153 - Y_pred_accuracy: 0.7600\n",
      "Epoch 53/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7876 - pseudo_Y_loss: 0.5345 - S_pred_loss: 0.6930 - Y_pred_loss: 0.4811 - pseudo_Y_accuracy: 0.7545 - S_pred_accuracy: 0.5063 - Y_pred_accuracy: 0.7607\n",
      "Epoch 54/72\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.7833 - pseudo_Y_loss: 0.5340 - S_pred_loss: 0.6932 - Y_pred_loss: 0.4764 - pseudo_Y_accuracy: 0.7533 - S_pred_accuracy: 0.4985 - Y_pred_accuracy: 0.7602\n",
      "Epoch 55/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7767 - pseudo_Y_loss: 0.5324 - S_pred_loss: 0.6934 - Y_pred_loss: 0.4708 - pseudo_Y_accuracy: 0.7580 - S_pred_accuracy: 0.4958 - Y_pred_accuracy: 0.7697\n",
      "Epoch 56/72\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7744 - pseudo_Y_loss: 0.5322 - S_pred_loss: 0.6933 - Y_pred_loss: 0.4690 - pseudo_Y_accuracy: 0.7592 - S_pred_accuracy: 0.5013 - Y_pred_accuracy: 0.7740\n",
      "Epoch 57/72\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7683 - pseudo_Y_loss: 0.5286 - S_pred_loss: 0.6931 - Y_pred_loss: 0.4672 - pseudo_Y_accuracy: 0.7535 - S_pred_accuracy: 0.5060 - Y_pred_accuracy: 0.7695\n",
      "Epoch 58/72\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7588 - pseudo_Y_loss: 0.5227 - S_pred_loss: 0.6931 - Y_pred_loss: 0.4639 - pseudo_Y_accuracy: 0.7617 - S_pred_accuracy: 0.5063 - Y_pred_accuracy: 0.7722\n",
      "Epoch 59/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7528 - pseudo_Y_loss: 0.5198 - S_pred_loss: 0.6930 - Y_pred_loss: 0.4610 - pseudo_Y_accuracy: 0.7670 - S_pred_accuracy: 0.5060 - Y_pred_accuracy: 0.7717\n",
      "Epoch 60/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7479 - pseudo_Y_loss: 0.5166 - S_pred_loss: 0.6928 - Y_pred_loss: 0.4600 - pseudo_Y_accuracy: 0.7705 - S_pred_accuracy: 0.5023 - Y_pred_accuracy: 0.7747\n",
      "Epoch 61/72\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7405 - pseudo_Y_loss: 0.5150 - S_pred_loss: 0.6929 - Y_pred_loss: 0.4538 - pseudo_Y_accuracy: 0.7750 - S_pred_accuracy: 0.5080 - Y_pred_accuracy: 0.7815\n",
      "Epoch 62/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7443 - pseudo_Y_loss: 0.5187 - S_pred_loss: 0.6933 - Y_pred_loss: 0.4525 - pseudo_Y_accuracy: 0.7660 - S_pred_accuracy: 0.5015 - Y_pred_accuracy: 0.7830\n",
      "Epoch 63/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7426 - pseudo_Y_loss: 0.5182 - S_pred_loss: 0.6931 - Y_pred_loss: 0.4519 - pseudo_Y_accuracy: 0.7738 - S_pred_accuracy: 0.5008 - Y_pred_accuracy: 0.7843\n",
      "Epoch 64/72\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7345 - pseudo_Y_loss: 0.5134 - S_pred_loss: 0.6931 - Y_pred_loss: 0.4487 - pseudo_Y_accuracy: 0.7710 - S_pred_accuracy: 0.5058 - Y_pred_accuracy: 0.7832\n",
      "Epoch 65/72\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7274 - pseudo_Y_loss: 0.5093 - S_pred_loss: 0.6929 - Y_pred_loss: 0.4464 - pseudo_Y_accuracy: 0.7807 - S_pred_accuracy: 0.5040 - Y_pred_accuracy: 0.7837\n",
      "Epoch 66/72\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 3.7211 - pseudo_Y_loss: 0.5074 - S_pred_loss: 0.6929 - Y_pred_loss: 0.4420 - pseudo_Y_accuracy: 0.7807 - S_pred_accuracy: 0.4988 - Y_pred_accuracy: 0.7872\n",
      "Epoch 67/72\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.7195 - pseudo_Y_loss: 0.5064 - S_pred_loss: 0.6929 - Y_pred_loss: 0.4413 - pseudo_Y_accuracy: 0.7768 - S_pred_accuracy: 0.5040 - Y_pred_accuracy: 0.7857\n",
      "Epoch 68/72\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.7166 - pseudo_Y_loss: 0.5065 - S_pred_loss: 0.6931 - Y_pred_loss: 0.4376 - pseudo_Y_accuracy: 0.7840 - S_pred_accuracy: 0.5008 - Y_pred_accuracy: 0.7887\n",
      "Epoch 69/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7214 - pseudo_Y_loss: 0.5108 - S_pred_loss: 0.6932 - Y_pred_loss: 0.4380 - pseudo_Y_accuracy: 0.7812 - S_pred_accuracy: 0.4992 - Y_pred_accuracy: 0.7860\n",
      "Epoch 70/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7127 - pseudo_Y_loss: 0.5052 - S_pred_loss: 0.6931 - Y_pred_loss: 0.4353 - pseudo_Y_accuracy: 0.7820 - S_pred_accuracy: 0.5063 - Y_pred_accuracy: 0.7900\n",
      "Epoch 71/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.6989 - pseudo_Y_loss: 0.4973 - S_pred_loss: 0.6930 - Y_pred_loss: 0.4296 - pseudo_Y_accuracy: 0.7830 - S_pred_accuracy: 0.4945 - Y_pred_accuracy: 0.7937\n",
      "Epoch 72/72\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 3.7009 - pseudo_Y_loss: 0.4995 - S_pred_loss: 0.6931 - Y_pred_loss: 0.4290 - pseudo_Y_accuracy: 0.7845 - S_pred_accuracy: 0.4975 - Y_pred_accuracy: 0.7955\n",
      "125/125 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "\n",
      "Pseudo-label statistics (training):\n",
      "Group 0 pseudo-positive rate: 0.4972\n",
      "Group 1 pseudo-positive rate: 0.5022\n",
      "\n",
      "Training baseline [BIASED] logistic regression classifier (X → Y)...\n",
      "\n",
      "Training fair logistic regression classifier (X → Y') using pseudo-labels...\n",
      "\n",
      "Baseline Logistic Regression (X → Y) Evaluation:\n",
      "AUC: 0.9450, Accuracy: 0.8470\n",
      "Fairness metrics: {'demographic_parity_difference': 0.2998496240601503, 'equalized_odds_difference': 0.5809983620242689, 'selection_rate': {0: 0.3485714285714286, 1: 0.6484210526315789}, 'group_accuracy': {0: 0.8666666666666667, 1: 0.8252631578947368}}\n",
      "\n",
      "Fair Logistic Regression (X → Y') Evaluation (compared to observed Y):\n",
      "AUC: 0.9917, Accuracy: 0.9530\n",
      "Fairness metrics: {'demographic_parity_difference': 0.06967418546365911, 'equalized_odds_difference': 0.11868953119923194, 'selection_rate': {0: 0.4419047619047619, 1: 0.511578947368421}, 'group_accuracy': {0: 0.9523809523809523, 1: 0.9536842105263158}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main_synthetic(4.0, 72, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53f08737-2fab-439f-aef0-27536aa9cf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training adversarial model (X → Y' with adversary) ...\n",
      "Epoch 1/64\n",
      "32/32 [==============================] - 2s 11ms/step - loss: 4.3876 - pseudo_Y_loss: 0.9277 - S_pred_loss: 0.7965 - Y_pred_loss: 1.0703 - pseudo_Y_accuracy: 0.4837 - S_pred_accuracy: 0.4848 - Y_pred_accuracy: 0.3927\n",
      "Epoch 2/64\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 4.3707 - pseudo_Y_loss: 0.9013 - S_pred_loss: 0.8247 - Y_pred_loss: 0.9953 - pseudo_Y_accuracy: 0.4997 - S_pred_accuracy: 0.4120 - Y_pred_accuracy: 0.4060\n",
      "Epoch 3/64\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 4.2791 - pseudo_Y_loss: 0.8815 - S_pred_loss: 0.8223 - Y_pred_loss: 0.9308 - pseudo_Y_accuracy: 0.5230 - S_pred_accuracy: 0.3685 - Y_pred_accuracy: 0.4240\n",
      "Epoch 4/64\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.1395 - pseudo_Y_loss: 0.8654 - S_pred_loss: 0.7992 - Y_pred_loss: 0.8767 - pseudo_Y_accuracy: 0.5328 - S_pred_accuracy: 0.3230 - Y_pred_accuracy: 0.4417\n",
      "Epoch 5/64\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9751 - pseudo_Y_loss: 0.8494 - S_pred_loss: 0.7627 - Y_pred_loss: 0.8375 - pseudo_Y_accuracy: 0.5490 - S_pred_accuracy: 0.3002 - Y_pred_accuracy: 0.4622\n",
      "Epoch 6/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8177 - pseudo_Y_loss: 0.8364 - S_pred_loss: 0.7250 - Y_pred_loss: 0.8063 - pseudo_Y_accuracy: 0.5548 - S_pred_accuracy: 0.2928 - Y_pred_accuracy: 0.4905\n",
      "Epoch 7/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6651 - pseudo_Y_loss: 0.8163 - S_pred_loss: 0.6905 - Y_pred_loss: 0.7774 - pseudo_Y_accuracy: 0.5617 - S_pred_accuracy: 0.5510 - Y_pred_accuracy: 0.5203\n",
      "Epoch 8/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5305 - pseudo_Y_loss: 0.7932 - S_pred_loss: 0.6612 - Y_pred_loss: 0.7537 - pseudo_Y_accuracy: 0.5740 - S_pred_accuracy: 0.7193 - Y_pred_accuracy: 0.5355\n",
      "Epoch 9/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4336 - pseudo_Y_loss: 0.7718 - S_pred_loss: 0.6418 - Y_pred_loss: 0.7362 - pseudo_Y_accuracy: 0.5860 - S_pred_accuracy: 0.7143 - Y_pred_accuracy: 0.5495\n",
      "Epoch 10/64\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.3732 - pseudo_Y_loss: 0.7498 - S_pred_loss: 0.6348 - Y_pred_loss: 0.7191 - pseudo_Y_accuracy: 0.5925 - S_pred_accuracy: 0.6885 - Y_pred_accuracy: 0.5650\n",
      "Epoch 11/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3694 - pseudo_Y_loss: 0.7299 - S_pred_loss: 0.6442 - Y_pred_loss: 0.7071 - pseudo_Y_accuracy: 0.6022 - S_pred_accuracy: 0.6463 - Y_pred_accuracy: 0.5773\n",
      "Epoch 12/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4306 - pseudo_Y_loss: 0.7160 - S_pred_loss: 0.6715 - Y_pred_loss: 0.7001 - pseudo_Y_accuracy: 0.6000 - S_pred_accuracy: 0.5872 - Y_pred_accuracy: 0.5800\n",
      "Epoch 13/64\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.5295 - pseudo_Y_loss: 0.7166 - S_pred_loss: 0.7062 - Y_pred_loss: 0.6942 - pseudo_Y_accuracy: 0.5995 - S_pred_accuracy: 0.5173 - Y_pred_accuracy: 0.5755\n",
      "Epoch 14/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6065 - pseudo_Y_loss: 0.7271 - S_pred_loss: 0.7294 - Y_pred_loss: 0.6911 - pseudo_Y_accuracy: 0.5855 - S_pred_accuracy: 0.4505 - Y_pred_accuracy: 0.5695\n",
      "Epoch 15/64\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.6196 - pseudo_Y_loss: 0.7425 - S_pred_loss: 0.7306 - Y_pred_loss: 0.6853 - pseudo_Y_accuracy: 0.5735 - S_pred_accuracy: 0.4070 - Y_pred_accuracy: 0.5688\n",
      "Epoch 16/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5604 - pseudo_Y_loss: 0.7417 - S_pred_loss: 0.7158 - Y_pred_loss: 0.6714 - pseudo_Y_accuracy: 0.5700 - S_pred_accuracy: 0.3857 - Y_pred_accuracy: 0.5900\n",
      "Epoch 17/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4855 - pseudo_Y_loss: 0.7338 - S_pred_loss: 0.6988 - Y_pred_loss: 0.6552 - pseudo_Y_accuracy: 0.5795 - S_pred_accuracy: 0.4277 - Y_pred_accuracy: 0.6210\n",
      "Epoch 18/64\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.4052 - pseudo_Y_loss: 0.7120 - S_pred_loss: 0.6864 - Y_pred_loss: 0.6339 - pseudo_Y_accuracy: 0.5975 - S_pred_accuracy: 0.6060 - Y_pred_accuracy: 0.6450\n",
      "Epoch 19/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3548 - pseudo_Y_loss: 0.6848 - S_pred_loss: 0.6843 - Y_pred_loss: 0.6172 - pseudo_Y_accuracy: 0.6155 - S_pred_accuracy: 0.5778 - Y_pred_accuracy: 0.6668\n",
      "Epoch 20/64\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.3289 - pseudo_Y_loss: 0.6572 - S_pred_loss: 0.6897 - Y_pred_loss: 0.6025 - pseudo_Y_accuracy: 0.6357 - S_pred_accuracy: 0.5365 - Y_pred_accuracy: 0.6777\n",
      "Epoch 21/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3152 - pseudo_Y_loss: 0.6319 - S_pred_loss: 0.6971 - Y_pred_loss: 0.5919 - pseudo_Y_accuracy: 0.6578 - S_pred_accuracy: 0.4965 - Y_pred_accuracy: 0.6805\n",
      "Epoch 22/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2967 - pseudo_Y_loss: 0.6127 - S_pred_loss: 0.7004 - Y_pred_loss: 0.5826 - pseudo_Y_accuracy: 0.6735 - S_pred_accuracy: 0.4585 - Y_pred_accuracy: 0.6830\n",
      "Epoch 23/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2666 - pseudo_Y_loss: 0.5987 - S_pred_loss: 0.6967 - Y_pred_loss: 0.5777 - pseudo_Y_accuracy: 0.6840 - S_pred_accuracy: 0.4588 - Y_pred_accuracy: 0.6845\n",
      "Epoch 24/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2340 - pseudo_Y_loss: 0.5925 - S_pred_loss: 0.6896 - Y_pred_loss: 0.5727 - pseudo_Y_accuracy: 0.6880 - S_pred_accuracy: 0.5523 - Y_pred_accuracy: 0.6933\n",
      "Epoch 25/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2043 - pseudo_Y_loss: 0.5833 - S_pred_loss: 0.6858 - Y_pred_loss: 0.5635 - pseudo_Y_accuracy: 0.6970 - S_pred_accuracy: 0.5732 - Y_pred_accuracy: 0.6963\n",
      "Epoch 26/64\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.2004 - pseudo_Y_loss: 0.5814 - S_pred_loss: 0.6874 - Y_pred_loss: 0.5567 - pseudo_Y_accuracy: 0.6988 - S_pred_accuracy: 0.5520 - Y_pred_accuracy: 0.7080\n",
      "Epoch 27/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2126 - pseudo_Y_loss: 0.5840 - S_pred_loss: 0.6926 - Y_pred_loss: 0.5508 - pseudo_Y_accuracy: 0.6973 - S_pred_accuracy: 0.5165 - Y_pred_accuracy: 0.7128\n",
      "Epoch 28/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2317 - pseudo_Y_loss: 0.5935 - S_pred_loss: 0.6968 - Y_pred_loss: 0.5479 - pseudo_Y_accuracy: 0.6957 - S_pred_accuracy: 0.4882 - Y_pred_accuracy: 0.7182\n",
      "Epoch 29/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2284 - pseudo_Y_loss: 0.5940 - S_pred_loss: 0.6974 - Y_pred_loss: 0.5422 - pseudo_Y_accuracy: 0.6915 - S_pred_accuracy: 0.4708 - Y_pred_accuracy: 0.7245\n",
      "Epoch 30/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2125 - pseudo_Y_loss: 0.5910 - S_pred_loss: 0.6951 - Y_pred_loss: 0.5361 - pseudo_Y_accuracy: 0.6957 - S_pred_accuracy: 0.4787 - Y_pred_accuracy: 0.7290\n",
      "Epoch 31/64\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.1934 - pseudo_Y_loss: 0.5843 - S_pred_loss: 0.6931 - Y_pred_loss: 0.5299 - pseudo_Y_accuracy: 0.7075 - S_pred_accuracy: 0.5038 - Y_pred_accuracy: 0.7322\n",
      "Epoch 32/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.1715 - pseudo_Y_loss: 0.5721 - S_pred_loss: 0.6926 - Y_pred_loss: 0.5215 - pseudo_Y_accuracy: 0.7145 - S_pred_accuracy: 0.5155 - Y_pred_accuracy: 0.7368\n",
      "Epoch 33/64\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.1556 - pseudo_Y_loss: 0.5592 - S_pred_loss: 0.6935 - Y_pred_loss: 0.5160 - pseudo_Y_accuracy: 0.7290 - S_pred_accuracy: 0.5063 - Y_pred_accuracy: 0.7398\n",
      "Epoch 34/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.1431 - pseudo_Y_loss: 0.5497 - S_pred_loss: 0.6938 - Y_pred_loss: 0.5120 - pseudo_Y_accuracy: 0.7293 - S_pred_accuracy: 0.4875 - Y_pred_accuracy: 0.7412\n",
      "Epoch 35/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.1270 - pseudo_Y_loss: 0.5411 - S_pred_loss: 0.6931 - Y_pred_loss: 0.5067 - pseudo_Y_accuracy: 0.7347 - S_pred_accuracy: 0.5090 - Y_pred_accuracy: 0.7365\n",
      "Epoch 36/64\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.1141 - pseudo_Y_loss: 0.5362 - S_pred_loss: 0.6917 - Y_pred_loss: 0.5028 - pseudo_Y_accuracy: 0.7385 - S_pred_accuracy: 0.5270 - Y_pred_accuracy: 0.7430\n",
      "Epoch 37/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.1098 - pseudo_Y_loss: 0.5360 - S_pred_loss: 0.6917 - Y_pred_loss: 0.4988 - pseudo_Y_accuracy: 0.7433 - S_pred_accuracy: 0.5285 - Y_pred_accuracy: 0.7510\n",
      "Epoch 38/64\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.1084 - pseudo_Y_loss: 0.5373 - S_pred_loss: 0.6929 - Y_pred_loss: 0.4924 - pseudo_Y_accuracy: 0.7492 - S_pred_accuracy: 0.5117 - Y_pred_accuracy: 0.7552\n",
      "Epoch 39/64\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.1034 - pseudo_Y_loss: 0.5364 - S_pred_loss: 0.6939 - Y_pred_loss: 0.4854 - pseudo_Y_accuracy: 0.7492 - S_pred_accuracy: 0.5015 - Y_pred_accuracy: 0.7600\n",
      "Epoch 40/64\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.1055 - pseudo_Y_loss: 0.5401 - S_pred_loss: 0.6941 - Y_pred_loss: 0.4831 - pseudo_Y_accuracy: 0.7495 - S_pred_accuracy: 0.4950 - Y_pred_accuracy: 0.7545\n",
      "Epoch 41/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.0991 - pseudo_Y_loss: 0.5385 - S_pred_loss: 0.6937 - Y_pred_loss: 0.4795 - pseudo_Y_accuracy: 0.7467 - S_pred_accuracy: 0.4960 - Y_pred_accuracy: 0.7663\n",
      "Epoch 42/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.0874 - pseudo_Y_loss: 0.5328 - S_pred_loss: 0.6934 - Y_pred_loss: 0.4744 - pseudo_Y_accuracy: 0.7530 - S_pred_accuracy: 0.4997 - Y_pred_accuracy: 0.7655\n",
      "Epoch 43/64\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.0763 - pseudo_Y_loss: 0.5259 - S_pred_loss: 0.6933 - Y_pred_loss: 0.4704 - pseudo_Y_accuracy: 0.7560 - S_pred_accuracy: 0.4963 - Y_pred_accuracy: 0.7720\n",
      "Epoch 44/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.0688 - pseudo_Y_loss: 0.5214 - S_pred_loss: 0.6932 - Y_pred_loss: 0.4679 - pseudo_Y_accuracy: 0.7628 - S_pred_accuracy: 0.5013 - Y_pred_accuracy: 0.7713\n",
      "Epoch 45/64\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.0586 - pseudo_Y_loss: 0.5151 - S_pred_loss: 0.6929 - Y_pred_loss: 0.4647 - pseudo_Y_accuracy: 0.7663 - S_pred_accuracy: 0.5005 - Y_pred_accuracy: 0.7700\n",
      "Epoch 46/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.0555 - pseudo_Y_loss: 0.5147 - S_pred_loss: 0.6928 - Y_pred_loss: 0.4625 - pseudo_Y_accuracy: 0.7653 - S_pred_accuracy: 0.5115 - Y_pred_accuracy: 0.7738\n",
      "Epoch 47/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.0570 - pseudo_Y_loss: 0.5163 - S_pred_loss: 0.6929 - Y_pred_loss: 0.4622 - pseudo_Y_accuracy: 0.7703 - S_pred_accuracy: 0.5142 - Y_pred_accuracy: 0.7720\n",
      "Epoch 48/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.0425 - pseudo_Y_loss: 0.5102 - S_pred_loss: 0.6930 - Y_pred_loss: 0.4534 - pseudo_Y_accuracy: 0.7732 - S_pred_accuracy: 0.5117 - Y_pred_accuracy: 0.7775\n",
      "Epoch 49/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.0436 - pseudo_Y_loss: 0.5125 - S_pred_loss: 0.6932 - Y_pred_loss: 0.4515 - pseudo_Y_accuracy: 0.7703 - S_pred_accuracy: 0.5145 - Y_pred_accuracy: 0.7828\n",
      "Epoch 50/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.0380 - pseudo_Y_loss: 0.5114 - S_pred_loss: 0.6934 - Y_pred_loss: 0.4463 - pseudo_Y_accuracy: 0.7715 - S_pred_accuracy: 0.5005 - Y_pred_accuracy: 0.7887\n",
      "Epoch 51/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.0405 - pseudo_Y_loss: 0.5126 - S_pred_loss: 0.6932 - Y_pred_loss: 0.4483 - pseudo_Y_accuracy: 0.7765 - S_pred_accuracy: 0.4940 - Y_pred_accuracy: 0.7875\n",
      "Epoch 52/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.0289 - pseudo_Y_loss: 0.5059 - S_pred_loss: 0.6931 - Y_pred_loss: 0.4437 - pseudo_Y_accuracy: 0.7815 - S_pred_accuracy: 0.4955 - Y_pred_accuracy: 0.7875\n",
      "Epoch 53/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.0223 - pseudo_Y_loss: 0.5030 - S_pred_loss: 0.6929 - Y_pred_loss: 0.4405 - pseudo_Y_accuracy: 0.7818 - S_pred_accuracy: 0.5020 - Y_pred_accuracy: 0.7893\n",
      "Epoch 54/64\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.0144 - pseudo_Y_loss: 0.4992 - S_pred_loss: 0.6928 - Y_pred_loss: 0.4369 - pseudo_Y_accuracy: 0.7853 - S_pred_accuracy: 0.5092 - Y_pred_accuracy: 0.7895\n",
      "Epoch 55/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.0078 - pseudo_Y_loss: 0.4968 - S_pred_loss: 0.6928 - Y_pred_loss: 0.4326 - pseudo_Y_accuracy: 0.7930 - S_pred_accuracy: 0.5140 - Y_pred_accuracy: 0.7915\n",
      "Epoch 56/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.0080 - pseudo_Y_loss: 0.4982 - S_pred_loss: 0.6930 - Y_pred_loss: 0.4308 - pseudo_Y_accuracy: 0.7912 - S_pred_accuracy: 0.5063 - Y_pred_accuracy: 0.7943\n",
      "Epoch 57/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.0081 - pseudo_Y_loss: 0.4988 - S_pred_loss: 0.6932 - Y_pred_loss: 0.4299 - pseudo_Y_accuracy: 0.7893 - S_pred_accuracy: 0.5055 - Y_pred_accuracy: 0.7977\n",
      "Epoch 58/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.0043 - pseudo_Y_loss: 0.4976 - S_pred_loss: 0.6932 - Y_pred_loss: 0.4272 - pseudo_Y_accuracy: 0.7872 - S_pred_accuracy: 0.5033 - Y_pred_accuracy: 0.8005\n",
      "Epoch 59/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.0003 - pseudo_Y_loss: 0.4968 - S_pred_loss: 0.6931 - Y_pred_loss: 0.4242 - pseudo_Y_accuracy: 0.7897 - S_pred_accuracy: 0.4967 - Y_pred_accuracy: 0.7993\n",
      "Epoch 60/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.9965 - pseudo_Y_loss: 0.4936 - S_pred_loss: 0.6930 - Y_pred_loss: 0.4240 - pseudo_Y_accuracy: 0.7943 - S_pred_accuracy: 0.5008 - Y_pred_accuracy: 0.7985\n",
      "Epoch 61/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.9884 - pseudo_Y_loss: 0.4903 - S_pred_loss: 0.6929 - Y_pred_loss: 0.4193 - pseudo_Y_accuracy: 0.7995 - S_pred_accuracy: 0.5060 - Y_pred_accuracy: 0.8040\n",
      "Epoch 62/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.9890 - pseudo_Y_loss: 0.4912 - S_pred_loss: 0.6930 - Y_pred_loss: 0.4188 - pseudo_Y_accuracy: 0.7922 - S_pred_accuracy: 0.5090 - Y_pred_accuracy: 0.8058\n",
      "Epoch 63/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.9890 - pseudo_Y_loss: 0.4902 - S_pred_loss: 0.6929 - Y_pred_loss: 0.4201 - pseudo_Y_accuracy: 0.7962 - S_pred_accuracy: 0.5035 - Y_pred_accuracy: 0.8020\n",
      "Epoch 64/64\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.9819 - pseudo_Y_loss: 0.4865 - S_pred_loss: 0.6928 - Y_pred_loss: 0.4171 - pseudo_Y_accuracy: 0.8005 - S_pred_accuracy: 0.5067 - Y_pred_accuracy: 0.7968\n",
      "125/125 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "\n",
      "Pseudo-label statistics (training):\n",
      "Group 0 pseudo-positive rate: 0.4906\n",
      "Group 1 pseudo-positive rate: 0.5096\n",
      "\n",
      "Training baseline [BIASED] logistic regression classifier (X → Y)...\n",
      "\n",
      "Training fair logistic regression classifier (X → Y') using pseudo-labels...\n",
      "\n",
      "Baseline Logistic Regression (X → Y) Evaluation:\n",
      "AUC: 0.9450, Accuracy: 0.8470\n",
      "Fairness metrics: {'demographic_parity_difference': 0.2998496240601503, 'equalized_odds_difference': 0.5809983620242689, 'selection_rate': {0: 0.3485714285714286, 1: 0.6484210526315789}, 'group_accuracy': {0: 0.8666666666666667, 1: 0.8252631578947368}}\n",
      "\n",
      "Fair Logistic Regression (X → Y') Evaluation (compared to observed Y):\n",
      "AUC: 0.9918, Accuracy: 0.9520\n",
      "Fairness metrics: {'demographic_parity_difference': 0.0797994987468672, 'equalized_odds_difference': 0.1388321300244143, 'selection_rate': {0: 0.4380952380952381, 1: 0.5178947368421053}, 'group_accuracy': {0: 0.9523809523809523, 1: 0.9515789473684211}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main_synthetic(3.0, 64, 128) # working well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b86e898-d71b-42d7-a0d9-ca66501381ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### last thing to do -- need to hypertune \n",
    "### need to do synthetic dataset for a multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f65247ba-a7aa-4e3b-a8fb-a3ef2b7905e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing lambda_adv=1.0, epochs=32, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([643, 691]))\n",
      "  Fold 1: Score=-0.1702, Accuracy=0.8606, AUC=0.9402, Demographic Parity Diff=0.2464\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([650, 683]))\n",
      "  Fold 2: Score=-0.0248, Accuracy=0.8357, AUC=0.9351, Demographic Parity Diff=0.2245\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([657, 676]))\n",
      "  Fold 3: Score=0.1538, Accuracy=0.8725, AUC=0.9535, Demographic Parity Diff=0.2090\n",
      "  Final (Avg) for lambda_adv=1.0, epochs=32, batch_size=64: Score=-0.0138, Accuracy=0.8562, AUC=0.9429, Demographic Parity Diff=0.2266\n",
      "\n",
      "Testing lambda_adv=1.0, epochs=32, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([625, 709]))\n",
      "  Fold 1: Score=0.0554, Accuracy=0.8658, AUC=0.9521, Demographic Parity Diff=0.2203\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([584, 749]))\n",
      "  Fold 2: Score=-0.0642, Accuracy=0.8650, AUC=0.9454, Demographic Parity Diff=0.2343\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([602, 731]))\n",
      "  Fold 3: Score=0.0352, Accuracy=0.8447, AUC=0.9320, Demographic Parity Diff=0.2177\n",
      "  Final (Avg) for lambda_adv=1.0, epochs=32, batch_size=128: Score=0.0088, Accuracy=0.8585, AUC=0.9432, Demographic Parity Diff=0.2241\n",
      "\n",
      "Testing lambda_adv=1.0, epochs=64, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([659, 675]))\n",
      "  Fold 1: Score=0.0504, Accuracy=0.8733, AUC=0.9521, Demographic Parity Diff=0.2219\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([629, 704]))\n",
      "  Fold 2: Score=-0.2176, Accuracy=0.8612, AUC=0.9431, Demographic Parity Diff=0.2527\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([664, 669]))\n",
      "  Fold 3: Score=0.1276, Accuracy=0.8417, AUC=0.9361, Demographic Parity Diff=0.2063\n",
      "  Final (Avg) for lambda_adv=1.0, epochs=64, batch_size=64: Score=-0.0132, Accuracy=0.8587, AUC=0.9438, Demographic Parity Diff=0.2270\n",
      "\n",
      "Testing lambda_adv=1.0, epochs=64, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([626, 708]))\n",
      "  Fold 1: Score=-0.3067, Accuracy=0.8441, AUC=0.9362, Demographic Parity Diff=0.2609\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([648, 685]))\n",
      "  Fold 2: Score=0.3648, Accuracy=0.8425, AUC=0.9372, Demographic Parity Diff=0.1769\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([624, 709]))\n",
      "  Fold 3: Score=-0.0458, Accuracy=0.8807, AUC=0.9604, Demographic Parity Diff=0.2359\n",
      "  Final (Avg) for lambda_adv=1.0, epochs=64, batch_size=128: Score=0.0041, Accuracy=0.8558, AUC=0.9446, Demographic Parity Diff=0.2245\n",
      "\n",
      "Testing lambda_adv=1.0, epochs=72, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([641, 693]))\n",
      "  Fold 1: Score=-0.0496, Accuracy=0.8553, AUC=0.9430, Demographic Parity Diff=0.2310\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([675, 658]))\n",
      "  Fold 2: Score=0.1891, Accuracy=0.8597, AUC=0.9418, Demographic Parity Diff=0.2015\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([658, 675]))\n",
      "  Fold 3: Score=-0.1034, Accuracy=0.8582, AUC=0.9484, Demographic Parity Diff=0.2388\n",
      "  Final (Avg) for lambda_adv=1.0, epochs=72, batch_size=64: Score=0.0120, Accuracy=0.8578, AUC=0.9444, Demographic Parity Diff=0.2238\n",
      "\n",
      "Testing lambda_adv=1.0, epochs=72, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([629, 705]))\n",
      "  Fold 1: Score=-0.1191, Accuracy=0.8546, AUC=0.9403, Demographic Parity Diff=0.2392\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([647, 686]))\n",
      "  Fold 2: Score=-0.0237, Accuracy=0.8545, AUC=0.9419, Demographic Parity Diff=0.2275\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([649, 684]))\n",
      "  Fold 3: Score=0.0388, Accuracy=0.8612, AUC=0.9482, Demographic Parity Diff=0.2213\n",
      "  Final (Avg) for lambda_adv=1.0, epochs=72, batch_size=128: Score=-0.0347, Accuracy=0.8568, AUC=0.9435, Demographic Parity Diff=0.2294\n",
      "\n",
      "Testing lambda_adv=2.0, epochs=32, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([660, 674]))\n",
      "  Fold 1: Score=0.0185, Accuracy=0.8718, AUC=0.9560, Demographic Parity Diff=0.2262\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([628, 705]))\n",
      "  Fold 2: Score=-0.0970, Accuracy=0.8545, AUC=0.9406, Demographic Parity Diff=0.2365\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([620, 713]))\n",
      "  Fold 3: Score=0.0339, Accuracy=0.8462, AUC=0.9373, Demographic Parity Diff=0.2187\n",
      "  Final (Avg) for lambda_adv=2.0, epochs=32, batch_size=64: Score=-0.0148, Accuracy=0.8575, AUC=0.9446, Demographic Parity Diff=0.2271\n",
      "\n",
      "Testing lambda_adv=2.0, epochs=32, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([673, 661]))\n",
      "  Fold 1: Score=0.0967, Accuracy=0.8516, AUC=0.9375, Demographic Parity Diff=0.2115\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([665, 668]))\n",
      "  Fold 2: Score=-0.0612, Accuracy=0.8590, AUC=0.9467, Demographic Parity Diff=0.2334\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([603, 730]))\n",
      "  Fold 3: Score=-0.0684, Accuracy=0.8672, AUC=0.9452, Demographic Parity Diff=0.2351\n",
      "  Final (Avg) for lambda_adv=2.0, epochs=32, batch_size=128: Score=-0.0109, Accuracy=0.8593, AUC=0.9431, Demographic Parity Diff=0.2267\n",
      "\n",
      "Testing lambda_adv=2.0, epochs=64, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([677, 657]))\n",
      "  Fold 1: Score=0.0226, Accuracy=0.8553, AUC=0.9411, Demographic Parity Diff=0.2217\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([651, 682]))\n",
      "  Fold 2: Score=0.1657, Accuracy=0.8635, AUC=0.9433, Demographic Parity Diff=0.2051\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([654, 679]))\n",
      "  Fold 3: Score=-0.2614, Accuracy=0.8507, AUC=0.9467, Demographic Parity Diff=0.2574\n",
      "  Final (Avg) for lambda_adv=2.0, epochs=64, batch_size=64: Score=-0.0244, Accuracy=0.8565, AUC=0.9437, Demographic Parity Diff=0.2281\n",
      "\n",
      "Testing lambda_adv=2.0, epochs=64, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([652, 682]))\n",
      "  Fold 1: Score=0.0252, Accuracy=0.8658, AUC=0.9469, Demographic Parity Diff=0.2234\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([607, 726]))\n",
      "  Fold 2: Score=0.2608, Accuracy=0.8702, AUC=0.9526, Demographic Parity Diff=0.1953\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([639, 694]))\n",
      "  Fold 3: Score=-0.2206, Accuracy=0.8432, AUC=0.9330, Demographic Parity Diff=0.2496\n",
      "  Final (Avg) for lambda_adv=2.0, epochs=64, batch_size=128: Score=0.0218, Accuracy=0.8597, AUC=0.9441, Demographic Parity Diff=0.2228\n",
      "\n",
      "Testing lambda_adv=2.0, epochs=72, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([643, 691]))\n",
      "  Fold 1: Score=0.2337, Accuracy=0.8568, AUC=0.9452, Demographic Parity Diff=0.1960\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([636, 697]))\n",
      "  Fold 2: Score=-0.5241, Accuracy=0.8417, AUC=0.9365, Demographic Parity Diff=0.2878\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([630, 703]))\n",
      "  Fold 3: Score=0.3802, Accuracy=0.8792, AUC=0.9524, Demographic Parity Diff=0.1814\n",
      "  Final (Avg) for lambda_adv=2.0, epochs=72, batch_size=64: Score=0.0299, Accuracy=0.8593, AUC=0.9447, Demographic Parity Diff=0.2218\n",
      "\n",
      "Testing lambda_adv=2.0, epochs=72, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([633, 701]))\n",
      "  Fold 1: Score=-0.2823, Accuracy=0.8433, AUC=0.9359, Demographic Parity Diff=0.2577\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([682, 651]))\n",
      "  Fold 2: Score=-0.3213, Accuracy=0.8492, AUC=0.9411, Demographic Parity Diff=0.2639\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([635, 698]))\n",
      "  Fold 3: Score=0.5508, Accuracy=0.8747, AUC=0.9540, Demographic Parity Diff=0.1598\n",
      "  Final (Avg) for lambda_adv=2.0, epochs=72, batch_size=128: Score=-0.0176, Accuracy=0.8558, AUC=0.9437, Demographic Parity Diff=0.2271\n",
      "\n",
      "Testing lambda_adv=2.5, epochs=32, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([677, 657]))\n",
      "  Fold 1: Score=-0.2891, Accuracy=0.8351, AUC=0.9335, Demographic Parity Diff=0.2572\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([653, 680]))\n",
      "  Fold 2: Score=-0.0659, Accuracy=0.8785, AUC=0.9547, Demographic Parity Diff=0.2374\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([618, 715]))\n",
      "  Fold 3: Score=0.2791, Accuracy=0.8552, AUC=0.9413, Demographic Parity Diff=0.1897\n",
      "  Final (Avg) for lambda_adv=2.5, epochs=32, batch_size=64: Score=-0.0253, Accuracy=0.8563, AUC=0.9432, Demographic Parity Diff=0.2281\n",
      "\n",
      "Testing lambda_adv=2.5, epochs=32, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([685, 649]))\n",
      "  Fold 1: Score=-0.4795, Accuracy=0.8306, AUC=0.9334, Demographic Parity Diff=0.2804\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([588, 745]))\n",
      "  Fold 2: Score=-0.2042, Accuracy=0.8515, AUC=0.9389, Demographic Parity Diff=0.2493\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([680, 653]))\n",
      "  Fold 3: Score=0.2606, Accuracy=0.8687, AUC=0.9501, Demographic Parity Diff=0.1948\n",
      "  Final (Avg) for lambda_adv=2.5, epochs=32, batch_size=128: Score=-0.1410, Accuracy=0.8503, AUC=0.9408, Demographic Parity Diff=0.2415\n",
      "\n",
      "Testing lambda_adv=2.5, epochs=64, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([673, 661]))\n",
      "  Fold 1: Score=-0.4206, Accuracy=0.8523, AUC=0.9410, Demographic Parity Diff=0.2767\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([655, 678]))\n",
      "  Fold 2: Score=0.0259, Accuracy=0.8425, AUC=0.9385, Demographic Parity Diff=0.2194\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([631, 702]))\n",
      "  Fold 3: Score=0.2676, Accuracy=0.8717, AUC=0.9524, Demographic Parity Diff=0.1946\n",
      "  Final (Avg) for lambda_adv=2.5, epochs=64, batch_size=64: Score=-0.0424, Accuracy=0.8555, AUC=0.9440, Demographic Parity Diff=0.2302\n",
      "\n",
      "Testing lambda_adv=2.5, epochs=64, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([649, 685]))\n",
      "  Fold 1: Score=0.0657, Accuracy=0.8456, AUC=0.9384, Demographic Parity Diff=0.2148\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([691, 642]))\n",
      "  Fold 2: Score=0.0342, Accuracy=0.8665, AUC=0.9493, Demographic Parity Diff=0.2227\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([673, 660]))\n",
      "  Fold 3: Score=0.0125, Accuracy=0.8627, AUC=0.9446, Demographic Parity Diff=0.2244\n",
      "  Final (Avg) for lambda_adv=2.5, epochs=64, batch_size=128: Score=0.0375, Accuracy=0.8583, AUC=0.9441, Demographic Parity Diff=0.2206\n",
      "\n",
      "Testing lambda_adv=2.5, epochs=72, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([637, 697]))\n",
      "  Fold 1: Score=-0.2379, Accuracy=0.8508, AUC=0.9374, Demographic Parity Diff=0.2533\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([689, 644]))\n",
      "  Fold 2: Score=0.0950, Accuracy=0.8515, AUC=0.9381, Demographic Parity Diff=0.2118\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([611, 722]))\n",
      "  Fold 3: Score=0.1890, Accuracy=0.8702, AUC=0.9540, Demographic Parity Diff=0.2044\n",
      "  Final (Avg) for lambda_adv=2.5, epochs=72, batch_size=64: Score=0.0154, Accuracy=0.8575, AUC=0.9432, Demographic Parity Diff=0.2232\n",
      "\n",
      "Testing lambda_adv=2.5, epochs=72, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([652, 682]))\n",
      "  Fold 1: Score=0.0728, Accuracy=0.8501, AUC=0.9380, Demographic Parity Diff=0.2144\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([640, 693]))\n",
      "  Fold 2: Score=-0.1365, Accuracy=0.8537, AUC=0.9415, Demographic Parity Diff=0.2415\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([667, 666]))\n",
      "  Fold 3: Score=0.2311, Accuracy=0.8770, AUC=0.9530, Demographic Parity Diff=0.1999\n",
      "  Final (Avg) for lambda_adv=2.5, epochs=72, batch_size=128: Score=0.0558, Accuracy=0.8603, AUC=0.9442, Demographic Parity Diff=0.2186\n",
      "\n",
      "Testing lambda_adv=3.0, epochs=32, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([681, 653]))\n",
      "  Fold 1: Score=0.0086, Accuracy=0.8538, AUC=0.9435, Demographic Parity Diff=0.2236\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([645, 688]))\n",
      "  Fold 2: Score=0.1512, Accuracy=0.8560, AUC=0.9441, Demographic Parity Diff=0.2061\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([639, 694]))\n",
      "  Fold 3: Score=-0.2414, Accuracy=0.8597, AUC=0.9435, Demographic Parity Diff=0.2556\n",
      "  Final (Avg) for lambda_adv=3.0, epochs=32, batch_size=64: Score=-0.0272, Accuracy=0.8565, AUC=0.9437, Demographic Parity Diff=0.2284\n",
      "\n",
      "Testing lambda_adv=3.0, epochs=32, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([699, 635]))\n",
      "  Fold 1: Score=0.1677, Accuracy=0.8643, AUC=0.9473, Demographic Parity Diff=0.2055\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([639, 694]))\n",
      "  Fold 2: Score=0.3998, Accuracy=0.8762, AUC=0.9551, Demographic Parity Diff=0.1789\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([465, 868]))\n",
      "  Fold 3: Score=-0.4926, Accuracy=0.8372, AUC=0.9298, Demographic Parity Diff=0.2825\n",
      "  Final (Avg) for lambda_adv=3.0, epochs=32, batch_size=128: Score=0.0249, Accuracy=0.8592, AUC=0.9441, Demographic Parity Diff=0.2223\n",
      "\n",
      "Testing lambda_adv=3.0, epochs=64, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([694, 640]))\n",
      "  Fold 1: Score=0.1439, Accuracy=0.8643, AUC=0.9490, Demographic Parity Diff=0.2087\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([619, 714]))\n",
      "  Fold 2: Score=-0.1079, Accuracy=0.8477, AUC=0.9382, Demographic Parity Diff=0.2367\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([660, 673]))\n",
      "  Fold 3: Score=-0.0430, Accuracy=0.8582, AUC=0.9433, Demographic Parity Diff=0.2306\n",
      "  Final (Avg) for lambda_adv=3.0, epochs=64, batch_size=64: Score=-0.0023, Accuracy=0.8567, AUC=0.9435, Demographic Parity Diff=0.2253\n",
      "\n",
      "Testing lambda_adv=3.0, epochs=64, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([633, 701]))\n",
      "  Fold 1: Score=-0.1674, Accuracy=0.8621, AUC=0.9477, Demographic Parity Diff=0.2471\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([576, 757]))\n",
      "  Fold 2: Score=0.1321, Accuracy=0.8522, AUC=0.9419, Demographic Parity Diff=0.2077\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([672, 661]))\n",
      "  Fold 3: Score=-0.0750, Accuracy=0.8552, AUC=0.9413, Demographic Parity Diff=0.2339\n",
      "  Final (Avg) for lambda_adv=3.0, epochs=64, batch_size=128: Score=-0.0368, Accuracy=0.8565, AUC=0.9436, Demographic Parity Diff=0.2296\n",
      "\n",
      "Testing lambda_adv=3.0, epochs=72, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([678, 656]))\n",
      "  Fold 1: Score=-0.0883, Accuracy=0.8493, AUC=0.9331, Demographic Parity Diff=0.2338\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([681, 652]))\n",
      "  Fold 2: Score=-0.3653, Accuracy=0.8552, AUC=0.9417, Demographic Parity Diff=0.2703\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([670, 663]))\n",
      "  Fold 3: Score=0.4921, Accuracy=0.8732, AUC=0.9512, Demographic Parity Diff=0.1665\n",
      "  Final (Avg) for lambda_adv=3.0, epochs=72, batch_size=64: Score=0.0129, Accuracy=0.8593, AUC=0.9420, Demographic Parity Diff=0.2236\n",
      "\n",
      "Testing lambda_adv=3.0, epochs=72, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([678, 656]))\n",
      "  Fold 1: Score=-0.1815, Accuracy=0.8606, AUC=0.9484, Demographic Parity Diff=0.2488\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([650, 683]))\n",
      "  Fold 2: Score=0.1236, Accuracy=0.8522, AUC=0.9424, Demographic Parity Diff=0.2089\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([698, 635]))\n",
      "  Fold 3: Score=-0.0423, Accuracy=0.8552, AUC=0.9445, Demographic Parity Diff=0.2303\n",
      "  Final (Avg) for lambda_adv=3.0, epochs=72, batch_size=128: Score=-0.0334, Accuracy=0.8560, AUC=0.9451, Demographic Parity Diff=0.2293\n",
      "\n",
      "Testing lambda_adv=3.5, epochs=32, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([590, 744]))\n",
      "  Fold 1: Score=-0.3836, Accuracy=0.8403, AUC=0.9332, Demographic Parity Diff=0.2696\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([613, 720]))\n",
      "  Fold 2: Score=0.1682, Accuracy=0.8612, AUC=0.9441, Demographic Parity Diff=0.2046\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([641, 692]))\n",
      "  Fold 3: Score=0.2507, Accuracy=0.8672, AUC=0.9506, Demographic Parity Diff=0.1959\n",
      "  Final (Avg) for lambda_adv=3.5, epochs=32, batch_size=64: Score=0.0117, Accuracy=0.8563, AUC=0.9426, Demographic Parity Diff=0.2234\n",
      "\n",
      "Testing lambda_adv=3.5, epochs=32, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([777, 557]))\n",
      "  Fold 1: Score=0.3668, Accuracy=0.8643, AUC=0.9457, Demographic Parity Diff=0.1804\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([683, 650]))\n",
      "  Fold 2: Score=-0.3216, Accuracy=0.8425, AUC=0.9274, Demographic Parity Diff=0.2614\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([560, 773]))\n",
      "  Fold 3: Score=0.0046, Accuracy=0.8695, AUC=0.9533, Demographic Parity Diff=0.2273\n",
      "  Final (Avg) for lambda_adv=3.5, epochs=32, batch_size=128: Score=0.0166, Accuracy=0.8587, AUC=0.9421, Demographic Parity Diff=0.2230\n",
      "\n",
      "Testing lambda_adv=3.5, epochs=64, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([643, 691]))\n",
      "  Fold 1: Score=-0.0655, Accuracy=0.8711, AUC=0.9500, Demographic Parity Diff=0.2358\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([640, 693]))\n",
      "  Fold 2: Score=0.0369, Accuracy=0.8387, AUC=0.9276, Demographic Parity Diff=0.2162\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([638, 695]))\n",
      "  Fold 3: Score=0.0284, Accuracy=0.8657, AUC=0.9506, Demographic Parity Diff=0.2235\n",
      "  Final (Avg) for lambda_adv=3.5, epochs=64, batch_size=64: Score=-0.0001, Accuracy=0.8585, AUC=0.9427, Demographic Parity Diff=0.2252\n",
      "\n",
      "Testing lambda_adv=3.5, epochs=64, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([609, 725]))\n",
      "  Fold 1: Score=-0.2881, Accuracy=0.8478, AUC=0.9384, Demographic Parity Diff=0.2593\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([637, 696]))\n",
      "  Fold 2: Score=-0.0077, Accuracy=0.8395, AUC=0.9360, Demographic Parity Diff=0.2229\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([654, 679]))\n",
      "  Fold 3: Score=0.1965, Accuracy=0.8785, AUC=0.9563, Demographic Parity Diff=0.2048\n",
      "  Final (Avg) for lambda_adv=3.5, epochs=64, batch_size=128: Score=-0.0331, Accuracy=0.8553, AUC=0.9436, Demographic Parity Diff=0.2290\n",
      "\n",
      "Testing lambda_adv=3.5, epochs=72, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([683, 651]))\n",
      "  Fold 1: Score=0.0148, Accuracy=0.8651, AUC=0.9487, Demographic Parity Diff=0.2249\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([629, 704]))\n",
      "  Fold 2: Score=-0.2255, Accuracy=0.8380, AUC=0.9332, Demographic Parity Diff=0.2496\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([622, 711]))\n",
      "  Fold 3: Score=0.1914, Accuracy=0.8680, AUC=0.9505, Demographic Parity Diff=0.2034\n",
      "  Final (Avg) for lambda_adv=3.5, epochs=72, batch_size=64: Score=-0.0064, Accuracy=0.8570, AUC=0.9442, Demographic Parity Diff=0.2259\n",
      "\n",
      "Testing lambda_adv=3.5, epochs=72, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([658, 676]))\n",
      "  Fold 1: Score=0.1008, Accuracy=0.8546, AUC=0.9404, Demographic Parity Diff=0.2118\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([626, 707]))\n",
      "  Fold 2: Score=-0.0218, Accuracy=0.8440, AUC=0.9357, Demographic Parity Diff=0.2252\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([700, 633]))\n",
      "  Fold 3: Score=-0.1142, Accuracy=0.8710, AUC=0.9537, Demographic Parity Diff=0.2424\n",
      "  Final (Avg) for lambda_adv=3.5, epochs=72, batch_size=128: Score=-0.0117, Accuracy=0.8565, AUC=0.9433, Demographic Parity Diff=0.2264\n",
      "\n",
      "Testing lambda_adv=4.0, epochs=32, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([713, 621]))\n",
      "  Fold 1: Score=-0.1597, Accuracy=0.8501, AUC=0.9400, Demographic Parity Diff=0.2437\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([652, 681]))\n",
      "  Fold 2: Score=0.0981, Accuracy=0.8470, AUC=0.9379, Demographic Parity Diff=0.2108\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([616, 717]))\n",
      "  Fold 3: Score=-0.1944, Accuracy=0.8605, AUC=0.9510, Demographic Parity Diff=0.2507\n",
      "  Final (Avg) for lambda_adv=4.0, epochs=32, batch_size=64: Score=-0.0853, Accuracy=0.8525, AUC=0.9430, Demographic Parity Diff=0.2351\n",
      "\n",
      "Testing lambda_adv=4.0, epochs=32, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([652, 682]))\n",
      "  Fold 1: Score=-0.0008, Accuracy=0.8636, AUC=0.9451, Demographic Parity Diff=0.2262\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([602, 731]))\n",
      "  Fold 2: Score=-0.0686, Accuracy=0.8530, AUC=0.9445, Demographic Parity Diff=0.2333\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([535, 798]))\n",
      "  Fold 3: Score=-0.0158, Accuracy=0.8537, AUC=0.9404, Demographic Parity Diff=0.2262\n",
      "  Final (Avg) for lambda_adv=4.0, epochs=32, batch_size=128: Score=-0.0284, Accuracy=0.8567, AUC=0.9433, Demographic Parity Diff=0.2286\n",
      "\n",
      "Testing lambda_adv=4.0, epochs=64, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([642, 692]))\n",
      "  Fold 1: Score=-0.0938, Accuracy=0.8643, AUC=0.9527, Demographic Parity Diff=0.2389\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([641, 692]))\n",
      "  Fold 2: Score=-0.2275, Accuracy=0.8395, AUC=0.9314, Demographic Parity Diff=0.2498\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([678, 655]))\n",
      "  Fold 3: Score=0.2760, Accuracy=0.8620, AUC=0.9441, Demographic Parity Diff=0.1913\n",
      "  Final (Avg) for lambda_adv=4.0, epochs=64, batch_size=64: Score=-0.0151, Accuracy=0.8552, AUC=0.9427, Demographic Parity Diff=0.2266\n",
      "\n",
      "Testing lambda_adv=4.0, epochs=64, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([646, 688]))\n",
      "  Fold 1: Score=-0.1904, Accuracy=0.8561, AUC=0.9433, Demographic Parity Diff=0.2487\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([540, 793]))\n",
      "  Fold 2: Score=0.0752, Accuracy=0.8627, AUC=0.9467, Demographic Parity Diff=0.2168\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([699, 634]))\n",
      "  Fold 3: Score=0.0656, Accuracy=0.8567, AUC=0.9443, Demographic Parity Diff=0.2169\n",
      "  Final (Avg) for lambda_adv=4.0, epochs=64, batch_size=128: Score=-0.0166, Accuracy=0.8585, AUC=0.9448, Demographic Parity Diff=0.2275\n",
      "\n",
      "Testing lambda_adv=4.0, epochs=72, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([641, 693]))\n",
      "  Fold 1: Score=0.0100, Accuracy=0.8628, AUC=0.9440, Demographic Parity Diff=0.2246\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([608, 725]))\n",
      "  Fold 2: Score=0.0995, Accuracy=0.8575, AUC=0.9409, Demographic Parity Diff=0.2124\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([655, 678]))\n",
      "  Fold 3: Score=0.1074, Accuracy=0.8612, AUC=0.9454, Demographic Parity Diff=0.2124\n",
      "  Final (Avg) for lambda_adv=4.0, epochs=72, batch_size=64: Score=0.0723, Accuracy=0.8605, AUC=0.9434, Demographic Parity Diff=0.2165\n",
      "\n",
      "Testing lambda_adv=4.0, epochs=72, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([635, 699]))\n",
      "  Fold 1: Score=0.1059, Accuracy=0.8591, AUC=0.9373, Demographic Parity Diff=0.2113\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([668, 665]))\n",
      "  Fold 2: Score=-0.0823, Accuracy=0.8500, AUC=0.9396, Demographic Parity Diff=0.2340\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([669, 664]))\n",
      "  Fold 3: Score=0.2267, Accuracy=0.8725, AUC=0.9539, Demographic Parity Diff=0.2000\n",
      "  Final (Avg) for lambda_adv=4.0, epochs=72, batch_size=128: Score=0.0834, Accuracy=0.8605, AUC=0.9436, Demographic Parity Diff=0.2151\n",
      "\n",
      "Testing lambda_adv=4.5, epochs=32, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([639, 695]))\n",
      "  Fold 1: Score=0.2181, Accuracy=0.8628, AUC=0.9474, Demographic Parity Diff=0.1990\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([657, 676]))\n",
      "  Fold 2: Score=-0.4431, Accuracy=0.8365, AUC=0.9227, Demographic Parity Diff=0.2753\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([643, 690]))\n",
      "  Fold 3: Score=0.2372, Accuracy=0.8710, AUC=0.9571, Demographic Parity Diff=0.1989\n",
      "  Final (Avg) for lambda_adv=4.5, epochs=32, batch_size=64: Score=0.0041, Accuracy=0.8567, AUC=0.9424, Demographic Parity Diff=0.2244\n",
      "\n",
      "Testing lambda_adv=4.5, epochs=32, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([637, 697]))\n",
      "  Fold 1: Score=-0.3117, Accuracy=0.8463, AUC=0.9384, Demographic Parity Diff=0.2621\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([676, 657]))\n",
      "  Fold 2: Score=0.1364, Accuracy=0.8590, AUC=0.9486, Demographic Parity Diff=0.2089\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([660, 673]))\n",
      "  Fold 3: Score=0.1346, Accuracy=0.8642, AUC=0.9446, Demographic Parity Diff=0.2093\n",
      "  Final (Avg) for lambda_adv=4.5, epochs=32, batch_size=128: Score=-0.0136, Accuracy=0.8565, AUC=0.9439, Demographic Parity Diff=0.2267\n",
      "\n",
      "Testing lambda_adv=4.5, epochs=64, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([628, 706]))\n",
      "  Fold 1: Score=-0.0912, Accuracy=0.8546, AUC=0.9448, Demographic Parity Diff=0.2363\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([636, 697]))\n",
      "  Fold 2: Score=-0.3445, Accuracy=0.8447, AUC=0.9343, Demographic Parity Diff=0.2654\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([698, 635]))\n",
      "  Fold 3: Score=0.3487, Accuracy=0.8680, AUC=0.9511, Demographic Parity Diff=0.1838\n",
      "  Final (Avg) for lambda_adv=4.5, epochs=64, batch_size=64: Score=-0.0290, Accuracy=0.8558, AUC=0.9434, Demographic Parity Diff=0.2285\n",
      "\n",
      "Testing lambda_adv=4.5, epochs=64, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([715, 619]))\n",
      "  Fold 1: Score=0.1564, Accuracy=0.8763, AUC=0.9592, Demographic Parity Diff=0.2099\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([622, 711]))\n",
      "  Fold 2: Score=-0.1808, Accuracy=0.8447, AUC=0.9294, Demographic Parity Diff=0.2444\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([620, 713]))\n",
      "  Fold 3: Score=0.1957, Accuracy=0.8530, AUC=0.9412, Demographic Parity Diff=0.1998\n",
      "  Final (Avg) for lambda_adv=4.5, epochs=64, batch_size=128: Score=0.0571, Accuracy=0.8580, AUC=0.9433, Demographic Parity Diff=0.2180\n",
      "\n",
      "Testing lambda_adv=4.5, epochs=72, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([639, 695]))\n",
      "  Fold 1: Score=-0.1527, Accuracy=0.8471, AUC=0.9342, Demographic Parity Diff=0.2417\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([681, 652]))\n",
      "  Fold 2: Score=0.2247, Accuracy=0.8702, AUC=0.9515, Demographic Parity Diff=0.1996\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([676, 657]))\n",
      "  Fold 3: Score=-0.0039, Accuracy=0.8582, AUC=0.9435, Demographic Parity Diff=0.2257\n",
      "  Final (Avg) for lambda_adv=4.5, epochs=72, batch_size=64: Score=0.0227, Accuracy=0.8585, AUC=0.9430, Demographic Parity Diff=0.2224\n",
      "\n",
      "Testing lambda_adv=4.5, epochs=72, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([639, 695]))\n",
      "  Fold 1: Score=-0.3764, Accuracy=0.8328, AUC=0.9254, Demographic Parity Diff=0.2668\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([540, 793]))\n",
      "  Fold 2: Score=0.0367, Accuracy=0.8605, AUC=0.9433, Demographic Parity Diff=0.2209\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([715, 618]))\n",
      "  Fold 3: Score=0.1634, Accuracy=0.8732, AUC=0.9588, Demographic Parity Diff=0.2086\n",
      "  Final (Avg) for lambda_adv=4.5, epochs=72, batch_size=128: Score=-0.0588, Accuracy=0.8555, AUC=0.9425, Demographic Parity Diff=0.2321\n",
      "\n",
      "Testing lambda_adv=5.0, epochs=32, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([703, 631]))\n",
      "  Fold 1: Score=0.1768, Accuracy=0.8508, AUC=0.9332, Demographic Parity Diff=0.2009\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([637, 696]))\n",
      "  Fold 2: Score=-0.0776, Accuracy=0.8665, AUC=0.9452, Demographic Parity Diff=0.2362\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([645, 688]))\n",
      "  Fold 3: Score=0.0605, Accuracy=0.8702, AUC=0.9523, Demographic Parity Diff=0.2203\n",
      "  Final (Avg) for lambda_adv=5.0, epochs=32, batch_size=64: Score=0.0533, Accuracy=0.8625, AUC=0.9436, Demographic Parity Diff=0.2191\n",
      "\n",
      "Testing lambda_adv=5.0, epochs=32, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([778, 556]))\n",
      "  Fold 1: Score=0.4332, Accuracy=0.8703, AUC=0.9557, Demographic Parity Diff=0.1741\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([600, 733]))\n",
      "  Fold 2: Score=-0.1251, Accuracy=0.8642, AUC=0.9456, Demographic Parity Diff=0.2419\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([647, 686]))\n",
      "  Fold 3: Score=-0.4923, Accuracy=0.8222, AUC=0.9162, Demographic Parity Diff=0.2788\n",
      "  Final (Avg) for lambda_adv=5.0, epochs=32, batch_size=128: Score=-0.0614, Accuracy=0.8522, AUC=0.9392, Demographic Parity Diff=0.2316\n",
      "\n",
      "Testing lambda_adv=5.0, epochs=64, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([667, 667]))\n",
      "  Fold 1: Score=0.0747, Accuracy=0.8561, AUC=0.9424, Demographic Parity Diff=0.2155\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([665, 668]))\n",
      "  Fold 2: Score=0.2216, Accuracy=0.8717, AUC=0.9530, Demographic Parity Diff=0.2004\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([703, 630]))\n",
      "  Fold 3: Score=-0.3364, Accuracy=0.8402, AUC=0.9355, Demographic Parity Diff=0.2640\n",
      "  Final (Avg) for lambda_adv=5.0, epochs=64, batch_size=64: Score=-0.0133, Accuracy=0.8560, AUC=0.9436, Demographic Parity Diff=0.2266\n",
      "\n",
      "Testing lambda_adv=5.0, epochs=64, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([604, 730]))\n",
      "  Fold 1: Score=0.3707, Accuracy=0.8561, AUC=0.9440, Demographic Parity Diff=0.1787\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([545, 788]))\n",
      "  Fold 2: Score=0.0913, Accuracy=0.8627, AUC=0.9476, Demographic Parity Diff=0.2149\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([639, 694]))\n",
      "  Fold 3: Score=-0.4312, Accuracy=0.8545, AUC=0.9417, Demographic Parity Diff=0.2784\n",
      "  Final (Avg) for lambda_adv=5.0, epochs=64, batch_size=128: Score=0.0103, Accuracy=0.8578, AUC=0.9445, Demographic Parity Diff=0.2240\n",
      "\n",
      "Testing lambda_adv=5.0, epochs=72, batch_size=64\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([705, 629]))\n",
      "  Fold 1: Score=-0.0841, Accuracy=0.8561, AUC=0.9416, Demographic Parity Diff=0.2352\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([646, 687]))\n",
      "  Fold 2: Score=-0.0497, Accuracy=0.8440, AUC=0.9334, Demographic Parity Diff=0.2284\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([624, 709]))\n",
      "  Fold 3: Score=0.0839, Accuracy=0.8620, AUC=0.9523, Demographic Parity Diff=0.2163\n",
      "  Final (Avg) for lambda_adv=5.0, epochs=72, batch_size=64: Score=-0.0166, Accuracy=0.8540, AUC=0.9424, Demographic Parity Diff=0.2266\n",
      "\n",
      "Testing lambda_adv=5.0, epochs=72, batch_size=128\n",
      "Fold 1 - Sample Predictions: (array([0., 1.], dtype=float32), array([600, 734]))\n",
      "  Fold 1: Score=0.2907, Accuracy=0.8703, AUC=0.9436, Demographic Parity Diff=0.1904\n",
      "Fold 2 - Sample Predictions: (array([0., 1.], dtype=float32), array([623, 710]))\n",
      "  Fold 2: Score=-0.2719, Accuracy=0.8522, AUC=0.9381, Demographic Parity Diff=0.2578\n",
      "Fold 3 - Sample Predictions: (array([0., 1.], dtype=float32), array([635, 698]))\n",
      "  Fold 3: Score=0.0691, Accuracy=0.8620, AUC=0.9525, Demographic Parity Diff=0.2182\n",
      "  Final (Avg) for lambda_adv=5.0, epochs=72, batch_size=128: Score=0.0293, Accuracy=0.8615, AUC=0.9447, Demographic Parity Diff=0.2221\n",
      "\n",
      "Best Hyperparameters: lambda_adv                   4.000000\n",
      "epochs                      72.000000\n",
      "batch_size                 128.000000\n",
      "score                        0.083409\n",
      "accuracy                     0.860500\n",
      "auc                          0.943612\n",
      "demographic_parity_diff      0.215088\n",
      "Name: 35, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "class AdversarialModelWrapperFixed(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Fixed Wrapper for Adversarial Model to work with Grid Search (Binary Version).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lambda_adv=1.0, epochs=64, batch_size=128):\n",
    "        self.lambda_adv = lambda_adv\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y, S):\n",
    "        \"\"\"\n",
    "        Train the adversarial model. S is passed dynamically per fold.\n",
    "        \"\"\"\n",
    "        y = y.reshape(-1, 1)  # Convert `y` to 2D array for binary classification\n",
    "        input_dim = X.shape[1]\n",
    "        S_oh = tf.keras.utils.to_categorical(S, num_classes=2)\n",
    "\n",
    "        # Ensure model is reinitialized for every fold\n",
    "        tf.keras.backend.clear_session()\n",
    "        self.model = build_adversarial_model(input_dim, lambda_adv=self.lambda_adv)\n",
    "\n",
    "        self.model.fit(\n",
    "            [X, S_oh],\n",
    "            {\"pseudo_Y\": y, \"S_pred\": S_oh, \"Y_pred\": y},\n",
    "            epochs=self.epochs,\n",
    "            batch_size=self.batch_size,\n",
    "            verbose=0\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, S):\n",
    "        \"\"\"\n",
    "        Generate predictions from the trained model. S must match X per fold.\n",
    "        \"\"\"\n",
    "        S_oh = tf.keras.utils.to_categorical(S, num_classes=2)\n",
    "        pseudo_Y, _, _ = self.model.predict([X, S_oh], verbose=0)\n",
    "        return (pseudo_Y > 0.5).astype(np.float32).flatten()  # Convert to binary predictions (0 or 1)\n",
    "\n",
    "    def score(self, X_train, Y_train_biased_pred, X_test, Y_test_biased_pred, Y_train_raw, Y_test_raw, S_train, S_test, return_metrics=False):\n",
    "        \"\"\"\n",
    "        Compute the optimization score combining AUC, accuracy, and fairness metrics.\n",
    "        \"\"\"\n",
    "        auc, acc, fairness_metrics = run_biased_logistic(\n",
    "            X_train, Y_train_biased_pred, X_test, Y_test_biased_pred, \n",
    "            Y_train_raw, Y_test_raw, S_train, S_test\n",
    "        )\n",
    "        \n",
    "        demographic_parity_diff = abs(fairness_metrics[\"demographic_parity_difference\"])\n",
    "\n",
    "        # Objective function (equal weights for now)\n",
    "        alpha = 8\n",
    "        score = auc + acc - alpha * demographic_parity_diff\n",
    "\n",
    "        if return_metrics:\n",
    "            return score, acc, auc, demographic_parity_diff\n",
    "        return score\n",
    "\n",
    "\n",
    "# Load binary synthetic dataset\n",
    "set_seed(42)\n",
    "X_train, X_test, Y_train_raw, Y_test_raw, S_train, S_test = generate_synthetic_data()\n",
    "Y_train_biased, Y_test_biased = inject_bias(bias_factor=0.3, seed=42)\n",
    "\n",
    "# Ensure `Y_train_biased` remains a **binary 1D array**\n",
    "Y_train_biased = Y_train_biased.ravel()\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    \"lambda_adv\": [1.0, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0],\n",
    "    \"epochs\": [32, 64, 72],\n",
    "    \"batch_size\": [64, 128]\n",
    "}\n",
    "\n",
    "# Custom cross-validation (Ensure stratification works correctly for binary classification)\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=None)  # Removing fixed random_state\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Perform manual grid search\n",
    "for lambda_adv, epochs, batch_size in product(param_grid[\"lambda_adv\"], param_grid[\"epochs\"], param_grid[\"batch_size\"]):\n",
    "    scores, accuracies, aucs, demographic_parity_diffs = [], [], [], []\n",
    "    \n",
    "    print(f\"\\nTesting lambda_adv={lambda_adv}, epochs={epochs}, batch_size={batch_size}\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, Y_train_biased)):  # Ensure Y_train_biased is used for stratification\n",
    "        # Split data\n",
    "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "        Y_train_fold, Y_val_fold = Y_train_biased[train_idx], Y_train_biased[val_idx]\n",
    "        S_train_fold, S_val_fold = S_train[train_idx], S_train[val_idx]\n",
    "\n",
    "        # Train model\n",
    "        model = AdversarialModelWrapperFixed(lambda_adv=lambda_adv, epochs=epochs, batch_size=batch_size)\n",
    "        model.fit(X_train_fold, Y_train_fold, S=S_train_fold)\n",
    "\n",
    "        # Evaluate model (Pass required arguments to `score`)\n",
    "        score, accuracy, auc, demographic_parity_diff = model.score(\n",
    "            X_train_fold, Y_train_fold, \n",
    "            X_val_fold, Y_val_fold, \n",
    "            Y_train_raw[train_idx], Y_train_raw[val_idx],  \n",
    "            S_train_fold, S_val_fold, \n",
    "            return_metrics=True\n",
    "        )\n",
    "\n",
    "        # Debug: Check if predictions are changing\n",
    "        preds = model.predict(X_val_fold, S_val_fold)\n",
    "        print(f\"Fold {fold + 1} - Sample Predictions: {np.unique(preds, return_counts=True)}\")  # Ensure different outputs\n",
    "\n",
    "        # Store fold results\n",
    "        scores.append(score)\n",
    "        accuracies.append(accuracy)\n",
    "        aucs.append(auc)\n",
    "        demographic_parity_diffs.append(demographic_parity_diff)\n",
    "\n",
    "        # Print results per fold\n",
    "        print(f\"  Fold {fold + 1}: Score={score:.4f}, Accuracy={accuracy:.4f}, AUC={auc:.4f}, Demographic Parity Diff={demographic_parity_diff:.4f}\")\n",
    "\n",
    "    # Store average scores across folds\n",
    "    avg_score = np.mean(scores)\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    avg_auc = np.mean(aucs)\n",
    "    avg_demographic_parity_diff = np.mean(demographic_parity_diffs)\n",
    "\n",
    "    results.append({\n",
    "        \"lambda_adv\": lambda_adv,\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"score\": avg_score,\n",
    "        \"accuracy\": avg_accuracy,\n",
    "        \"auc\": avg_auc,\n",
    "        \"demographic_parity_diff\": avg_demographic_parity_diff\n",
    "    })\n",
    "\n",
    "    print(f\"  Final (Avg) for lambda_adv={lambda_adv}, epochs={epochs}, batch_size={batch_size}: \"\n",
    "          f\"Score={avg_score:.4f}, Accuracy={avg_accuracy:.4f}, AUC={avg_auc:.4f}, Demographic Parity Diff={avg_demographic_parity_diff:.4f}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Find best hyperparameters\n",
    "best_params = results_df.loc[results_df[\"score\"].idxmax()]\n",
    "print(\"\\nBest Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e4102-7834-4fa7-861c-33a025a58553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ebd500-9c2a-4fbc-b363-fd79165e2187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
