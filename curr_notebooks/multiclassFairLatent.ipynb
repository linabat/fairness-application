{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24672b93-3c9d-4e08-98b2-b6a106a323bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Conv2D, Flatten, \n",
    "    MaxPooling2D, BatchNormalization, Dropout\n",
    ")\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    LearningRateScheduler\n",
    ")\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.initializers import Constant\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tqdm import tqdm\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Conv2D, Flatten, \n",
    "    MaxPooling2D, BatchNormalization, Dropout, Concatenate\n",
    ")\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    LearningRateScheduler\n",
    ")\n",
    "\n",
    "from tensorflow.keras.regularizers import Regularizer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a9af067-aa00-404e-9bbb-9fa55fd4367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Custom Gradient Reversal Layer\n",
    "# -------------------------------\n",
    "@tf.custom_gradient\n",
    "def grad_reverse(x, lambda_):\n",
    "    def grad(dy):\n",
    "        return -lambda_ * dy, None # reverses direction of gradient \n",
    "    return x, grad\n",
    "\n",
    "# custom Keras layer\n",
    "\"\"\"\n",
    "Layer is used to ensure that the feature representation are independent of a sensitive attribute\n",
    "- feature extract learns normally in the forward pass\n",
    "- reversing gradients of classifier that tries to predict the sensitive attribute during backpropagation -- stops feature extractor from encoding sensitive information\n",
    "\"\"\"\n",
    "class GradientReversalLayer(tf.keras.layers.Layer): \n",
    "    def __init__(self, lambda_=1.0, **kwargs):\n",
    "        super(GradientReversalLayer, self).__init__(**kwargs)\n",
    "        self.lambda_ = lambda_ # strength of gradient reversal\n",
    "    def call(self, x):\n",
    "        return grad_reverse(x, self.lambda_)\n",
    "\n",
    "# -------------------------------\n",
    "# Data Loading and Preprocessing\n",
    "# -------------------------------\n",
    "def set_seed(seed_num):\n",
    "    random.seed(seed_num)\n",
    "    np.random.seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98a279a6-a67d-4bab-8049-18a4eb1ab4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Adversarial Debiasing Model\n",
    "# -------------------------------\n",
    "\n",
    "## has been adjusted for multiclass\n",
    "def build_adversarial_model(input_dim, num_classes_Y, lambda_adv=1.0):\n",
    "    \"\"\"\n",
    "    Build an adversarial debiasing model that learns pseudo‑labels Y' from X.\n",
    "\n",
    "    Architecture:\n",
    "      - Main branch (encoder): from X, several dense layers produce a latent pseudo‑label pseudo_Y (via sigmoid).\n",
    "      - Adversary branch: pseudo_Y is passed through a Gradient Reversal Layer and then dense layers predict S.\n",
    "      - Decoder branch: concatenates pseudo_Y and the one-hot sensitive attribute S to predict the observed label Y.\n",
    "\n",
    "    Losses:\n",
    "      - For the main branch, binary crossentropy between observed Y and pseudo_Y (and Y_pred).\n",
    "      - For the adversary branch, categorical crossentropy to predict S.\n",
    "\n",
    "    Returns a compiled Keras model that takes inputs X and S (one-hot encoded) and outputs:\n",
    "      [pseudo_Y, S_pred, Y_pred].\n",
    "    \"\"\"\n",
    "    X_input = tf.keras.Input(shape=(input_dim,), name=\"X\")\n",
    "    S_input = tf.keras.Input(shape=(2,), name=\"S\")  # one-hot encoded S\n",
    "\n",
    "    # Main branch: Encoder for pseudo-label.\n",
    "    h = Dense(64, activation='relu')(X_input)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Dense(32, activation='relu')(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    pseudo_Y = Dense(num_classes_Y, activation='softmax', name=\"pseudo_Y\")(h) ## changed to softmax because multi-class\n",
    "\n",
    "    # Adversary branch: from pseudo_Y, with GRL.\n",
    "    \"\"\"\n",
    "    This is to prevent psuedo_Y from containing information about S\n",
    "    - adversary will try to predict S from pseudo_Y (fair label)...if it can accurately predict S, then Y' still encodes information about S (don't want this) \n",
    "    - use the gradient reversal layer to prevent this from happening\n",
    "    \"\"\"\n",
    "    grl = GradientReversalLayer(lambda_=lambda_adv)(pseudo_Y)\n",
    "    a = Dense(32, activation='relu')(grl)\n",
    "    a = BatchNormalization()(a)\n",
    "    S_pred = Dense(2, activation='softmax', name=\"S_pred\")(a)\n",
    "\n",
    "    # Decoder branch: combine pseudo_Y and S to predict observed Y.\n",
    "    concat = Concatenate()([pseudo_Y, S_input])\n",
    "    d = Dense(16, activation='relu')(concat)\n",
    "    d = BatchNormalization()(d)\n",
    "    Y_pred = Dense(num_classes_Y, activation='softmax', name=\"Y_pred\")(d) # changed from 1 to num_classes_Y, changed to softmax cause multi\n",
    "\n",
    "    model = tf.keras.Model(inputs=[X_input, S_input],\n",
    "                           outputs=[pseudo_Y, S_pred, Y_pred])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  loss={\"pseudo_Y\": \"categorical_crossentropy\", # changed from binary to categorical\n",
    "                        \"S_pred\": \"categorical_crossentropy\",\n",
    "                        \"Y_pred\": \"categorical_crossentropy\"}, # changed from binary to categorical\n",
    "                  loss_weights={\"pseudo_Y\": 1.0, \"S_pred\": lambda_adv, \"Y_pred\": 1.0},\n",
    "                  metrics={\"pseudo_Y\": \"accuracy\",\n",
    "                           \"S_pred\": \"accuracy\",\n",
    "                           \"Y_pred\": \"accuracy\"}) # Y_pred is the best estimate of Y accounting for fair dependencies \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdce495e-4c4f-4024-81ae-ec51509beaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def multi_compute_fairness_metrics_manual(y_true, y_pred, sensitive_features):\n",
    "    \"\"\"\n",
    "    Compute fairness metrics manually for multi-class classification.\n",
    "    \n",
    "    Args:\n",
    "      y_true: Ground-truth labels (1D numpy array, categorical).\n",
    "      y_pred: Predicted labels (1D numpy array, categorical).\n",
    "      sensitive_features: 1D numpy array (binary sensitive attribute).\n",
    "    \n",
    "    Returns:\n",
    "      Dictionary containing:\n",
    "        - Demographic parity difference\n",
    "        - Equalized odds difference\n",
    "        - Selection rates per group\n",
    "        - Group-wise accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure inputs are numpy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    sensitive_features = np.array(sensitive_features)\n",
    "\n",
    "    groups = np.unique(sensitive_features)  # Unique groups in sensitive attribute\n",
    "    classes = np.unique(y_true)  # Unique class labels\n",
    "\n",
    "    # -----------------------\n",
    "    # Demographic Parity Difference\n",
    "    # -----------------------\n",
    "    class_rates = {g: np.zeros(len(classes)) for g in groups}\n",
    "\n",
    "    for g in groups:\n",
    "        mask = (sensitive_features == g)  # Filter by group\n",
    "        for i, cl in enumerate(classes):  # Iterate over class labels\n",
    "            class_rates[g][i] = np.mean(y_pred[mask] == cl)  # Proportion of predictions for class c\n",
    "    \n",
    "    dp_diff = np.max([np.abs(class_rates[g1] - class_rates[g2]) \n",
    "                      for g1 in groups for g2 in groups if g1 != g2])\n",
    "\n",
    "    # -----------------------\n",
    "    # Equalized Odds Difference\n",
    "    # -----------------------\n",
    "    \"\"\"\n",
    "    Ensuring that different groups in the sensitive feature have similar TPR and FPR rates\n",
    "    This prevents the model from discriminating based on error types.\n",
    "    \"\"\"\n",
    "    metrics = {g: {c: {\"TPR\": 0, \"FPR\": 0} for c in classes} for g in groups}\n",
    "\n",
    "    y_true = np.argmax(y_true, axis=1) if len(y_true.shape) > 1 else y_true # categorical\n",
    "\n",
    "    for g in groups:\n",
    "        mask = (sensitive_features == g)\n",
    "        y_true_g = y_true[mask]\n",
    "        y_pred_g = y_pred[mask]\n",
    "\n",
    "        for c in classes:\n",
    "            tp = np.sum((y_pred_g == c) & (y_true_g == c))\n",
    "            fn = np.sum((y_pred_g != c) & (y_true_g == c))\n",
    "            fp = np.sum((y_pred_g == c) & (y_true_g != c))\n",
    "            tn = np.sum((y_pred_g != c) & (y_true_g != c))\n",
    "\n",
    "            # Avoid division by zero\n",
    "            metrics[g][c][\"TPR\"] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            metrics[g][c][\"FPR\"] = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "    # Compute max difference across groups\n",
    "    eo_diff_vals = []\n",
    "    for g1 in groups:\n",
    "        for g2 in groups:\n",
    "            if g1 != g2:  # Compare across different groups\n",
    "                for c in classes:\n",
    "                    tpr_diff = np.abs(metrics[g1][c][\"TPR\"] - metrics[g2][c][\"TPR\"])\n",
    "                    fpr_diff = np.abs(metrics[g1][c][\"FPR\"] - metrics[g2][c][\"FPR\"])\n",
    "                    eo_diff_vals.append(tpr_diff + fpr_diff)\n",
    "\n",
    "    eo_diff = np.max(eo_diff_vals) if eo_diff_vals else 0  # Avoid empty list issue\n",
    "\n",
    "    # -----------------------\n",
    "    # Selection Rate Per Group\n",
    "    # -----------------------\n",
    "    selection_rate = {g: class_rates[g].tolist() for g in groups}\n",
    "\n",
    "    # -----------------------\n",
    "    # Group-Wise Accuracy\n",
    "    # -----------------------\n",
    "    group_acc = {}\n",
    "    for g in groups:\n",
    "        mask = (sensitive_features == g)\n",
    "        group_acc[g] = accuracy_score(y_true[mask], y_pred[mask])\n",
    "\n",
    "    return {\n",
    "        \"demographic_parity_difference\": dp_diff,\n",
    "        \"equalized_odds_difference\": eo_diff,\n",
    "        \"selection_rate\": selection_rate,\n",
    "        \"group_accuracy\": group_acc\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # -------------------------------\n",
    "# # Manual Fairness Metrics\n",
    "# # -------------------------------\n",
    "\n",
    "# # changed for multi\n",
    "# def multi_compute_fairness_metrics_manual(y_true, y_pred, sensitive_features):\n",
    "#     \"\"\"\n",
    "#     Compute fairness metrics manually.\n",
    "#     y_true: binary ground-truth labels (1-D numpy array).\n",
    "#     y_pred: continuous scores (will be thresholded at 0.5).\n",
    "#     sensitive_features: 1-D numpy array (0 or 1).\n",
    "\n",
    "#     Returns a dictionary with:\n",
    "#       - Demographic parity difference (absolute difference in positive rates).\n",
    "#       - Equalized odds difference (average difference in TPR and FPR).\n",
    "#       - Selection rates per group.\n",
    "#       - Group-wise accuracy.\n",
    "#     \"\"\"\n",
    "#     # y_pred_bin = np.argmax(y_pred, axis=1) # converting probability to class prediction\n",
    "#     y_pred_bin = y_pred\n",
    "#     groups = np.unique(sensitive_features) # all the different groups in the sensitive feature)\n",
    "#     classes = np.unique(y_true) # all the different classes in y_true (for multiclass)\n",
    "\n",
    "#     # Demographic parity \n",
    "\n",
    "#     # For each group in the sensitive feature, find the demographic parity and compute the difference (based on the formula in above comment) -- will look at each proportion per class\n",
    "#     class_rates = {g: np.zeros(len(classes)) for g in groups}\n",
    "\n",
    "#     for g in groups:\n",
    "#         mask = (sensitive_features == g) \n",
    "#         for cl in classes: \n",
    "#             class_rates[g][cl] = np.mean(y_pred_bin[mask] == cl)\n",
    "#     dp_diff = np.max([np.abs(class_rates[g1] - class_rates[g2]) for g1 in groups for g2 in groups if g1 != g2])\n",
    "\n",
    "\n",
    "#     # Equalized odds\n",
    "#     \"\"\"\n",
    "#     Ensuring the different groups in the sensitive feature similar TPR and FPR rates -- this is so that the model isn't discriminating in error types\n",
    "#     \"\"\"\n",
    "#     metrics = {g: {c: {\"TPR\": 0, \"FPR\": 0} for c in classes} for g in groups}\n",
    "\n",
    "#     for g in groups:\n",
    "#         mask = (sensitive_features == g)\n",
    "#         y_true_g = y_true[mask]\n",
    "#         y_pred_g = y_pred_bin[mask]\n",
    "\n",
    "#         for c in unique_classes:\n",
    "#             tp = np.sum((y_pred_g == c) & (y_true_g == c))\n",
    "#             fn = np.sum((y_pred_g != c) & (y_true_g == c))\n",
    "#             fp = np.sum((y_pred_g == c) & (y_true_g != c))\n",
    "#             tn = np.sum((y_pred_g != c) & (y_true_g != c))\n",
    "\n",
    "#             metrics[g][c][\"TPR\"] = tp / (tp + fn) # true positive\n",
    "#             metrics[g][c][\"FPR\"] = fp / (fp + tn) # false positive\n",
    "\n",
    "        \n",
    "#     eo_diff_vals = []\n",
    "#     for g1 in groups:\n",
    "#         for g2 in groups: \n",
    "#             if g1 != g2: # trying to compare tpr and fpr across the different groups\n",
    "#                 for c in classes: \n",
    "#                     tpr_diff = np.abs(metrics[g1][c][\"TPR\"] - metrics[g2][c][\"TPR\"])\n",
    "#                     fpr_diff = np.abs(metrics[g1][c][\"FPR\"] - metrics[g2][c][\"FPR\"])\n",
    "#                     eo_diff_vals.append(tpr_diff + fpr_diff)\n",
    "#     eof_diff = np.max(eo_diff_vals)\n",
    "                \n",
    "    \n",
    "#     # Selection rate per group.\n",
    "#     \"\"\"\n",
    "#     proportion of samples predicted as positive for each group -- a group has a higher selection rate, the model may favor that group unfairly\n",
    "#     \"\"\"\n",
    "#     selection_rate = {g: class_rates[g].tolist() for g in groups}\n",
    "\n",
    "#     # Group-wise accuracy.\n",
    "#     \"\"\"\n",
    "#     for each group in the sensitive feature, compute the accuracy of the model (to ensure that it's perfoming consistently across groups)\n",
    "#     \"\"\"\n",
    "#     group_acc = {}\n",
    "#     for g in groups:\n",
    "#         mask = (sensitive_features == g)\n",
    "#         group_acc[g] = accuracy_score(y_true[mask], y_pred_bin[mask])\n",
    "\n",
    "#     return {\n",
    "#         \"demographic_parity_difference\": dp_diff,\n",
    "#         \"equalized_odds_difference\": eo_diff,\n",
    "#         \"selection_rate\": sel_rate,\n",
    "#         \"group_accuracy\": group_acc\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "215ef3cd-b252-45a1-a259-d6b4dd09001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Plotting Function\n",
    "# -------------------------------\n",
    "\n",
    "# changed for multi class\n",
    "def multi_plot_comparison(metrics_baseline, metrics_fair):\n",
    "    \"\"\"\n",
    "    parameters are dictionaries with the stored values of the evaluation metrics\n",
    "    \"\"\"\n",
    "    models = ['Baseline', 'Fair']\n",
    "    aucs = [metrics_baseline['auc'], metrics_fair['auc']]\n",
    "    accs = [metrics_baseline['accuracy'], metrics_fair['accuracy']]\n",
    "    dp_diff = [metrics_baseline[\"demographic_parity_difference\"], metrics_fair[\"demographic_parity_difference\"]]\n",
    "    eo_diff = [metrics_baseline[\"equalized_odds_difference\"], metrics_fair[\"equalized_odds_difference\"]]\n",
    "\n",
    "    # creating a 2x3 gird of bar chars comparing baseline model and fair model across: AUC, accuracy, demographic parity diff, equalized odd difference\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    ## measures how well the model seperates postiive and negative classes, higher AUC = better model performance\n",
    "    # if fair model has a lower AUC than the baseline, can indicate a fairness-performance tradeoff (meaning less well seperation for more fair results)\n",
    "    axs[0,0].bar(models, aucs, color=['blue', 'green'])\n",
    "    axs[0,0].set_title('AUC')\n",
    "    axs[0,0].set_ylim([0, 1])\n",
    "\n",
    "    ## correct pred/total pred\n",
    "    ## fairness may lower accuracy \n",
    "    axs[0,1].bar(models, accs, color=['blue', 'green'])\n",
    "    axs[0,1].set_title('Accuracy')\n",
    "    axs[0,1].set_ylim([0, 1])\n",
    "\n",
    "    ## orange = baseline, purple = fairness -LOOK INTO TO SEE HOW TO KNOW WHICH GROUP IS CONTRIBUTING TO HIGHER DP\n",
    "    # lower values of dp indciate better fairness\n",
    "    axs[1,0].bar(models, dp_diff, color=['orange', 'purple'])\n",
    "    axs[1,0].set_title('Demographic Parity Difference')\n",
    "\n",
    "    ## lower value - better fairness\n",
    "    ## equalized odds is satisfied if tpr and fpr are equal across the different groups in the sensitive feature\n",
    "    axs[1,1].bar(models, eo_diff, color=['orange', 'purple'])\n",
    "    axs[1,1].set_title('Equalized Odds Difference')\n",
    "\n",
    "    plt.suptitle(\"Comparison: Baseline (X → Y) vs. Fair (X → Y') Model\")\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9934d0d9-03c6-4480-a9d2-90283ba9e07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Main Function: Comparison and Visualization\n",
    "# -------------------------------\n",
    "def multi_main(data_url, dataset_name, lambda_adv=1.0):\n",
    "    set_seed(42)\n",
    "\n",
    "    if dataset_name == \"compas\": \n",
    "        X, Y_obs, S = load_and_preprocess_compas_data_binary(data_url) ##  Y, S is binary\n",
    "        num_classes_Y = len(np.unique(Y_obs))\n",
    "    \n",
    "    elif dataset_name == \"drug\":\n",
    "        X, Y_obs, S = load_and_process_drug_consumption_data(data_url) ##  Y is multi class, S is binary\n",
    "        num_classes_Y = len(np.unique(Y_obs))\n",
    "\n",
    "    elif dataset_name == \"health\":\n",
    "        X, Y_obs, S = load_and_process_health_data(data_url) ##  Y is multi class, S is binary\n",
    "        num_classes_Y = len(np.unique(Y_obs))\n",
    "\n",
    "    else:\n",
    "        print (\"Invalid dataset_name\")\n",
    "        return \n",
    "    \n",
    "    print(f\"Loading and preprocessing {dataset_name} data...\")\n",
    "    X_train, X_test, Y_train_obs, Y_test_obs, S_train, S_test = train_test_split(\n",
    "        X, Y_obs, S, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    if dataset_name == \"compas\":\n",
    "        print(f\"Features shape: {X.shape}\")\n",
    "        print(f\"Observed Label Y shape: {Y_obs.shape}   (Recidivism: 1=recid, 0=non-recid)\")\n",
    "        print(f\"Sensitive Attribute (Race, binarized) shape: {S.shape}\")\n",
    "        \n",
    "    elif dataset_name == \"drug\":\n",
    "        print(f\"Features shape: {X.shape}\")\n",
    "        print(f\"Observed Label Y shape: {Y_obs.shape}   (Label from 'drug consumption')\")\n",
    "        print(f\"Sensitive Attribute (Education) shape: {S.shape}\")\n",
    "\n",
    "    elif dataset_name == \"health\":\n",
    "        print(f\"Features shape: {X.shape}\")\n",
    "        print(f\"Observed Label Y shape: {Y_obs.shape}   (Label from 'health readmission')\")\n",
    "        print(f\"Sensitive Attribute (Gender) shape: {S.shape}\")\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "\n",
    "    # One-hot encode S for adversarial model training.\n",
    "    S_train_oh = tf.keras.utils.to_categorical(S_train, num_classes=2) # will need to change this if not longer 2\n",
    "    S_test_oh  = tf.keras.utils.to_categorical(S_test, num_classes=2) # will need to change this if no longer 2\n",
    "\n",
    "    # need to one hot encode Y\n",
    "    Y_train_obs = tf.keras.utils.to_categorical(Y_train_obs, num_classes=num_classes_Y)\n",
    "    Y_test_obs = tf.keras.utils.to_categorical(Y_test_obs, num_classes=num_classes_Y)\n",
    "    \n",
    "    Y_train_obs_1d = np.argmax(Y_train_obs, axis=1)  # Convert from one-hot to categorical labels\n",
    "    Y_test_obs_1d = np.argmax(Y_test_obs, axis=1)  # Do the same for test set\n",
    "\n",
    "    ### 1. Train adversarial debiasing model (X → Y' with adversary)\n",
    "    print(\"\\nTraining adversarial model (X → Y' with adversary) ...\")\n",
    "    adv_model = build_adversarial_model(input_dim, num_classes_Y, lambda_adv=lambda_adv)\n",
    "    # For training, we use the observed Y as target for both pseudo_Y and Y_pred.\n",
    "    # Reshape Y_obs to (-1,1) since our outputs are scalars.\n",
    "    # Y_train_obs_exp = Y_train_obs.reshape(-1, 1)\n",
    "    # Y_test_obs_exp  = Y_test_obs.reshape(-1, 1)\n",
    "    adv_model.fit([X_train, S_train_oh],\n",
    "                  {\"pseudo_Y\": Y_train_obs, \"S_pred\": S_train_oh, \"Y_pred\": Y_train_obs},\n",
    "                  epochs=30, batch_size=128, verbose=1)\n",
    "\n",
    "    # Get pseudo-label predictions.\n",
    "    pseudo_Y_train, S_pred_train, Y_pred_train = adv_model.predict([X_train, S_train_oh]) ## changed so we're using Y_pred here instead of psuedo_Y\n",
    "    pseudo_Y_test,  S_pred_test, Y_pred_test = adv_model.predict([X_test, S_test_oh])\n",
    "\n",
    "    # Threshold pseudo-labels to get binary labels.\n",
    "    Y_pred_train_bin = np.argmax(Y_pred_train, axis= 1)\n",
    "    Y_pred_test_bin  = np.argmax(Y_pred_test, axis=1) \n",
    "\n",
    "    print(\"\\nPseudo-label statistics (training):\")\n",
    "    for g in np.unique(S_train):\n",
    "        mask = (S_train == g)\n",
    "        print(f\"Group {g} pseudo-positive rate: {np.mean(Y_pred_train_bin[mask]):.4f}\") # average probability of a postive prediction per group -- fairness check to see if both groups receive similar treatment\n",
    "\n",
    "    ### 2. Train baseline logistic regression model on observed Y (X → Y) -- regular logistic regression for baseline for comparison; does not include any fairness constraints\n",
    "    print(\"\\nTraining baseline logistic regression classifier (X → Y)...\")\n",
    "    baseline_clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "    baseline_clf.fit(X_train, Y_train_obs_1d)\n",
    "    \n",
    "    baseline_preds = baseline_clf.predict_proba(X_test)    \n",
    "    baseline_auc = roc_auc_score(Y_test_obs, baseline_preds, multi_class=\"ovr\")\n",
    "    baseline_preds_class = baseline_preds.argmax(axis=1)\n",
    "    baseline_acc = accuracy_score(Y_test_obs_1d, baseline_preds_class)\n",
    "\n",
    "    baseline_fairness = multi_compute_fairness_metrics_manual(Y_test_obs, baseline_preds_class, sensitive_features=S_test)\n",
    "\n",
    "    ### 3. Train fair logistic regression model on pseudo-labels (X → Y') -- using psuedo_Y from the the adv_model, \n",
    "    print(\"\\nTraining fair logistic regression classifier (X → Y') using Y_pred labels...\")\n",
    "    fair_clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "    fair_clf.fit(X_train, Y_pred_train_bin)\n",
    "    fair_preds = fair_clf.predict_proba(X_test)\n",
    "    fair_auc = roc_auc_score(Y_test_obs, fair_preds, multi_class='ovr')\n",
    "    fair_preds_class = fair_preds.argmax(axis=1)\n",
    "    fair_acc = accuracy_score(Y_test_obs_1d, fair_preds_class)\n",
    "\n",
    "    fair_fairness = multi_compute_fairness_metrics_manual(Y_test_obs, fair_preds_class, sensitive_features=S_test)\n",
    "\n",
    "    # Aggregate metrics for plotting.\n",
    "    metrics_baseline = {\n",
    "        \"auc\": baseline_auc,\n",
    "        \"accuracy\": baseline_acc,\n",
    "        \"demographic_parity_difference\": baseline_fairness[\"demographic_parity_difference\"],\n",
    "        \"equalized_odds_difference\": baseline_fairness[\"equalized_odds_difference\"]\n",
    "    }\n",
    "    metrics_fair = {\n",
    "        \"auc\": fair_auc,\n",
    "        \"accuracy\": fair_acc,\n",
    "        \"demographic_parity_difference\": fair_fairness[\"demographic_parity_difference\"],\n",
    "        \"equalized_odds_difference\": fair_fairness[\"equalized_odds_difference\"]\n",
    "    }\n",
    "\n",
    "    print(\"\\nBaseline Logistic Regression (X → Y) Evaluation:\")\n",
    "    print(f\"AUC: {baseline_auc:.4f}, Accuracy: {baseline_acc:.4f}\")\n",
    "    print(\"Fairness metrics:\", baseline_fairness)\n",
    "\n",
    "    print(\"\\nFair Logistic Regression (X → Y') Evaluation (compared to observed Y):\")\n",
    "    print(f\"AUC: {fair_auc:.4f}, Accuracy: {fair_acc:.4f}\")\n",
    "    print(\"Fairness metrics:\", fair_fairness)\n",
    "\n",
    "    # Plot comparison.\n",
    "    multi_plot_comparison(metrics_baseline, metrics_fair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046a7324-619d-470b-9ec7-f1b4bf6d984f",
   "metadata": {},
   "source": [
    "### Application on Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4a8cb1-26fd-47ae-ba82-01642fb05249",
   "metadata": {},
   "source": [
    "#### Drug Consumption Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a030df-362c-4806-8fdd-75f9b4a75487",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/drug_consumption.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 53\u001b[0m\n\u001b[1;32m     49\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meducation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, Y, S\n\u001b[0;32m---> 53\u001b[0m \u001b[43mmulti_main\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mANYTHING\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrug\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_adv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m, in \u001b[0;36mmulti_main\u001b[0;34m(data_url, dataset_name, lambda_adv)\u001b[0m\n\u001b[1;32m      9\u001b[0m     num_classes_Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(Y_obs))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dataset_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrug\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 12\u001b[0m     X, Y_obs, S \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_process_drug_consumption_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_url\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m##  Y is multi class, S is binary\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     num_classes_Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(Y_obs))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m, in \u001b[0;36mload_and_process_drug_consumption_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_and_process_drug_consumption_data\u001b[39m(path):\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# path = os.path.join(\"data\", \"drug_consumption.csv\")\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/drug_consumption.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# convert to 4 classes\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/drug_consumption.csv'"
     ]
    }
   ],
   "source": [
    "## Good to go\n",
    "def load_and_process_drug_consumption_data(path):\n",
    "\n",
    "    # path = os.path.join(\"data\", \"drug_consumption.csv\")\n",
    "    path = \"../data/drug_consumption.csv\"\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = df.columns.str.lower().str.strip()\n",
    "    \n",
    "    # convert to 4 classes\n",
    "    df = df[df.columns[1:]]\n",
    "    df = df.replace(\n",
    "        {\n",
    "            \"cannabis\": {\n",
    "                \"CL0\": \"never_used\",\n",
    "                \"CL1\": \"not_in_last_year\",\n",
    "                \"CL2\": \"not_in_last_year\",\n",
    "                \"CL3\": \"used_in_last_year\",\n",
    "                \"CL4\": \"used_in_last_year\",\n",
    "                \"CL5\": \"used_in_last_week\",\n",
    "                \"CL6\": \"used_in_last_week\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    educated_cat = {\n",
    "        \"University degree\",\n",
    "        \"Masters degree\",\n",
    "        \"Doctorate degree\",\n",
    "        \"Professional certificate/ diploma\"\n",
    "    }\n",
    "    \n",
    "    df[\"education\"] = df[\"education\"].apply(lambda x: 1 if x in educated_cat else 0)\n",
    "    \n",
    "    # changing to numerical representation\n",
    "    label_encoder = LabelEncoder()\n",
    "    # df[\"age\"] = label_encoder.fit_transform(df[\"age\"]) \n",
    "    df[\"country\"] = label_encoder.fit_transform(df[\"country\"])\n",
    "    df[\"ethnicity\"] = label_encoder.fit_transform(df[\"ethnicity\"])\n",
    "    df[\"cannabis\"] = label_encoder.fit_transform(df[\"cannabis\"])\n",
    "\n",
    "    \n",
    "    \n",
    "    df[\"gender\"] = df[\"gender\"].apply(lambda x: 1 if x == \"M\" else 0)\n",
    "    \n",
    "    X = df[df.columns[1:12]]\n",
    "    Y = df[\"cannabis\"].to_numpy()\n",
    "    S = df[\"education\"].to_numpy()\n",
    "    X = X.drop(columns = [\"education\"])\n",
    "\n",
    "    return X, Y, S\n",
    "\n",
    "multi_main(\"ANYTHING\", \"drug\", lambda_adv=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31d2a34-5537-464d-bfa2-145aca328906",
   "metadata": {},
   "source": [
    "#### Compas Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c9792f0-69b2-4b91-b491-c5acfac2ec6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main_compas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m compas_data_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# You can adjust lambda_adv as desired (e.g., lambda_adv=15.5 as in your German data experiment)\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[43mmain_compas\u001b[49m(compas_data_url, lambda_adv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3.1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'main_compas' is not defined"
     ]
    }
   ],
   "source": [
    "# COME BACK AND DO IF WANT TO IMPLEMENT WHERE SENSITIVE FEATURE IS NOT JUST BINARY\n",
    "def load_and_preprocess_compas_data_multi_cat(data_url):\n",
    "    \"\"\"\n",
    "    Try the algorithm, except instead of binary sensitive feature, it multi classes (so not just Aferican American)? \n",
    "    \n",
    "    Download and preprocess the COMPAS dataset.\n",
    "\n",
    "    We assume the dataset contains, among others, the following columns:\n",
    "      - 'age'\n",
    "      - 'race'\n",
    "      - 'priors_count'\n",
    "      - 'juv_fel_count'\n",
    "      - 'juv_misd_count'\n",
    "      - 'juv_other_count'\n",
    "      - 'two_year_recid'\n",
    "\n",
    "    Features (X): We select a few numerical features.\n",
    "    Observed Label (Y): Use 'two_year_recid' as a binary label (0/1).\n",
    "    Protected Attribute (S): Use 'race'. Here we binarize race so that:\n",
    "         African‑American  → 1\n",
    "         all other races  → 0.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(data_url)\n",
    "    # Drop rows with missing values in the selected columns.\n",
    "    data = data.dropna(subset=[\"age\", \"race\", \"priors_count\", \"juv_fel_count\", \"juv_misd_count\", \"juv_other_count\", \"two_year_recid\"])\n",
    "\n",
    "    # Observed label: two_year_recid (already 0/1)\n",
    "    Y = data[\"two_year_recid\"].values\n",
    "\n",
    "    # Sensitive attribute: race. We set S=1 if race is African-American, else 0.\n",
    "    S = (data[\"race\"] == \"African-American\").astype(int).values\n",
    "\n",
    "    # Features: use a subset of numerical features.\n",
    "    feature_cols = [\"age\", \"priors_count\", \"juv_fel_count\", \"juv_misd_count\", \"juv_other_count\"]\n",
    "    X = data[feature_cols].copy().astype(np.float32)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X.values)\n",
    "\n",
    "    return X, Y, S\n",
    "\n",
    "# URL for the ProPublica COMPAS dataset\n",
    "compas_data_url = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
    "# You can adjust lambda_adv as desired (e.g., lambda_adv=15.5 as in your German data experiment)\n",
    "main_compas(compas_data_url, lambda_adv=3.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143afddc-1d95-486a-943a-3463209f11cf",
   "metadata": {},
   "source": [
    "#### Health Readmission Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28b61a03-cc68-4845-8e7a-ba7f14f638b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.7)\n",
      "Loading and preprocessing health data...\n",
      "Features shape: (2000, 5)\n",
      "Observed Label Y shape: (2000,)   (Label from 'health readmission')\n",
      "Sensitive Attribute (Gender) shape: (2000,)\n",
      "\n",
      "Training adversarial model (X → Y' with adversary) ...\n",
      "Epoch 1/30\n",
      "13/13 [==============================] - 2s 8ms/step - loss: 3.9033 - pseudo_Y_loss: 1.3577 - S_pred_loss: 0.9528 - Y_pred_loss: 1.5927 - pseudo_Y_accuracy: 0.3738 - S_pred_accuracy: 0.5006 - Y_pred_accuracy: 0.3550\n",
      "Epoch 2/30\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.8321 - pseudo_Y_loss: 1.3370 - S_pred_loss: 0.9369 - Y_pred_loss: 1.5582 - pseudo_Y_accuracy: 0.3688 - S_pred_accuracy: 0.4969 - Y_pred_accuracy: 0.3575\n",
      "Epoch 3/30\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.7876 - pseudo_Y_loss: 1.3351 - S_pred_loss: 0.9265 - Y_pred_loss: 1.5260 - pseudo_Y_accuracy: 0.3613 - S_pred_accuracy: 0.4894 - Y_pred_accuracy: 0.3625\n",
      "Epoch 4/30\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.7144 - pseudo_Y_loss: 1.3220 - S_pred_loss: 0.8955 - Y_pred_loss: 1.4969 - pseudo_Y_accuracy: 0.3681 - S_pred_accuracy: 0.4975 - Y_pred_accuracy: 0.3500\n",
      "Epoch 5/30\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.6735 - pseudo_Y_loss: 1.3197 - S_pred_loss: 0.8779 - Y_pred_loss: 1.4759 - pseudo_Y_accuracy: 0.3725 - S_pred_accuracy: 0.5000 - Y_pred_accuracy: 0.3625\n",
      "Epoch 6/30\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.6185 - pseudo_Y_loss: 1.3056 - S_pred_loss: 0.8516 - Y_pred_loss: 1.4613 - pseudo_Y_accuracy: 0.3681 - S_pred_accuracy: 0.4900 - Y_pred_accuracy: 0.3575\n",
      "Epoch 7/30\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.5836 - pseudo_Y_loss: 1.3065 - S_pred_loss: 0.8389 - Y_pred_loss: 1.4382 - pseudo_Y_accuracy: 0.3663 - S_pred_accuracy: 0.4869 - Y_pred_accuracy: 0.3569\n",
      "Epoch 8/30\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 3.5416 - pseudo_Y_loss: 1.2978 - S_pred_loss: 0.8287 - Y_pred_loss: 1.4151 - pseudo_Y_accuracy: 0.3613 - S_pred_accuracy: 0.4856 - Y_pred_accuracy: 0.3581\n",
      "Epoch 9/30\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.4990 - pseudo_Y_loss: 1.2897 - S_pred_loss: 0.8111 - Y_pred_loss: 1.3982 - pseudo_Y_accuracy: 0.3688 - S_pred_accuracy: 0.4762 - Y_pred_accuracy: 0.3500\n",
      "Epoch 10/30\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.4667 - pseudo_Y_loss: 1.2789 - S_pred_loss: 0.8046 - Y_pred_loss: 1.3832 - pseudo_Y_accuracy: 0.3625 - S_pred_accuracy: 0.4800 - Y_pred_accuracy: 0.3500\n",
      "Epoch 11/30\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.4259 - pseudo_Y_loss: 1.2658 - S_pred_loss: 0.7918 - Y_pred_loss: 1.3683 - pseudo_Y_accuracy: 0.3669 - S_pred_accuracy: 0.4725 - Y_pred_accuracy: 0.3581\n",
      "Epoch 12/30\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.3772 - pseudo_Y_loss: 1.2544 - S_pred_loss: 0.7767 - Y_pred_loss: 1.3461 - pseudo_Y_accuracy: 0.3694 - S_pred_accuracy: 0.4725 - Y_pred_accuracy: 0.3562\n",
      "Epoch 13/30\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.3525 - pseudo_Y_loss: 1.2478 - S_pred_loss: 0.7755 - Y_pred_loss: 1.3292 - pseudo_Y_accuracy: 0.3781 - S_pred_accuracy: 0.4681 - Y_pred_accuracy: 0.3512\n",
      "Epoch 14/30\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.3017 - pseudo_Y_loss: 1.2289 - S_pred_loss: 0.7543 - Y_pred_loss: 1.3185 - pseudo_Y_accuracy: 0.3719 - S_pred_accuracy: 0.4944 - Y_pred_accuracy: 0.3556\n",
      "Epoch 15/30\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.2913 - pseudo_Y_loss: 1.2255 - S_pred_loss: 0.7602 - Y_pred_loss: 1.3056 - pseudo_Y_accuracy: 0.3781 - S_pred_accuracy: 0.4650 - Y_pred_accuracy: 0.3525\n",
      "Epoch 16/30\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2508 - pseudo_Y_loss: 1.2174 - S_pred_loss: 0.7476 - Y_pred_loss: 1.2858 - pseudo_Y_accuracy: 0.3819 - S_pred_accuracy: 0.4837 - Y_pred_accuracy: 0.3600\n",
      "Epoch 17/30\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2420 - pseudo_Y_loss: 1.2205 - S_pred_loss: 0.7459 - Y_pred_loss: 1.2755 - pseudo_Y_accuracy: 0.3731 - S_pred_accuracy: 0.4744 - Y_pred_accuracy: 0.3550\n",
      "Epoch 18/30\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.1844 - pseudo_Y_loss: 1.1955 - S_pred_loss: 0.7368 - Y_pred_loss: 1.2520 - pseudo_Y_accuracy: 0.3825 - S_pred_accuracy: 0.4781 - Y_pred_accuracy: 0.3625\n",
      "Epoch 19/30\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.1653 - pseudo_Y_loss: 1.1891 - S_pred_loss: 0.7352 - Y_pred_loss: 1.2410 - pseudo_Y_accuracy: 0.3850 - S_pred_accuracy: 0.4913 - Y_pred_accuracy: 0.3556\n",
      "Epoch 20/30\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.1512 - pseudo_Y_loss: 1.1839 - S_pred_loss: 0.7341 - Y_pred_loss: 1.2332 - pseudo_Y_accuracy: 0.3781 - S_pred_accuracy: 0.4944 - Y_pred_accuracy: 0.3619\n",
      "Epoch 21/30\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1263 - pseudo_Y_loss: 1.1734 - S_pred_loss: 0.7338 - Y_pred_loss: 1.2190 - pseudo_Y_accuracy: 0.3900 - S_pred_accuracy: 0.4950 - Y_pred_accuracy: 0.3562\n",
      "Epoch 22/30\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.1048 - pseudo_Y_loss: 1.1731 - S_pred_loss: 0.7281 - Y_pred_loss: 1.2036 - pseudo_Y_accuracy: 0.3900 - S_pred_accuracy: 0.4831 - Y_pred_accuracy: 0.3644\n",
      "Epoch 23/30\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.0874 - pseudo_Y_loss: 1.1584 - S_pred_loss: 0.7295 - Y_pred_loss: 1.1995 - pseudo_Y_accuracy: 0.3938 - S_pred_accuracy: 0.4900 - Y_pred_accuracy: 0.3644\n",
      "Epoch 24/30\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.0740 - pseudo_Y_loss: 1.1563 - S_pred_loss: 0.7341 - Y_pred_loss: 1.1836 - pseudo_Y_accuracy: 0.3887 - S_pred_accuracy: 0.4806 - Y_pred_accuracy: 0.3606\n",
      "Epoch 25/30\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 3.0453 - pseudo_Y_loss: 1.1503 - S_pred_loss: 0.7255 - Y_pred_loss: 1.1695 - pseudo_Y_accuracy: 0.3988 - S_pred_accuracy: 0.4894 - Y_pred_accuracy: 0.3675\n",
      "Epoch 26/30\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0293 - pseudo_Y_loss: 1.1404 - S_pred_loss: 0.7244 - Y_pred_loss: 1.1645 - pseudo_Y_accuracy: 0.4000 - S_pred_accuracy: 0.5075 - Y_pred_accuracy: 0.3613\n",
      "Epoch 27/30\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 3.0171 - pseudo_Y_loss: 1.1407 - S_pred_loss: 0.7228 - Y_pred_loss: 1.1536 - pseudo_Y_accuracy: 0.3994 - S_pred_accuracy: 0.4906 - Y_pred_accuracy: 0.3694\n",
      "Epoch 28/30\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.0117 - pseudo_Y_loss: 1.1322 - S_pred_loss: 0.7266 - Y_pred_loss: 1.1530 - pseudo_Y_accuracy: 0.4006 - S_pred_accuracy: 0.4719 - Y_pred_accuracy: 0.3519\n",
      "Epoch 29/30\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2.9910 - pseudo_Y_loss: 1.1329 - S_pred_loss: 0.7216 - Y_pred_loss: 1.1365 - pseudo_Y_accuracy: 0.4125 - S_pred_accuracy: 0.4938 - Y_pred_accuracy: 0.3719\n",
      "Epoch 30/30\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.9838 - pseudo_Y_loss: 1.1257 - S_pred_loss: 0.7200 - Y_pred_loss: 1.1381 - pseudo_Y_accuracy: 0.4156 - S_pred_accuracy: 0.4994 - Y_pred_accuracy: 0.3619\n",
      "50/50 [==============================] - 0s 1ms/step\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "\n",
      "Pseudo-label statistics (training):\n",
      "Group 0 pseudo-positive rate: 0.4145\n",
      "Group 1 pseudo-positive rate: 1.1703\n",
      "\n",
      "Training baseline logistic regression classifier (X → Y)...\n",
      "\n",
      "Training fair logistic regression classifier (X → Y') using Y_pred labels...\n",
      "\n",
      "Baseline Logistic Regression (X → Y) Evaluation:\n",
      "AUC: 0.5352, Accuracy: 0.4675\n",
      "Fairness metrics: {'demographic_parity_difference': 0.0, 'equalized_odds_difference': 0.0, 'selection_rate': {0: [1.0, 0.0], 1: [1.0, 0.0]}, 'group_accuracy': {0: 0.494949494949495, 1: 0.4405940594059406}}\n",
      "\n",
      "Fair Logistic Regression (X → Y') Evaluation (compared to observed Y):\n",
      "AUC: 0.4697, Accuracy: 0.4200\n",
      "Fairness metrics: {'demographic_parity_difference': 0.0665066506650665, 'equalized_odds_difference': 0.17693750742512024, 'selection_rate': {0: [0.8585858585858586, 0.1414141414141414], 1: [0.7920792079207921, 0.2079207920792079]}, 'group_accuracy': {0: 0.43434343434343436, 1: 0.40594059405940597}}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import kagglehub\n",
    "def load_and_process_health_data(data):\n",
    "    path = kagglehub.dataset_download(\"vanpatangan/readmission-dataset\")\n",
    "    \n",
    "    dataset_files = os.listdir(path)\n",
    "    \n",
    "    train_df = pd.read_csv(os.path.join(path, \"train_df.csv\"))\n",
    "    test_df = pd.read_csv(os.path.join(path, \"test_df.csv\"))\n",
    "\n",
    "    #No Readmission = Class 0\n",
    "    #Short-term Readmission = Class 1\n",
    "    #Long-term Readmission = Class 2\n",
    "    \n",
    "    mapping_discharge = {\n",
    "        'Home': 0,\n",
    "        'Home Health Care': 0,\n",
    "        'Skilled Nursing Facility': 1, \n",
    "        'Rehabilitation Facility': 2,\n",
    "    }\n",
    "    \n",
    "    test_df['discharge_category'] = test_df['discharge_to'].map(mapping_discharge)\n",
    "    \n",
    "    mapping_gender = {\n",
    "        \"Male\": 0, \n",
    "        \"Female\": 1\n",
    "    }\n",
    "    \n",
    "    test_df['gender_category'] = test_df['gender'].map(mapping_gender)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    test_df['primary_diagnosis'] = label_encoder.fit_transform(test_df['primary_diagnosis'])\n",
    "\n",
    "    Y = test_df['discharge_category'].to_numpy()\n",
    "    S = test_df['gender_category']\n",
    "    X = test_df.drop(columns = ['gender_category', 'discharge_to', 'discharge_category', 'gender'])\n",
    "    return X, Y, S\n",
    "\n",
    "multi_main(\"ANYTHING\", \"health\", lambda_adv=1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd8e345-9cf0-4c15-aafa-7aae9d5d9b79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
