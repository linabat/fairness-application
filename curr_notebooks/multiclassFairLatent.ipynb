{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a08e2fe6-61a7-4995-8fdb-181a371fa961",
   "metadata": {},
   "source": [
    "# create synthetic data  \n",
    "\n",
    "RAW DATA \n",
    "where S is sampled from binomial \n",
    "X -- some function of S and multinomial noise, X is high dimensional\n",
    "Y -- linear function of X + noise\n",
    "\n",
    "create train and test, \n",
    "\n",
    "inject error into training data -- Y is a function of S ,randomly mess around with the postive lables for Y (look at accuracy and fairness) -- use test for ground truth \n",
    "\n",
    "\n",
    "apply entire pipeline to the Y new\n",
    "\n",
    "original raw data\n",
    "dirty data (corrupted) \n",
    "cleaned data \n",
    "\n",
    "\n",
    "figure int where lambda doesn't take "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24672b93-3c9d-4e08-98b2-b6a106a323bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 15:12:46.689201: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-10 15:12:46.689258: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-10 15:12:46.691029: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-10 15:12:46.701298: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Conv2D, Flatten, \n",
    "    MaxPooling2D, BatchNormalization, Dropout\n",
    ")\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    LearningRateScheduler\n",
    ")\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.initializers import Constant\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tqdm import tqdm\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Conv2D, Flatten, \n",
    "    MaxPooling2D, BatchNormalization, Dropout, Concatenate\n",
    ")\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    LearningRateScheduler\n",
    ")\n",
    "\n",
    "from tensorflow.keras.regularizers import Regularizer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9af067-aa00-404e-9bbb-9fa55fd4367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Custom Gradient Reversal Layer\n",
    "# -------------------------------\n",
    "@tf.custom_gradient\n",
    "def grad_reverse(x, lambda_):\n",
    "    def grad(dy):\n",
    "        return -lambda_ * dy, None # reverses direction of gradient \n",
    "    return x, grad\n",
    "\n",
    "# custom Keras layer\n",
    "\"\"\"\n",
    "Layer is used to ensure that the feature representation are independent of a sensitive attribute\n",
    "- feature extract learns normally in the forward pass\n",
    "- reversing gradients of classifier that tries to predict the sensitive attribute during backpropagation -- stops feature extractor from encoding sensitive information\n",
    "\"\"\"\n",
    "class GradientReversalLayer(tf.keras.layers.Layer): \n",
    "    def __init__(self, lambda_=1.0, **kwargs):\n",
    "        super(GradientReversalLayer, self).__init__(**kwargs)\n",
    "        self.lambda_ = lambda_ # strength of gradient reversal -- larger lambda would work more towards S, Y independence -- smaller, is less penality but possible less fair\n",
    "        # ...how should we figure out the lambda value that should be used -- brought up from our discussion with David Danks\n",
    "    def call(self, x):\n",
    "        return grad_reverse(x, self.lambda_)\n",
    "\n",
    "# -------------------------------\n",
    "# Data Loading and Preprocessing\n",
    "# -------------------------------\n",
    "def set_seed(seed_num):\n",
    "    random.seed(seed_num)\n",
    "    np.random.seed(seed_num)\n",
    "    tf.random.set_seed(seed_num)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98a279a6-a67d-4bab-8049-18a4eb1ab4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Adversarial Debiasing Model\n",
    "# -------------------------------\n",
    "\n",
    "## has been adjusted for multiclass\n",
    "def build_adversarial_model(input_dim, num_classes_Y, lambda_adv=1.0):\n",
    "    \"\"\"\n",
    "    Build an adversarial debiasing model that learns pseudo‑labels Y' from X.\n",
    "\n",
    "    Architecture:\n",
    "      - Main branch (encoder): from X, several dense layers produce a latent pseudo‑label pseudo_Y (via sigmoid).\n",
    "      - Adversary branch: pseudo_Y is passed through a Gradient Reversal Layer and then dense layers predict S.\n",
    "      - Decoder branch: concatenates pseudo_Y and the one-hot sensitive attribute S to predict the observed label Y.\n",
    "\n",
    "    Losses:\n",
    "      - For the main branch, binary crossentropy between observed Y and pseudo_Y (and Y_pred).\n",
    "      - For the adversary branch, categorical crossentropy to predict S.\n",
    "\n",
    "    Returns a compiled Keras model that takes inputs X and S (one-hot encoded) and outputs:\n",
    "      [pseudo_Y, S_pred, Y_pred].\n",
    "    \"\"\"\n",
    "    X_input = tf.keras.Input(shape=(input_dim,), name=\"X\")\n",
    "    S_input = tf.keras.Input(shape=(2,), name=\"S\")  # one-hot encoded S\n",
    "\n",
    "    # Main branch: Encoder for pseudo-label.\n",
    "    h = Dense(64, activation='relu')(X_input)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = Dense(32, activation='relu')(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    pseudo_Y = Dense(num_classes_Y, activation='softmax', name=\"pseudo_Y\")(h) ## changed to softmax because multi-class\n",
    "\n",
    "    # Adversary branch: from pseudo_Y, with GRL.\n",
    "    \"\"\"\n",
    "    This is to prevent psuedo_Y from containing information about S\n",
    "    - adversary will try to predict S from pseudo_Y (fair label)...if it can accurately predict S, then Y' still encodes information about S (don't want this) \n",
    "    - use the gradient reversal layer to prevent this from happening\n",
    "    \"\"\"\n",
    "    grl = GradientReversalLayer(lambda_=lambda_adv)(pseudo_Y)\n",
    "    a = Dense(32, activation='relu')(grl)\n",
    "    a = BatchNormalization()(a)\n",
    "    S_pred = Dense(2, activation='softmax', name=\"S_pred\")(a)\n",
    "\n",
    "    # Decoder branch: combine pseudo_Y and S to predict observed Y.\n",
    "    concat = Concatenate()([pseudo_Y, S_input])\n",
    "    d = Dense(16, activation='relu')(concat)\n",
    "    d = BatchNormalization()(d)\n",
    "    Y_pred = Dense(num_classes_Y, activation='softmax', name=\"Y_pred\")(d) # changed from 1 to num_classes_Y, changed to softmax cause multi\n",
    "\n",
    "    model = tf.keras.Model(inputs=[X_input, S_input],\n",
    "                           outputs=[pseudo_Y, S_pred, Y_pred])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  loss={\"pseudo_Y\": \"categorical_crossentropy\", # changed from binary to categorical\n",
    "                        \"S_pred\": \"categorical_crossentropy\",\n",
    "                        \"Y_pred\": \"categorical_crossentropy\"}, # changed from binary to categorical\n",
    "                  loss_weights={\"pseudo_Y\": 1.0, \"S_pred\": lambda_adv, \"Y_pred\": 1.0},\n",
    "                  metrics={\"pseudo_Y\": \"accuracy\",\n",
    "                           \"S_pred\": \"accuracy\",\n",
    "                           \"Y_pred\": \"accuracy\"}) # Y_pred is the best estimate of Y accounting for fair dependencies \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdce495e-4c4f-4024-81ae-ec51509beaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def multi_compute_fairness_metrics_manual(y_true, y_pred, sensitive_features):\n",
    "    \"\"\"\n",
    "    Compute fairness metrics manually for multi-class classification.\n",
    "    \n",
    "    Args:\n",
    "      y_true: Ground-truth labels (1D numpy array, categorical).\n",
    "      y_pred: Predicted labels (1D numpy array, categorical).\n",
    "      sensitive_features: 1D numpy array (binary sensitive attribute).\n",
    "    \n",
    "    Returns:\n",
    "      Dictionary containing:\n",
    "        - Demographic parity difference\n",
    "        - Equalized odds difference\n",
    "        - Selection rates per group\n",
    "        - Group-wise accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure inputs are numpy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    sensitive_features = np.array(sensitive_features)\n",
    "\n",
    "    groups = np.unique(sensitive_features)  # Unique groups in sensitive attribute\n",
    "    classes = np.unique(y_true)  # Unique class labels\n",
    "\n",
    "    # -----------------------\n",
    "    # Demographic Parity Difference\n",
    "    # -----------------------\n",
    "    \n",
    "    # For each group in the sensitive feature, find the demographic parity and compute the difference (based on the formula in above comment) -- will look at each proportion per class\n",
    "    class_rates = {g: np.zeros(len(classes)) for g in groups}\n",
    "\n",
    "    for g in groups:\n",
    "        mask = (sensitive_features == g)  # Filter by group\n",
    "        for i, cl in enumerate(classes):  # Iterate over class labels\n",
    "            class_rates[g][i] = np.mean(y_pred[mask] == cl)  # Proportion of predictions for class c\n",
    "    \n",
    "    dp_diff = np.max([np.abs(class_rates[g1] - class_rates[g2]) \n",
    "                      for g1 in groups for g2 in groups if g1 != g2])\n",
    "\n",
    "    # -----------------------\n",
    "    # Ensuring the different groups in the sensitive feature similar TPR and FPR rates -- this is so that the model isn't discriminating in error types\n",
    "    # -----------------------\n",
    "    \"\"\"\n",
    "    Ensuring that different groups in the sensitive feature have similar TPR and FPR rates\n",
    "    This prevents the model from discriminating based on error types.\n",
    "    \"\"\"\n",
    "    metrics = {g: {c: {\"TPR\": 0, \"FPR\": 0} for c in classes} for g in groups}\n",
    "\n",
    "    y_true = np.argmax(y_true, axis=1) if len(y_true.shape) > 1 else y_true # categorical\n",
    "\n",
    "    for g in groups:\n",
    "        mask = (sensitive_features == g)\n",
    "        y_true_g = y_true[mask]\n",
    "        y_pred_g = y_pred[mask]\n",
    "\n",
    "        for c in classes:\n",
    "            tp = np.sum((y_pred_g == c) & (y_true_g == c))\n",
    "            fn = np.sum((y_pred_g != c) & (y_true_g == c))\n",
    "            fp = np.sum((y_pred_g == c) & (y_true_g != c))\n",
    "            tn = np.sum((y_pred_g != c) & (y_true_g != c))\n",
    "\n",
    "            # Avoid division by zero\n",
    "            metrics[g][c][\"TPR\"] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            metrics[g][c][\"FPR\"] = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\n",
    "    # Compute max difference across groups\n",
    "    eo_diff_vals = []\n",
    "    for g1 in groups:\n",
    "        for g2 in groups:\n",
    "            if g1 != g2:   # trying to compare tpr and fpr across the different groupss\n",
    "                for c in classes:\n",
    "                    tpr_diff = np.abs(metrics[g1][c][\"TPR\"] - metrics[g2][c][\"TPR\"])\n",
    "                    fpr_diff = np.abs(metrics[g1][c][\"FPR\"] - metrics[g2][c][\"FPR\"])\n",
    "                    eo_diff_vals.append(tpr_diff + fpr_diff)\n",
    "\n",
    "    eo_diff = np.max(eo_diff_vals) if eo_diff_vals else 0  # Avoid empty list issue\n",
    "\n",
    "    # -----------------------\n",
    "    # Selection Rate Per Group\n",
    "    # proportion of samples predicted as positive for each group -- a group has a higher selection rate, the model may favor that group unfairly\n",
    "    # -----------------------\n",
    "    selection_rate = {g: class_rates[g].tolist() for g in groups}\n",
    "\n",
    "    # -----------------------\n",
    "    # Group-Wise Accuracy\n",
    "    # for each group in the sensitive feature, compute the accuracy of the model (to ensure that it's perfoming consistently across groups)\n",
    "    # -----------------------\n",
    "    group_acc = {}\n",
    "    for g in groups:\n",
    "        mask = (sensitive_features == g)\n",
    "        group_acc[g] = accuracy_score(y_true[mask], y_pred[mask])\n",
    "\n",
    "    return {\n",
    "        \"demographic_parity_difference\": dp_diff,\n",
    "        \"equalized_odds_difference\": eo_diff,\n",
    "        \"selection_rate\": selection_rate,\n",
    "        \"group_accuracy\": group_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "215ef3cd-b252-45a1-a259-d6b4dd09001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Plotting Function\n",
    "# -------------------------------\n",
    "\n",
    "# changed for multi class\n",
    "def multi_plot_comparison(metrics_baseline, metrics_fair):\n",
    "    \"\"\"\n",
    "    parameters are dictionaries with the stored values of the evaluation metrics\n",
    "    \"\"\"\n",
    "    models = ['Baseline', 'Fair']\n",
    "    aucs = [metrics_baseline['auc'], metrics_fair['auc']]\n",
    "    accs = [metrics_baseline['accuracy'], metrics_fair['accuracy']]\n",
    "    dp_diff = [metrics_baseline[\"demographic_parity_difference\"], metrics_fair[\"demographic_parity_difference\"]]\n",
    "    eo_diff = [metrics_baseline[\"equalized_odds_difference\"], metrics_fair[\"equalized_odds_difference\"]]\n",
    "\n",
    "    # creating a 2x3 gird of bar chars comparing baseline model and fair model across: AUC, accuracy, demographic parity diff, equalized odd difference\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    ## measures how well the model seperates postiive and negative classes, higher AUC = better model performance\n",
    "    # if fair model has a lower AUC than the baseline, can indicate a fairness-performance tradeoff (meaning less well seperation for more fair results)\n",
    "    axs[0,0].bar(models, aucs, color=['blue', 'green'])\n",
    "    axs[0,0].set_title('AUC')\n",
    "    axs[0,0].set_ylim([0, 1])\n",
    "\n",
    "    ## correct pred/total pred\n",
    "    ## fairness may lower accuracy \n",
    "    axs[0,1].bar(models, accs, color=['blue', 'green'])\n",
    "    axs[0,1].set_title('Accuracy')\n",
    "    axs[0,1].set_ylim([0, 1])\n",
    "\n",
    "    ## orange = baseline, purple = fairness -LOOK INTO TO SEE HOW TO KNOW WHICH GROUP IS CONTRIBUTING TO HIGHER DP\n",
    "    # lower values of dp indciate better fairness\n",
    "    axs[1,0].bar(models, dp_diff, color=['orange', 'purple'])\n",
    "    axs[1,0].set_title('Demographic Parity Difference')\n",
    "\n",
    "    ## lower value - better fairness\n",
    "    ## equalized odds is satisfied if tpr and fpr are equal across the different groups in the sensitive feature\n",
    "    axs[1,1].bar(models, eo_diff, color=['orange', 'purple'])\n",
    "    axs[1,1].set_title('Equalized Odds Difference')\n",
    "\n",
    "    plt.suptitle(\"Comparison: Baseline (X → Y) vs. Fair (X → Y') Model\")\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9934d0d9-03c6-4480-a9d2-90283ba9e07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Main Function: Comparison and Visualization\n",
    "# -------------------------------\n",
    "def multi_main(data_url, dataset_name, lambda_adv=1.0):\n",
    "    set_seed(42)\n",
    "\n",
    "    if dataset_name == \"compas\": \n",
    "        X, Y_obs, S = load_and_preprocess_compas_data_binary(data_url) ##  Y, S is binary\n",
    "        num_classes_Y = len(np.unique(Y_obs))\n",
    "    \n",
    "    elif dataset_name == \"drug\":\n",
    "        X, Y_obs, S = load_and_process_drug_consumption_data(data_url) ##  Y is multi class, S is binary\n",
    "        num_classes_Y = len(np.unique(Y_obs))\n",
    "\n",
    "    else:\n",
    "        print (\"Invalid dataset_name\")\n",
    "        return \n",
    "    \n",
    "    print(f\"Loading and preprocessing {dataset_name} data...\")\n",
    "    X_train, X_test, Y_train_obs, Y_test_obs, S_train, S_test = train_test_split(\n",
    "        X, Y_obs, S, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    if dataset_name == \"compas\":\n",
    "        print(f\"Features shape: {X.shape}\")\n",
    "        print(f\"Observed Label Y shape: {Y_obs.shape}   (Recidivism: 1=recid, 0=non-recid)\")\n",
    "        print(f\"Sensitive Attribute (Race, binarized) shape: {S.shape}\")\n",
    "        \n",
    "    elif dataset_name == \"drug\":\n",
    "        print(f\"Features shape: {X.shape}\")\n",
    "        print(f\"Observed Label Y shape: {Y_obs.shape}   (Label from 'drug consumption')\")\n",
    "        print(f\"Sensitive Attribute (Education) shape: {S.shape}\")\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "\n",
    "    # One-hot encode S for adversarial model training.\n",
    "    S_train_oh = tf.keras.utils.to_categorical(S_train, num_classes=2) # will need to change this if not longer 2\n",
    "    S_test_oh  = tf.keras.utils.to_categorical(S_test, num_classes=2) # will need to change this if no longer 2\n",
    "\n",
    "    # need to one hot encode Y\n",
    "    Y_train_obs = tf.keras.utils.to_categorical(Y_train_obs, num_classes=num_classes_Y)\n",
    "    Y_test_obs = tf.keras.utils.to_categorical(Y_test_obs, num_classes=num_classes_Y)\n",
    "    \n",
    "    Y_train_obs_1d = np.argmax(Y_train_obs, axis=1)  # Convert from one-hot to categorical labels\n",
    "    Y_test_obs_1d = np.argmax(Y_test_obs, axis=1)  # Do the same for test set\n",
    "\n",
    "    ### 1. Train adversarial debiasing model (X → Y' with adversary)\n",
    "    print(\"\\nTraining adversarial model (X → Y' with adversary) ...\")\n",
    "    adv_model = build_adversarial_model(input_dim, num_classes_Y, lambda_adv=lambda_adv)\n",
    "    # For training, we use the observed Y as target for both pseudo_Y and Y_pred.\n",
    "    # Reshape Y_obs to (-1,1) since our outputs are scalars.\n",
    "    # Y_train_obs_exp = Y_train_obs.reshape(-1, 1)\n",
    "    # Y_test_obs_exp  = Y_test_obs.reshape(-1, 1)\n",
    "    adv_model.fit([X_train, S_train_oh],\n",
    "                  {\"pseudo_Y\": Y_train_obs, \"S_pred\": S_train_oh, \"Y_pred\": Y_train_obs},\n",
    "                  epochs=60, batch_size=128, verbose=1)\n",
    "\n",
    "    # Get pseudo-label predictions.\n",
    "    pseudo_Y_train, S_pred_train, Y_pred_train = adv_model.predict([X_train, S_train_oh]) ## changed so we're using Y_pred here instead of psuedo_Y\n",
    "    pseudo_Y_test,  S_pred_test, Y_pred_test = adv_model.predict([X_test, S_test_oh])\n",
    "\n",
    "    # Threshold pseudo-labels to get binary labels.\n",
    "    Y_pred_train_bin = np.argmax(Y_pred_train, axis= 1)\n",
    "    Y_pred_test_bin  = np.argmax(Y_pred_test, axis=1) \n",
    "\n",
    "    print(\"\\nPseudo-label statistics (training):\")\n",
    "    for g in np.unique(S_train):\n",
    "        mask = (S_train == g)\n",
    "        print(f\"Group {g} pseudo-positive rate: {np.mean(Y_pred_train_bin[mask]):.4f}\") # average probability of a postive prediction per group -- fairness check to see if both groups receive similar treatment\n",
    "\n",
    "    ### 2. Train baseline logistic regression model on observed Y (X → Y) -- regular logistic regression for baseline for comparison; does not include any fairness constraints\n",
    "    print(\"\\nTraining baseline logistic regression classifier (X → Y)...\")\n",
    "    baseline_clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "    baseline_clf.fit(X_train, Y_train_obs_1d)\n",
    "    \n",
    "    baseline_preds = baseline_clf.predict_proba(X_test)    \n",
    "    baseline_auc = roc_auc_score(Y_test_obs, baseline_preds, multi_class=\"ovr\")\n",
    "    baseline_preds_class = baseline_preds.argmax(axis=1)\n",
    "    baseline_acc = accuracy_score(Y_test_obs_1d, baseline_preds_class)\n",
    "\n",
    "    baseline_fairness = multi_compute_fairness_metrics_manual(Y_test_obs, baseline_preds_class, sensitive_features=S_test)\n",
    "\n",
    "    ### 3. Train fair logistic regression model on pseudo-labels (X → Y') -- using psuedo_Y from the the adv_model, \n",
    "    print(\"\\nTraining fair logistic regression classifier (X → Y') using Y_pred labels...\")\n",
    "    fair_clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "    fair_clf.fit(X_train, Y_pred_train_bin)\n",
    "    fair_preds = fair_clf.predict_proba(X_test)\n",
    "    fair_auc = roc_auc_score(Y_test_obs, fair_preds, multi_class='ovr')\n",
    "    fair_preds_class = fair_preds.argmax(axis=1)\n",
    "    fair_acc = accuracy_score(Y_test_obs_1d, fair_preds_class)\n",
    "\n",
    "    fair_fairness = multi_compute_fairness_metrics_manual(Y_test_obs, fair_preds_class, sensitive_features=S_test)\n",
    "\n",
    "    # Aggregate metrics for plotting.\n",
    "    metrics_baseline = {\n",
    "        \"auc\": baseline_auc,\n",
    "        \"accuracy\": baseline_acc,\n",
    "        \"demographic_parity_difference\": baseline_fairness[\"demographic_parity_difference\"],\n",
    "        \"equalized_odds_difference\": baseline_fairness[\"equalized_odds_difference\"]\n",
    "    }\n",
    "    metrics_fair = {\n",
    "        \"auc\": fair_auc,\n",
    "        \"accuracy\": fair_acc,\n",
    "        \"demographic_parity_difference\": fair_fairness[\"demographic_parity_difference\"],\n",
    "        \"equalized_odds_difference\": fair_fairness[\"equalized_odds_difference\"]\n",
    "    }\n",
    "\n",
    "    print(\"\\nBaseline Logistic Regression (X → Y) Evaluation:\")\n",
    "    print(f\"AUC: {baseline_auc:.4f}, Accuracy: {baseline_acc:.4f}\")\n",
    "    print(\"Fairness metrics:\", baseline_fairness)\n",
    "\n",
    "    print(\"\\nFair Logistic Regression (X → Y') Evaluation (compared to observed Y):\")\n",
    "    print(f\"AUC: {fair_auc:.4f}, Accuracy: {fair_acc:.4f}\")\n",
    "    print(\"Fairness metrics:\", fair_fairness)\n",
    "\n",
    "    # Plot comparison.\n",
    "    multi_plot_comparison(metrics_baseline, metrics_fair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046a7324-619d-470b-9ec7-f1b4bf6d984f",
   "metadata": {},
   "source": [
    "### Application on Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4a8cb1-26fd-47ae-ba82-01642fb05249",
   "metadata": {},
   "source": [
    "#### Drug Consumption Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49a030df-362c-4806-8fdd-75f9b4a75487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing drug data...\n",
      "Features shape: (1884, 10)\n",
      "Observed Label Y shape: (1884,)   (Label from 'drug consumption')\n",
      "Sensitive Attribute (Education) shape: (1884,)\n",
      "\n",
      "Training adversarial model (X → Y' with adversary) ...\n",
      "Epoch 1/60\n",
      "12/12 [==============================] - 2s 11ms/step - loss: 3.5275 - pseudo_Y_loss: 1.8738 - S_pred_loss: 0.9527 - Y_pred_loss: 1.6538 - pseudo_Y_accuracy: 0.2515 - S_pred_accuracy: 0.5222 - Y_pred_accuracy: 0.2979\n",
      "Epoch 2/60\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.4465 - pseudo_Y_loss: 1.8410 - S_pred_loss: 0.9196 - Y_pred_loss: 1.6055 - pseudo_Y_accuracy: 0.2608 - S_pred_accuracy: 0.5189 - Y_pred_accuracy: 0.2893\n",
      "Epoch 3/60\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.4092 - pseudo_Y_loss: 1.8235 - S_pred_loss: 0.9177 - Y_pred_loss: 1.5857 - pseudo_Y_accuracy: 0.2614 - S_pred_accuracy: 0.5156 - Y_pred_accuracy: 0.2999\n",
      "Epoch 4/60\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.3525 - pseudo_Y_loss: 1.7865 - S_pred_loss: 0.9181 - Y_pred_loss: 1.5660 - pseudo_Y_accuracy: 0.2648 - S_pred_accuracy: 0.5242 - Y_pred_accuracy: 0.3152\n",
      "Epoch 5/60\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 3.3004 - pseudo_Y_loss: 1.7683 - S_pred_loss: 0.8986 - Y_pred_loss: 1.5322 - pseudo_Y_accuracy: 0.2707 - S_pred_accuracy: 0.5189 - Y_pred_accuracy: 0.3139\n",
      "Epoch 6/60\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.2572 - pseudo_Y_loss: 1.7445 - S_pred_loss: 0.8997 - Y_pred_loss: 1.5127 - pseudo_Y_accuracy: 0.2707 - S_pred_accuracy: 0.5109 - Y_pred_accuracy: 0.3225\n",
      "Epoch 7/60\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.2065 - pseudo_Y_loss: 1.7201 - S_pred_loss: 0.8833 - Y_pred_loss: 1.4864 - pseudo_Y_accuracy: 0.2694 - S_pred_accuracy: 0.5123 - Y_pred_accuracy: 0.3504\n",
      "Epoch 8/60\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.1683 - pseudo_Y_loss: 1.6909 - S_pred_loss: 0.8694 - Y_pred_loss: 1.4775 - pseudo_Y_accuracy: 0.2807 - S_pred_accuracy: 0.5090 - Y_pred_accuracy: 0.3298\n",
      "Epoch 9/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.1386 - pseudo_Y_loss: 1.6759 - S_pred_loss: 0.8603 - Y_pred_loss: 1.4627 - pseudo_Y_accuracy: 0.2714 - S_pred_accuracy: 0.5163 - Y_pred_accuracy: 0.3404\n",
      "Epoch 10/60\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.0980 - pseudo_Y_loss: 1.6537 - S_pred_loss: 0.8450 - Y_pred_loss: 1.4444 - pseudo_Y_accuracy: 0.2920 - S_pred_accuracy: 0.5182 - Y_pred_accuracy: 0.3470\n",
      "Epoch 11/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.0689 - pseudo_Y_loss: 1.6383 - S_pred_loss: 0.8518 - Y_pred_loss: 1.4305 - pseudo_Y_accuracy: 0.2833 - S_pred_accuracy: 0.5136 - Y_pred_accuracy: 0.3557\n",
      "Epoch 12/60\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3.0323 - pseudo_Y_loss: 1.6112 - S_pred_loss: 0.8426 - Y_pred_loss: 1.4212 - pseudo_Y_accuracy: 0.2853 - S_pred_accuracy: 0.5070 - Y_pred_accuracy: 0.3470\n",
      "Epoch 13/60\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.9951 - pseudo_Y_loss: 1.5919 - S_pred_loss: 0.8420 - Y_pred_loss: 1.4032 - pseudo_Y_accuracy: 0.2960 - S_pred_accuracy: 0.5090 - Y_pred_accuracy: 0.3736\n",
      "Epoch 14/60\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.9592 - pseudo_Y_loss: 1.5763 - S_pred_loss: 0.8166 - Y_pred_loss: 1.3829 - pseudo_Y_accuracy: 0.2880 - S_pred_accuracy: 0.5090 - Y_pred_accuracy: 0.3776\n",
      "Epoch 15/60\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.9352 - pseudo_Y_loss: 1.5575 - S_pred_loss: 0.8197 - Y_pred_loss: 1.3776 - pseudo_Y_accuracy: 0.3006 - S_pred_accuracy: 0.5143 - Y_pred_accuracy: 0.3829\n",
      "Epoch 16/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.9281 - pseudo_Y_loss: 1.5581 - S_pred_loss: 0.8161 - Y_pred_loss: 1.3700 - pseudo_Y_accuracy: 0.2933 - S_pred_accuracy: 0.5109 - Y_pred_accuracy: 0.3962\n",
      "Epoch 17/60\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.8831 - pseudo_Y_loss: 1.5280 - S_pred_loss: 0.7994 - Y_pred_loss: 1.3551 - pseudo_Y_accuracy: 0.3059 - S_pred_accuracy: 0.5249 - Y_pred_accuracy: 0.4015\n",
      "Epoch 18/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.8675 - pseudo_Y_loss: 1.5198 - S_pred_loss: 0.7930 - Y_pred_loss: 1.3478 - pseudo_Y_accuracy: 0.3145 - S_pred_accuracy: 0.5209 - Y_pred_accuracy: 0.3962\n",
      "Epoch 19/60\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.8367 - pseudo_Y_loss: 1.5012 - S_pred_loss: 0.7909 - Y_pred_loss: 1.3356 - pseudo_Y_accuracy: 0.3145 - S_pred_accuracy: 0.5149 - Y_pred_accuracy: 0.4127\n",
      "Epoch 20/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.8244 - pseudo_Y_loss: 1.4936 - S_pred_loss: 0.7917 - Y_pred_loss: 1.3308 - pseudo_Y_accuracy: 0.3179 - S_pred_accuracy: 0.5090 - Y_pred_accuracy: 0.4187\n",
      "Epoch 21/60\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.8005 - pseudo_Y_loss: 1.4782 - S_pred_loss: 0.7879 - Y_pred_loss: 1.3224 - pseudo_Y_accuracy: 0.3145 - S_pred_accuracy: 0.5090 - Y_pred_accuracy: 0.4273\n",
      "Epoch 22/60\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.7938 - pseudo_Y_loss: 1.4738 - S_pred_loss: 0.7764 - Y_pred_loss: 1.3200 - pseudo_Y_accuracy: 0.3238 - S_pred_accuracy: 0.5143 - Y_pred_accuracy: 0.4333\n",
      "Epoch 23/60\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.7688 - pseudo_Y_loss: 1.4582 - S_pred_loss: 0.7719 - Y_pred_loss: 1.3105 - pseudo_Y_accuracy: 0.3278 - S_pred_accuracy: 0.5109 - Y_pred_accuracy: 0.4446\n",
      "Epoch 24/60\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.7518 - pseudo_Y_loss: 1.4551 - S_pred_loss: 0.7684 - Y_pred_loss: 1.2968 - pseudo_Y_accuracy: 0.3278 - S_pred_accuracy: 0.5189 - Y_pred_accuracy: 0.4439\n",
      "Epoch 25/60\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.7487 - pseudo_Y_loss: 1.4545 - S_pred_loss: 0.7648 - Y_pred_loss: 1.2942 - pseudo_Y_accuracy: 0.3351 - S_pred_accuracy: 0.5143 - Y_pred_accuracy: 0.4559\n",
      "Epoch 26/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7188 - pseudo_Y_loss: 1.4356 - S_pred_loss: 0.7584 - Y_pred_loss: 1.2832 - pseudo_Y_accuracy: 0.3451 - S_pred_accuracy: 0.5123 - Y_pred_accuracy: 0.4532\n",
      "Epoch 27/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.7111 - pseudo_Y_loss: 1.4302 - S_pred_loss: 0.7599 - Y_pred_loss: 1.2809 - pseudo_Y_accuracy: 0.3444 - S_pred_accuracy: 0.5236 - Y_pred_accuracy: 0.4526\n",
      "Epoch 28/60\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.6923 - pseudo_Y_loss: 1.4143 - S_pred_loss: 0.7567 - Y_pred_loss: 1.2779 - pseudo_Y_accuracy: 0.3417 - S_pred_accuracy: 0.5136 - Y_pred_accuracy: 0.4472\n",
      "Epoch 29/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6865 - pseudo_Y_loss: 1.4094 - S_pred_loss: 0.7487 - Y_pred_loss: 1.2771 - pseudo_Y_accuracy: 0.3570 - S_pred_accuracy: 0.5255 - Y_pred_accuracy: 0.4446\n",
      "Epoch 30/60\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.6615 - pseudo_Y_loss: 1.4023 - S_pred_loss: 0.7304 - Y_pred_loss: 1.2592 - pseudo_Y_accuracy: 0.3444 - S_pred_accuracy: 0.5209 - Y_pred_accuracy: 0.4665\n",
      "Epoch 31/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6607 - pseudo_Y_loss: 1.3998 - S_pred_loss: 0.7312 - Y_pred_loss: 1.2609 - pseudo_Y_accuracy: 0.3603 - S_pred_accuracy: 0.5289 - Y_pred_accuracy: 0.4658\n",
      "Epoch 32/60\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.6531 - pseudo_Y_loss: 1.3923 - S_pred_loss: 0.7264 - Y_pred_loss: 1.2608 - pseudo_Y_accuracy: 0.3517 - S_pred_accuracy: 0.5163 - Y_pred_accuracy: 0.4645\n",
      "Epoch 33/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.6264 - pseudo_Y_loss: 1.3747 - S_pred_loss: 0.7292 - Y_pred_loss: 1.2516 - pseudo_Y_accuracy: 0.3789 - S_pred_accuracy: 0.5355 - Y_pred_accuracy: 0.4638\n",
      "Epoch 34/60\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.6142 - pseudo_Y_loss: 1.3733 - S_pred_loss: 0.7141 - Y_pred_loss: 1.2409 - pseudo_Y_accuracy: 0.3603 - S_pred_accuracy: 0.5474 - Y_pred_accuracy: 0.4751\n",
      "Epoch 35/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5975 - pseudo_Y_loss: 1.3659 - S_pred_loss: 0.7255 - Y_pred_loss: 1.2316 - pseudo_Y_accuracy: 0.3623 - S_pred_accuracy: 0.5382 - Y_pred_accuracy: 0.4851\n",
      "Epoch 36/60\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.5935 - pseudo_Y_loss: 1.3629 - S_pred_loss: 0.7162 - Y_pred_loss: 1.2305 - pseudo_Y_accuracy: 0.3802 - S_pred_accuracy: 0.5481 - Y_pred_accuracy: 0.4698\n",
      "Epoch 37/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5936 - pseudo_Y_loss: 1.3594 - S_pred_loss: 0.7065 - Y_pred_loss: 1.2342 - pseudo_Y_accuracy: 0.3656 - S_pred_accuracy: 0.5455 - Y_pred_accuracy: 0.4751\n",
      "Epoch 38/60\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.5757 - pseudo_Y_loss: 1.3504 - S_pred_loss: 0.7064 - Y_pred_loss: 1.2252 - pseudo_Y_accuracy: 0.3663 - S_pred_accuracy: 0.5627 - Y_pred_accuracy: 0.4764\n",
      "Epoch 39/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5613 - pseudo_Y_loss: 1.3409 - S_pred_loss: 0.7030 - Y_pred_loss: 1.2204 - pseudo_Y_accuracy: 0.3822 - S_pred_accuracy: 0.5601 - Y_pred_accuracy: 0.4758\n",
      "Epoch 40/60\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.5592 - pseudo_Y_loss: 1.3449 - S_pred_loss: 0.7046 - Y_pred_loss: 1.2143 - pseudo_Y_accuracy: 0.3889 - S_pred_accuracy: 0.5574 - Y_pred_accuracy: 0.4791\n",
      "Epoch 41/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5562 - pseudo_Y_loss: 1.3405 - S_pred_loss: 0.6940 - Y_pred_loss: 1.2157 - pseudo_Y_accuracy: 0.3696 - S_pred_accuracy: 0.5700 - Y_pred_accuracy: 0.4824\n",
      "Epoch 42/60\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.5379 - pseudo_Y_loss: 1.3311 - S_pred_loss: 0.6999 - Y_pred_loss: 1.2069 - pseudo_Y_accuracy: 0.3855 - S_pred_accuracy: 0.5720 - Y_pred_accuracy: 0.4764\n",
      "Epoch 43/60\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.5312 - pseudo_Y_loss: 1.3265 - S_pred_loss: 0.6941 - Y_pred_loss: 1.2047 - pseudo_Y_accuracy: 0.3928 - S_pred_accuracy: 0.5766 - Y_pred_accuracy: 0.4897\n",
      "Epoch 44/60\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.5228 - pseudo_Y_loss: 1.3192 - S_pred_loss: 0.6876 - Y_pred_loss: 1.2036 - pseudo_Y_accuracy: 0.3835 - S_pred_accuracy: 0.5813 - Y_pred_accuracy: 0.4745\n",
      "Epoch 45/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5178 - pseudo_Y_loss: 1.3142 - S_pred_loss: 0.6869 - Y_pred_loss: 1.2036 - pseudo_Y_accuracy: 0.3882 - S_pred_accuracy: 0.5740 - Y_pred_accuracy: 0.4771\n",
      "Epoch 46/60\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.5072 - pseudo_Y_loss: 1.3093 - S_pred_loss: 0.6855 - Y_pred_loss: 1.1979 - pseudo_Y_accuracy: 0.4068 - S_pred_accuracy: 0.5760 - Y_pred_accuracy: 0.4917\n",
      "Epoch 47/60\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.4959 - pseudo_Y_loss: 1.3077 - S_pred_loss: 0.6806 - Y_pred_loss: 1.1883 - pseudo_Y_accuracy: 0.4015 - S_pred_accuracy: 0.5999 - Y_pred_accuracy: 0.4977\n",
      "Epoch 48/60\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.4880 - pseudo_Y_loss: 1.2987 - S_pred_loss: 0.6813 - Y_pred_loss: 1.1893 - pseudo_Y_accuracy: 0.4074 - S_pred_accuracy: 0.5965 - Y_pred_accuracy: 0.4950\n",
      "Epoch 49/60\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2.4822 - pseudo_Y_loss: 1.2967 - S_pred_loss: 0.6760 - Y_pred_loss: 1.1855 - pseudo_Y_accuracy: 0.3962 - S_pred_accuracy: 0.6005 - Y_pred_accuracy: 0.4930\n",
      "Epoch 50/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4674 - pseudo_Y_loss: 1.2897 - S_pred_loss: 0.6826 - Y_pred_loss: 1.1777 - pseudo_Y_accuracy: 0.4035 - S_pred_accuracy: 0.6005 - Y_pred_accuracy: 0.4910\n",
      "Epoch 51/60\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.4767 - pseudo_Y_loss: 1.2899 - S_pred_loss: 0.6798 - Y_pred_loss: 1.1867 - pseudo_Y_accuracy: 0.4107 - S_pred_accuracy: 0.6078 - Y_pred_accuracy: 0.4957\n",
      "Epoch 52/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4707 - pseudo_Y_loss: 1.2925 - S_pred_loss: 0.6750 - Y_pred_loss: 1.1782 - pseudo_Y_accuracy: 0.4041 - S_pred_accuracy: 0.5859 - Y_pred_accuracy: 0.4930\n",
      "Epoch 53/60\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.4472 - pseudo_Y_loss: 1.2811 - S_pred_loss: 0.6736 - Y_pred_loss: 1.1661 - pseudo_Y_accuracy: 0.4180 - S_pred_accuracy: 0.6105 - Y_pred_accuracy: 0.4891\n",
      "Epoch 54/60\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.4527 - pseudo_Y_loss: 1.2799 - S_pred_loss: 0.6723 - Y_pred_loss: 1.1727 - pseudo_Y_accuracy: 0.4094 - S_pred_accuracy: 0.6078 - Y_pred_accuracy: 0.4871\n",
      "Epoch 55/60\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.4454 - pseudo_Y_loss: 1.2742 - S_pred_loss: 0.6725 - Y_pred_loss: 1.1712 - pseudo_Y_accuracy: 0.4194 - S_pred_accuracy: 0.6078 - Y_pred_accuracy: 0.4871\n",
      "Epoch 56/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4358 - pseudo_Y_loss: 1.2708 - S_pred_loss: 0.6730 - Y_pred_loss: 1.1650 - pseudo_Y_accuracy: 0.4161 - S_pred_accuracy: 0.6065 - Y_pred_accuracy: 0.4811\n",
      "Epoch 57/60\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.4231 - pseudo_Y_loss: 1.2653 - S_pred_loss: 0.6718 - Y_pred_loss: 1.1578 - pseudo_Y_accuracy: 0.4161 - S_pred_accuracy: 0.6092 - Y_pred_accuracy: 0.4930\n",
      "Epoch 58/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4235 - pseudo_Y_loss: 1.2628 - S_pred_loss: 0.6682 - Y_pred_loss: 1.1608 - pseudo_Y_accuracy: 0.4207 - S_pred_accuracy: 0.6105 - Y_pred_accuracy: 0.4930\n",
      "Epoch 59/60\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2.4047 - pseudo_Y_loss: 1.2550 - S_pred_loss: 0.6664 - Y_pred_loss: 1.1497 - pseudo_Y_accuracy: 0.4260 - S_pred_accuracy: 0.6098 - Y_pred_accuracy: 0.5023\n",
      "Epoch 60/60\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.4006 - pseudo_Y_loss: 1.2506 - S_pred_loss: 0.6648 - Y_pred_loss: 1.1500 - pseudo_Y_accuracy: 0.4267 - S_pred_accuracy: 0.6138 - Y_pred_accuracy: 0.4910\n",
      "48/48 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "\n",
      "Pseudo-label statistics (training):\n",
      "Group 0 pseudo-positive rate: 1.8232\n",
      "Group 1 pseudo-positive rate: 0.9866\n",
      "\n",
      "Training baseline logistic regression classifier (X → Y)...\n",
      "\n",
      "Training fair logistic regression classifier (X → Y') using Y_pred labels...\n",
      "\n",
      "Baseline Logistic Regression (X → Y) Evaluation:\n",
      "AUC: 0.7180, Accuracy: 0.4562\n",
      "Fairness metrics: {'demographic_parity_difference': 0.1530409356725146, 'equalized_odds_difference': 0.1799298143903881, 'selection_rate': {0: [0.14473684210526316, 0.21052631578947367], 1: [0.29777777777777775, 0.23555555555555555]}, 'group_accuracy': {0: 0.5657894736842105, 1: 0.38222222222222224}}\n",
      "\n",
      "Fair Logistic Regression (X → Y') Evaluation (compared to observed Y):\n",
      "AUC: 0.6602, Accuracy: 0.4483\n",
      "Fairness metrics: {'demographic_parity_difference': 0.12921052631578947, 'equalized_odds_difference': 0.22805336012172966, 'selection_rate': {0: [0.13815789473684212, 0.19078947368421054], 1: [0.18222222222222223, 0.32]}, 'group_accuracy': {0: 0.5394736842105263, 1: 0.38666666666666666}}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Good to go\n",
    "def load_and_process_drug_consumption_data(path):\n",
    "\n",
    "    # path = os.path.join(\"data\", \"drug_consumption.csv\")\n",
    "    path = \"../data/drug_consumption.csv\"\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = df.columns.str.lower().str.strip()\n",
    "    \n",
    "    # convert to 4 classes\n",
    "    df = df[df.columns[1:]]\n",
    "    df = df.replace(\n",
    "        {\n",
    "            \"cannabis\": {\n",
    "                \"CL0\": \"never_used\",\n",
    "                \"CL1\": \"not_in_last_year\",\n",
    "                \"CL2\": \"not_in_last_year\",\n",
    "                \"CL3\": \"used_in_last_year\",\n",
    "                \"CL4\": \"used_in_last_year\",\n",
    "                \"CL5\": \"used_in_last_week\",\n",
    "                \"CL6\": \"used_in_last_week\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    educated_cat = {\n",
    "        \"University degree\",\n",
    "        \"Masters degree\",\n",
    "        \"Doctorate degree\",\n",
    "        \"Professional certificate/ diploma\"\n",
    "    }\n",
    "    \n",
    "    df[\"education\"] = df[\"education\"].apply(lambda x: 1 if x in educated_cat else 0)\n",
    "    \n",
    "    # changing to numerical representation\n",
    "    label_encoder = LabelEncoder()\n",
    "    # df[\"age\"] = label_encoder.fit_transform(df[\"age\"]) \n",
    "    df[\"country\"] = label_encoder.fit_transform(df[\"country\"])\n",
    "    df[\"ethnicity\"] = label_encoder.fit_transform(df[\"ethnicity\"])\n",
    "    df[\"cannabis\"] = label_encoder.fit_transform(df[\"cannabis\"])\n",
    "\n",
    "    \n",
    "    \n",
    "    df[\"gender\"] = df[\"gender\"].apply(lambda x: 1 if x == \"M\" else 0)\n",
    "    \n",
    "    X = df[df.columns[1:12]]\n",
    "    Y = df[\"cannabis\"].to_numpy()\n",
    "    S = df[\"education\"].to_numpy()\n",
    "    X = X.drop(columns = [\"education\"])\n",
    "\n",
    "    return X, Y, S\n",
    "\n",
    "multi_main(\"ANYTHING\", \"drug\", lambda_adv=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995afe77-9590-4179-91be-d8f49e8cad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## logistic regression is essentially being used to as test model to see how it's working? for multiclass, it's still using logistic regression but multi_class=multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31d2a34-5537-464d-bfa2-145aca328906",
   "metadata": {},
   "source": [
    "#### Compas Dataset -- multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9792f0-69b2-4b91-b491-c5acfac2ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COME BACK AND DO IF WANT TO IMPLEMENT WHERE SENSITIVE FEATURE IS NOT JUST BINARY\n",
    "def load_and_preprocess_compas_data_multi_cat(data_url):\n",
    "    \"\"\"\n",
    "    Try the algorithm, except instead of binary sensitive feature, it multi classes (so not just Aferican American)? \n",
    "    \n",
    "    Download and preprocess the COMPAS dataset.\n",
    "\n",
    "    We assume the dataset contains, among others, the following columns:\n",
    "      - 'age'\n",
    "      - 'race'\n",
    "      - 'priors_count'\n",
    "      - 'juv_fel_count'\n",
    "      - 'juv_misd_count'\n",
    "      - 'juv_other_count'\n",
    "      - 'two_year_recid'\n",
    "\n",
    "    Features (X): We select a few numerical features.\n",
    "    Observed Label (Y): Use 'two_year_recid' as a binary label (0/1).\n",
    "    Protected Attribute (S): Use 'race'. Here we binarize race so that:\n",
    "         African‑American  → 1\n",
    "         all other races  → 0.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(data_url)\n",
    "    # Drop rows with missing values in the selected columns.\n",
    "    data = data.dropna(subset=[\"age\", \"race\", \"priors_count\", \"juv_fel_count\", \"juv_misd_count\", \"juv_other_count\", \"two_year_recid\"])\n",
    "\n",
    "    # Observed label: two_year_recid (already 0/1)\n",
    "    Y = data[\"two_year_recid\"].values\n",
    "\n",
    "    # Sensitive attribute: race. We set S=1 if race is African-American, else 0.\n",
    "    S = (data[\"race\"] == \"African-American\").astype(int).values\n",
    "\n",
    "    # Features: use a subset of numerical features.\n",
    "    feature_cols = [\"age\", \"priors_count\", \"juv_fel_count\", \"juv_misd_count\", \"juv_other_count\"]\n",
    "    X = data[feature_cols].copy().astype(np.float32)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X.values)\n",
    "\n",
    "    return X, Y, S\n",
    "\n",
    "# URL for the ProPublica COMPAS dataset\n",
    "compas_data_url = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
    "# You can adjust lambda_adv as desired (e.g., lambda_adv=15.5 as in your German data experiment)\n",
    "main_compas(compas_data_url, lambda_adv=3.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
